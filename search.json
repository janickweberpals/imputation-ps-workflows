[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multiple imputation-propensity score workflows",
    "section": "",
    "text": "Background\nMultiple imputation is a powerful tool in presence of missing data. However, especially in combination with propensity score analyses, multiple imputation can lead to challenges since analytic workflows can be become much more complex.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Objective",
    "text": "Objective\nThis repository showcases and evaluation different multiple imputation &gt; propensity score &gt; outcome analyses and associated implementation challenges.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#sec-dependencies",
    "href": "index.html#sec-dependencies",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Dependencies",
    "text": "Dependencies\nThis is a quarto book project and R package dependencies are managed through the renv package. All packages and their versions can be viewed in the lockfile renv.lock. All required packages and the appropriate versions can be installed by running the following command:\n\nrenv::restore(repos = \"https://packagemanager.posit.co/cran/latest\")\n\n\n\n\n\n\n\nImportant\n\n\n\nThe dependencies are managed through Posit’s repository package manager (RSPM). If you use a different operating system than macOS, please head over to the RSPM setup website and follow these steps to adjust the URL above.\n\nGo to the RSPM setup website\nChoose the operating system (if Linux, also choose the Linux distribution)\nGo to Repository URL: and copy-paste the URL to the options statement in the .Rprofile file\noptions(repos = c(REPO_NAME = “URL”))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Reproducibility",
    "text": "Reproducibility\nFollow these steps in RStudio to reproduce this study:\n\n\n\n\n\n\nNote\n\n\n\n\nClone this repository via git clone &lt;url&gt; or in RStudio via File &gt; New Project &gt; Version Control &gt; Git &gt; then paste the link to repository URL\nInstall all necessary dependencies (see above)\nAdd/adapt the paths to the datasets in .Renviron\nIn RStudio, run all scripts via quarto render or Build &gt; Render Book (make sure quarto is installed)\n\n\n\n\nSteps to clone this repository in RStudio\n\n\n\n\nThe data used in this project is strictly simulated and no real patient-level data is used.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#repository-structure-and-files",
    "href": "index.html#repository-structure-and-files",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Repository structure and files",
    "text": "Repository structure and files\n\nDirectory overview\n\n\n.\n├── 01_syvcox_coxph.md\n├── 01_syvcox_coxph.qmd\n├── 02_re_weight.html.md\n├── 02_re_weight.qmd\n├── 03_subgroup_analysis.qmd\n├── README.md\n├── RStudio_init.png\n├── _book\n│   ├── 01_syvcox_coxph.html\n│   ├── 02_re_weight.html\n│   ├── RStudio_init.png\n│   ├── index.html\n│   ├── nejm_tbl1.png\n│   ├── search.json\n│   └── site_libs\n├── _quarto.yml\n├── functions\n│   ├── imputation_workflow.R\n│   ├── install_on_demand.R\n│   ├── re_weight.R\n│   ├── simulate_flaura.R\n│   ├── source_encore.io_functions.R\n│   └── subgroup.R\n├── index.qmd\n├── index.rmarkdown\n├── nejm_tbl1.png\n├── references.bib\n├── renv\n│   ├── activate.R\n│   ├── library\n│   ├── settings.json\n│   └── staging\n├── renv.lock\n└── site_libs\n    ├── bootstrap\n    ├── clipboard\n    ├── quarto-html\n    ├── quarto-nav\n    └── quarto-search",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html",
    "href": "01_syvcox_coxph.html",
    "title": "2  coxph versus svycoxph",
    "section": "",
    "text": "2.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()\n\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1,712\n1\n1\nN = 1,788\n1\n\n\n\n\nc_smoking_history\n579 (51%)\n520 (43%)\n\n\n    Unknown\n578\n584\n\n\nc_number_met_sites\n\n\n\n\n\n\n    1\n837 (74%)\n899 (75%)\n\n\n    2\n249 (22%)\n255 (21%)\n\n\n    3\n41 (3.6%)\n42 (3.5%)\n\n\n    4\n7 (0.6%)\n8 (0.7%)\n\n\n    Unknown\n578\n584\n\n\nc_ecog_cont\n714 (63%)\n637 (53%)\n\n\n    Unknown\n578\n584\n\n\nc_stage_initial_dx_cont\n\n\n\n\n\n\n    1\n101 (8.9%)\n0 (0%)\n\n\n    2\n17 (1.5%)\n12 (1.0%)\n\n\n    3\n15 (1.3%)\n38 (3.2%)\n\n\n    4\n1,001 (88%)\n1,154 (96%)\n\n\n    Unknown\n578\n584\n\n\nc_hemoglobin_g_dl_cont\n12.97 (12.16, 13.72)\n12.89 (11.98, 13.75)\n\n\n    Unknown\n578\n584\n\n\nc_urea_nitrogen_mg_dl_cont\n2.76 (2.42, 3.08)\n2.77 (2.58, 2.97)\n\n\n    Unknown\n578\n584\n\n\nc_platelets_10_9_l_cont\n255 (218, 290)\n266 (230, 302)\n\n\n    Unknown\n578\n584\n\n\nc_calcium_mg_dl_cont\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n\n\n    Unknown\n578\n584\n\n\nc_glucose_mg_dl_cont\n4.64 (4.55, 4.72)\n4.65 (4.58, 4.73)\n\n\n    Unknown\n578\n584\n\n\nc_lymphocyte_leukocyte_ratio_cont\n2.94 (2.81, 3.08)\n2.93 (2.82, 3.04)\n\n\n    Unknown\n578\n584\n\n\nc_alp_u_l_cont\n4.47 (4.33, 4.61)\n4.51 (4.42, 4.59)\n\n\n    Unknown\n578\n584\n\n\nc_protein_g_l_cont\n67.8 (65.1, 70.6)\n69.0 (66.0, 72.1)\n\n\n    Unknown\n578\n584\n\n\nc_alt_u_l_cont\n2.93 (2.72, 3.14)\n2.86 (2.64, 3.10)\n\n\n    Unknown\n578\n584\n\n\nc_albumin_g_l_cont\n39.01 (36.94, 41.01)\n39.98 (37.76, 42.07)\n\n\n    Unknown\n578\n584\n\n\nc_bilirubin_mg_dl_cont\n-0.71 (-1.45, 0.07)\n-0.85 (-1.74, -0.03)\n\n\n    Unknown\n578\n584\n\n\nc_chloride_mmol_l_cont\n102.08 (100.08, 104.20)\n102.05 (100.20, 104.12)\n\n\n    Unknown\n578\n584\n\n\nc_monocytes_10_9_l_cont\n-0.53 (-0.78, -0.24)\n-0.51 (-0.68, -0.35)\n\n\n    Unknown\n578\n584\n\n\nc_eosinophils_leukocytes_ratio_cont\n0.72 (0.50, 0.97)\n0.69 (0.28, 1.07)\n\n\n    Unknown\n578\n584\n\n\nc_ldh_u_l_cont\n1.68 (1.65, 1.71)\n1.69 (1.65, 1.72)\n\n\n    Unknown\n578\n584\n\n\nc_hr_cont\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n\n\n    Unknown\n578\n584\n\n\nc_sbp_cont\n4.85 (4.77, 4.92)\n4.85 (4.79, 4.92)\n\n\n    Unknown\n578\n584\n\n\nc_oxygen_cont\n97.000 (96.986, 97.014)\n97.001 (96.993, 97.007)\n\n\n    Unknown\n578\n584\n\n\nc_neutrophil_lymphocyte_ratio_cont\n1.33 (1.11, 1.56)\n1.28 (1.02, 1.52)\n\n\n    Unknown\n578\n584\n\n\nc_bmi_cont\n3.23 (3.14, 3.31)\n3.23 (3.14, 3.31)\n\n\n    Unknown\n578\n584\n\n\nc_ast_alt_ratio_cont\n0.09 (-0.10, 0.30)\n0.12 (-0.07, 0.32)\n\n\n    Unknown\n578\n584\n\n\nc_time_dx_to_index\n73 (43, 103)\n43 (32, 55)\n\n\n    Unknown\n578\n584\n\n\nc_de_novo_mets_dx\n774 (68%)\n945 (78%)\n\n\n    Unknown\n578\n584\n\n\nc_height_cont\n1.64 (1.59, 1.69)\n1.65 (1.59, 1.70)\n\n\n    Unknown\n578\n584\n\n\nc_weight_cont\n68 (60, 76)\n69 (61, 76)\n\n\n    Unknown\n578\n584\n\n\nc_dbp_cont\n75 (70, 79)\n76 (72, 80)\n\n\n    Unknown\n578\n584\n\n\nc_year_index\n\n\n\n\n\n\n    &lt;2018\n87 (5.1%)\n1,703 (95%)\n\n\n    2018+\n1,625 (95%)\n85 (4.8%)\n\n\ndem_age_index_cont\n70 (63, 76)\n69 (64, 74)\n\n\ndem_sex_cont\n614 (36%)\n569 (32%)\n\n\ndem_race\n664 (59%)\n753 (63%)\n\n\n    Unknown\n578\n584\n\n\ndem_region\n\n\n\n\n\n\n    Midwest\n123 (11%)\n137 (11%)\n\n\n    Northeast\n382 (34%)\n390 (32%)\n\n\n    South\n409 (36%)\n456 (38%)\n\n\n    West\n220 (19%)\n221 (18%)\n\n\n    Unknown\n578\n584\n\n\ndem_ses\n\n\n\n\n\n\n    1\n102 (9.0%)\n217 (18%)\n\n\n    2\n152 (13%)\n157 (13%)\n\n\n    3\n302 (27%)\n210 (17%)\n\n\n    4\n271 (24%)\n291 (24%)\n\n\n    5\n307 (27%)\n329 (27%)\n\n\n    Unknown\n578\n584\n\n\n\n1\nn (%); Median (Q1, Q3)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html#multiple-imputation",
    "href": "01_syvcox_coxph.html#multiple-imputation",
    "title": "2  coxph versus svycoxph",
    "section": "2.2 Multiple imputation",
    "text": "2.2 Multiple imputation\nMultiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "href": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "title": "2  coxph versus svycoxph",
    "section": "2.3 Propensity score matching and weighting",
    "text": "2.3 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset:\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html#outcome-model-comparisons",
    "href": "01_syvcox_coxph.html#outcome-model-comparisons",
    "title": "2  coxph versus svycoxph",
    "section": "2.4 Outcome model comparisons",
    "text": "2.4 Outcome model comparisons\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n2.4.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n2.4.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6809175 0.1662638 0.4841641 0.9576269\n2   survey treat 0.6809175 0.1665147 0.4853937 0.9552010\n\n\n\n\n\n\n2.4.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n2.4.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7646088 0.07472081 0.6598544 0.8859933\n2   survey treat 0.7646088 0.07472930 0.6598863 0.8859505",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html",
    "href": "02_re_weight.html",
    "title": "3  Re-weighting to a target population",
    "section": "",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\nShow the code\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  ) |&gt; \n  # we have to convert sex and ecog into a factor variable \n  # since anesrake doesn't accept 0/1 numeric encoding for \n  # binary variables\n  mutate(across(c(dem_sex_cont, c_ecog_cont), function(x) factor(as.character(x))))\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#multiple-imputation",
    "href": "02_re_weight.html#multiple-imputation",
    "title": "3  Re-weighting to a target population",
    "section": "3.2 Multiple imputation",
    "text": "3.2 Multiple imputation\nMultiple imputation using mice:\n\n\nShow the code\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = 7,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\n\nWarning in check.cores(n.core, available, m): 'n.core' exceeds the maximum\nnumber of available cores on your machine or the number of imputations, and is\nset to 3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#defining-target-distributions",
    "href": "02_re_weight.html#defining-target-distributions",
    "title": "3  Re-weighting to a target population",
    "section": "3.3 Defining target distributions",
    "text": "3.3 Defining target distributions\nBefore applying the re-weighting, we need to define the target distributions of patient characteristics that we want to match from the clinical trial using the raking procedure. The following distributions are taken from Table 1 of the FLAURA trial.\n\n\n\nFLAURA trial Table 1; in OS analysis race was simplified to Asian vs. non-Asian\n\n\n\n\nShow the code\n# Define FLAURA distributions for key covariates --------------------------\n# order is as in Table 1\n\n## sex ---------------------------------------------------------------------\n\n# female (0) to male (1) proportion:\nsex_target &lt;- c(.63, .37) \nnames(sex_target) &lt;- c(\"0\", \"1\")\n\n## race --------------------------------------------------------------------\n# asian, non-asian\n# asian (TRUE) to non-asian (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nrace_target &lt;- c(.62, .38)\n\n## smoking -----------------------------------------------------------------\n\n# current/former smoker (TRUE) to never smoker (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nsmoker_target &lt;- c(.35, .65)\n\n## ecog --------------------------------------------------------------------\n\n# ecog 0 by exposure \navg_prop_ecog0 &lt;- .41\n\n# ecog 0 to ecog 1 proportion\necog_target &lt;- c(.41, .59)\nnames(ecog_target) &lt;- c(\"0\", \"1\")\n\n\n# summarize target distributions in a named list vector --------------\ntargets &lt;- list(sex_target, race_target, smoker_target, ecog_target)\nnames(targets) &lt;- c(\"dem_sex_cont\", \"dem_race\", \"c_smoking_history\", \"c_ecog_cont\")\n\n# print\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "href": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "title": "3  Re-weighting to a target population",
    "section": "3.4 Propensity score matching and re-weighting",
    "text": "3.4 Propensity score matching and re-weighting\nIn this step, propensity score matching and re-weighting of key patient characteristics to match those of the original RCT is performed across all imputed datasets.\nThe propensity score model is specified as follows:\n\n\nShow the code\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\n\ntreat ~ c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index + dem_age_index_cont + \n    dem_sex_cont + dem_race + dem_region + dem_ses\n\n\nThe matching and re-weighting is performed using the re_weight() function. This function is a wrapper for matchit() and weightit() in combination with the anesrake() function which performs the raking (= re-weighting) procedure.\nWe apply this function to each imputed dataset. Before doing so, the imputed datasets, which are currently stored as a mids object, needs to be converted to a list of dataframes:\n\n\nShow the code\n# create a mild object containing lists of data.frames\ndata_mild &lt;- mice::complete(data = data_imp, action = \"all\", include = FALSE)\n\nsummary(data_mild)\n\n\n   Length Class      Mode\n1  39     data.frame list\n2  39     data.frame list\n3  39     data.frame list\n4  39     data.frame list\n5  39     data.frame list\n6  39     data.frame list\n7  39     data.frame list\n8  39     data.frame list\n9  39     data.frame list\n10 39     data.frame list\n\n\nThe lapply function loops the function through each dataframe and returns a list of matchit objects which contain imputed &gt; matched &gt; re-weighted datasets. To take advantage of the features that come with the cobalt and matchthem packages, the function stores the raking weights as sampling weights (s.weights).\n\n\nShow the code\n# call match re-weight\nmatchit_out_list &lt;- lapply(\n  # list of dataframes\n  X = data_mild, \n  # call function\n  FUN = re_weight,\n  # target distributions\n  targets = targets,\n  # should matching or weighting be performed\n  matching_weighting = \"matching\",\n  # matching arguments passed on to matchit() function\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"linear.logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 13 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 13 iterations\"\n[1] \"Raking converged in 13 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 11 iterations\"\n\n\nWe can inspect the output of the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\nmatchit_out_list[[1]]\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression and linearized\n             - sampling weights not included in estimation\n - caliper: &lt;distance&gt; (0.175)\n - number of obs.: 3500 (original), 380 (matched)\n - sampling weights: present\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#table-1",
    "href": "02_re_weight.html#table-1",
    "title": "3  Re-weighting to a target population",
    "section": "3.5 Table 1",
    "text": "3.5 Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\nUnweighted Table 1Weighted Table 1\n\n\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 380\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 190  (50.0%)\n1\n1  N = 190  (50.0%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.03\n\n\n    0\n253 (67%)\n128 (67%)\n125 (66%)\n\n\n\n\n    1\n127 (33%)\n62 (33%)\n65 (34%)\n\n\n\n\ndem_race\n226 (59%)\n106 (56%)\n120 (63%)\n-0.15\n\n\nc_smoking_history\n185 (49%)\n94 (49%)\n91 (48%)\n0.03\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.01\n\n\n    0\n175 (46%)\n88 (46%)\n87 (46%)\n\n\n\n\n    1\n205 (54%)\n102 (54%)\n103 (54%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 380\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 187.36  (49.3%)\n1\n1  N = 192.64  (50.7%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.03\n\n\n    0\n239 (63%)\n119 (64%)\n120 (62%)\n\n\n\n\n    1\n141 (37%)\n68 (36%)\n73 (38%)\n\n\n\n\ndem_race\n236 (62%)\n109 (58%)\n127 (66%)\n-0.16\n\n\nc_smoking_history\n133 (35%)\n68 (36%)\n65 (34%)\n0.06\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.06\n\n\n    0\n156 (41%)\n80 (43%)\n76 (40%)\n\n\n\n\n    1\n224 (59%)\n108 (57%)\n117 (60%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.1 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n3.5.2 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.022)\n - number of obs.: 3500 (original), 376 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.3 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.022)\n - number of obs.: 3500 (original), 376 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.4 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  }
]