[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multiple imputation-propensity score workflows",
    "section": "",
    "text": "Background\nMultiple imputation is a powerful tool in presence of missing data. However, especially in combination with propensity score analyses, multiple imputation can lead to challenges since analytic workflows can be become much more complex.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Objective",
    "text": "Objective\nThis repository showcases and evaluation different multiple imputation &gt; propensity score &gt; outcome analyses and associated implementation challenges."
  },
  {
    "objectID": "index.html#sec-dependencies",
    "href": "index.html#sec-dependencies",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Dependencies",
    "text": "Dependencies\nThis is a quarto book project and R package dependencies are managed through the renv package. All packages and their versions can be viewed in the lockfile renv.lock. All required packages and the appropriate versions can be installed by running the following command:\n\nrenv::restore(repos = \"https://packagemanager.posit.co/cran/latest\")\n\n\n\n\n\n\n\nImportant\n\n\n\nThe dependencies are managed through Posit’s repository package manager (RSPM). If you use a different operating system than macOS, please head over to the RSPM setup website and follow these steps to adjust the URL above.\n\nGo to the RSPM setup website\nChoose the operating system (if Linux, also choose the Linux distribution)\nGo to Repository URL: and copy-paste the URL to the options statement in the .Rprofile file\noptions(repos = c(REPO_NAME = “URL”))"
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Reproducibility",
    "text": "Reproducibility\nFollow these steps in RStudio to reproduce this study:\n\n\n\n\n\n\nNote\n\n\n\n\nClone this repository via git clone &lt;url&gt; or in RStudio via File &gt; New Project &gt; Version Control &gt; Git &gt; then paste the link to repository URL\nInstall all necessary dependencies (see above)\nAdd/adapt the paths to the datasets in .Renviron\nIn RStudio, run all scripts via quarto render or Build &gt; Render Book (make sure quarto is installed)\n\n\n\n\nSteps to clone this repository in RStudio\n\n\n\n\nThe data used in this project is strictly simulated and no real patient-level data is used."
  },
  {
    "objectID": "index.html#repository-structure-and-files",
    "href": "index.html#repository-structure-and-files",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Repository structure and files",
    "text": "Repository structure and files\n\nDirectory overview\n\n\n.\n├── README.md\n├── RStudio_init.png\n├── _book\n│   ├── 01_syvcox_coxph.html\n│   ├── 02_re_weight.html\n│   ├── RStudio_init.png\n│   ├── chapters\n│   ├── index.html\n│   ├── nejm_tbl1.png\n│   ├── search.json\n│   └── site_libs\n├── _quarto.yml\n├── chapters\n│   ├── images\n│   ├── re_weight.md\n│   ├── re_weight.qmd\n│   ├── references.bib\n│   ├── subgroup_analysis.md\n│   ├── subgroup_analysis.qmd\n│   ├── syvcox_coxph.md\n│   ├── syvcox_coxph.qmd\n│   ├── whole_game.md\n│   ├── whole_game.qmd\n│   └── whole_game_files\n├── functions\n│   ├── install_on_demand.R\n│   ├── re_weight.R\n│   ├── simulate_flaura.R\n│   ├── source_encore.io_functions.R\n│   └── subgroup.R\n├── images\n│   ├── leyrat_results.png\n│   ├── mi_ps.png\n│   ├── mice.png\n│   ├── nejm_tbl1.png\n│   └── workflow.png\n├── imputation-ps-workflows.Rproj\n├── index.qmd\n├── index.rmarkdown\n├── index_files\n│   └── execute-results\n├── literature\n│   ├── MatchThem_vignette.pdf\n│   └── leyrat-et-al-2017-propensity-score-analysis-with-partially-observed-covariates-how-should-multiple-imputation-be-used.pdf\n├── references.bib\n├── renv\n│   ├── activate.R\n│   ├── library\n│   ├── settings.json\n│   └── staging\n├── renv.lock\n└── site_libs\n    ├── bootstrap\n    ├── clipboard\n    ├── quarto-html\n    ├── quarto-nav\n    └── quarto-search"
  },
  {
    "objectID": "01_syvcox_coxph.html",
    "href": "01_syvcox_coxph.html",
    "title": "2  coxph versus svycoxph",
    "section": "",
    "text": "2.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()\n\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1,761\n1\n1\nN = 1,739\n1\n\n\n\n\nc_smoking_history\n607 (53%)\n504 (43%)\n\n\n    Unknown\n617\n563\n\n\nc_number_met_sites\n\n\n\n\n\n\n    1\n868 (76%)\n888 (76%)\n\n\n    2\n244 (21%)\n235 (20%)\n\n\n    3\n27 (2.4%)\n45 (3.8%)\n\n\n    4\n4 (0.3%)\n7 (0.6%)\n\n\n    5\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n\n\n    Unknown\n617\n563\n\n\nc_ecog_cont\n697 (61%)\n642 (55%)\n\n\n    Unknown\n617\n563\n\n\nc_stage_initial_dx_cont\n\n\n\n\n\n\n    1\n122 (11%)\n0 (0%)\n\n\n    2\n12 (1.0%)\n16 (1.4%)\n\n\n    3\n20 (1.7%)\n48 (4.1%)\n\n\n    4\n990 (87%)\n1,112 (95%)\n\n\n    Unknown\n617\n563\n\n\nc_hemoglobin_g_dl_cont\n12.95 (12.28, 13.77)\n12.86 (11.91, 13.72)\n\n\n    Unknown\n617\n563\n\n\nc_urea_nitrogen_mg_dl_cont\n2.78 (2.44, 3.11)\n2.76 (2.56, 2.95)\n\n\n    Unknown\n617\n563\n\n\nc_platelets_10_9_l_cont\n257 (216, 293)\n261 (226, 303)\n\n\n    Unknown\n617\n563\n\n\nc_calcium_mg_dl_cont\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n\n\n    Unknown\n617\n563\n\n\nc_glucose_mg_dl_cont\n4.63 (4.56, 4.71)\n4.65 (4.58, 4.73)\n\n\n    Unknown\n617\n563\n\n\nc_lymphocyte_leukocyte_ratio_cont\n2.94 (2.81, 3.07)\n2.93 (2.82, 3.04)\n\n\n    Unknown\n617\n563\n\n\nc_alp_u_l_cont\n4.47 (4.32, 4.61)\n4.51 (4.42, 4.60)\n\n\n    Unknown\n617\n563\n\n\nc_protein_g_l_cont\n68.1 (65.4, 70.8)\n69.0 (66.2, 71.6)\n\n\n    Unknown\n617\n563\n\n\nc_alt_u_l_cont\n2.91 (2.71, 3.10)\n2.89 (2.66, 3.12)\n\n\n    Unknown\n617\n563\n\n\nc_albumin_g_l_cont\n38.94 (36.87, 41.00)\n39.92 (37.90, 41.96)\n\n\n    Unknown\n617\n563\n\n\nc_bilirubin_mg_dl_cont\n-0.65 (-1.46, 0.16)\n-0.93 (-1.75, -0.09)\n\n\n    Unknown\n617\n563\n\n\nc_chloride_mmol_l_cont\n101.93 (100.01, 103.92)\n101.83 (99.82, 104.21)\n\n\n    Unknown\n617\n563\n\n\nc_monocytes_10_9_l_cont\n-0.49 (-0.76, -0.24)\n-0.49 (-0.67, -0.34)\n\n\n    Unknown\n617\n563\n\n\nc_eosinophils_leukocytes_ratio_cont\n0.72 (0.50, 0.96)\n0.67 (0.28, 1.07)\n\n\n    Unknown\n617\n563\n\n\nc_ldh_u_l_cont\n1.68 (1.65, 1.70)\n1.69 (1.65, 1.72)\n\n\n    Unknown\n617\n563\n\n\nc_hr_cont\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n\n\n    Unknown\n617\n563\n\n\nc_sbp_cont\n4.86 (4.78, 4.93)\n4.85 (4.79, 4.91)\n\n\n    Unknown\n617\n563\n\n\nc_oxygen_cont\n97.000 (96.985, 97.014)\n96.999 (96.992, 97.006)\n\n\n    Unknown\n617\n563\n\n\nc_neutrophil_lymphocyte_ratio_cont\n1.30 (1.05, 1.54)\n1.29 (1.06, 1.52)\n\n\n    Unknown\n617\n563\n\n\nc_bmi_cont\n3.23 (3.14, 3.32)\n3.24 (3.15, 3.32)\n\n\n    Unknown\n617\n563\n\n\nc_ast_alt_ratio_cont\n0.10 (-0.11, 0.31)\n0.12 (-0.08, 0.32)\n\n\n    Unknown\n617\n563\n\n\nc_time_dx_to_index\n73 (43, 102)\n44 (33, 55)\n\n\n    Unknown\n617\n563\n\n\nc_de_novo_mets_dx\n772 (67%)\n922 (78%)\n\n\n    Unknown\n617\n563\n\n\nc_height_cont\n1.64 (1.60, 1.69)\n1.65 (1.59, 1.70)\n\n\n    Unknown\n617\n563\n\n\nc_weight_cont\n68 (60, 76)\n69 (61, 76)\n\n\n    Unknown\n617\n563\n\n\nc_dbp_cont\n75 (70, 80)\n76 (72, 80)\n\n\n    Unknown\n617\n563\n\n\nc_year_index\n\n\n\n\n\n\n    &lt;2018\n91 (5.2%)\n1,639 (94%)\n\n\n    2018+\n1,670 (95%)\n100 (5.8%)\n\n\ndem_age_index_cont\n70 (64, 76)\n69 (64, 75)\n\n\ndem_sex_cont\n605 (34%)\n598 (34%)\n\n\ndem_race\n\n\n\n\n\n\n    Asian\n137 (12%)\n154 (13%)\n\n\n    Other\n320 (28%)\n355 (30%)\n\n\n    White\n687 (60%)\n667 (57%)\n\n\n    Unknown\n617\n563\n\n\ndem_region\n\n\n\n\n\n\n    Midwest\n117 (10%)\n160 (14%)\n\n\n    Northeast\n391 (34%)\n340 (29%)\n\n\n    South\n424 (37%)\n477 (41%)\n\n\n    West\n212 (19%)\n199 (17%)\n\n\n    Unknown\n617\n563\n\n\ndem_ses\n\n\n\n\n\n\n    1\n138 (12%)\n198 (17%)\n\n\n    2\n156 (14%)\n173 (15%)\n\n\n    3\n299 (26%)\n223 (19%)\n\n\n    4\n245 (21%)\n256 (22%)\n\n\n    5\n306 (27%)\n326 (28%)\n\n\n    Unknown\n617\n563\n\n\n\n1\nn (%); Median (Q1, Q3)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html#multiple-imputation",
    "href": "01_syvcox_coxph.html#multiple-imputation",
    "title": "2  coxph versus svycoxph",
    "section": "2.2 Multiple imputation",
    "text": "2.2 Multiple imputation\nMultiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )"
  },
  {
    "objectID": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "href": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "title": "2  coxph versus svycoxph",
    "section": "2.3 Propensity score matching and weighting",
    "text": "2.3 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset:\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )"
  },
  {
    "objectID": "01_syvcox_coxph.html#outcome-model-comparisons",
    "href": "01_syvcox_coxph.html#outcome-model-comparisons",
    "title": "2  coxph versus svycoxph",
    "section": "2.4 Outcome model comparisons",
    "text": "2.4 Outcome model comparisons\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n2.4.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n2.4.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n2.4.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n2.4.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  },
  {
    "objectID": "01_syvcox_coxph.html#data-generation",
    "href": "01_syvcox_coxph.html#data-generation",
    "title": "2  coxph versus svycoxph",
    "section": "2.1 Data generation",
    "text": "2.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()\n\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    )\n\n\n\n\n\n  \n    \n      Characteristic\n\n      0\nN = 1,712\n1\n      1\nN = 1,788\n1\n    \n  \n  \n    c_smoking_history\n579 (51%)\n520 (43%)\n        Unknown\n578\n584\n    c_number_met_sites\n\n\n        1\n837 (74%)\n899 (75%)\n        2\n249 (22%)\n255 (21%)\n        3\n41 (3.6%)\n42 (3.5%)\n        4\n7 (0.6%)\n8 (0.7%)\n        Unknown\n578\n584\n    c_ecog_cont\n714 (63%)\n637 (53%)\n        Unknown\n578\n584\n    c_stage_initial_dx_cont\n\n\n        1\n101 (8.9%)\n0 (0%)\n        2\n17 (1.5%)\n12 (1.0%)\n        3\n15 (1.3%)\n38 (3.2%)\n        4\n1,001 (88%)\n1,154 (96%)\n        Unknown\n578\n584\n    c_hemoglobin_g_dl_cont\n12.97 (12.16, 13.72)\n12.89 (11.98, 13.75)\n        Unknown\n578\n584\n    c_urea_nitrogen_mg_dl_cont\n2.76 (2.42, 3.08)\n2.77 (2.58, 2.97)\n        Unknown\n578\n584\n    c_platelets_10_9_l_cont\n255 (218, 290)\n266 (230, 302)\n        Unknown\n578\n584\n    c_calcium_mg_dl_cont\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n        Unknown\n578\n584\n    c_glucose_mg_dl_cont\n4.64 (4.55, 4.72)\n4.65 (4.58, 4.73)\n        Unknown\n578\n584\n    c_lymphocyte_leukocyte_ratio_cont\n2.94 (2.81, 3.08)\n2.93 (2.82, 3.04)\n        Unknown\n578\n584\n    c_alp_u_l_cont\n4.47 (4.33, 4.61)\n4.51 (4.42, 4.59)\n        Unknown\n578\n584\n    c_protein_g_l_cont\n67.8 (65.1, 70.6)\n69.0 (66.0, 72.1)\n        Unknown\n578\n584\n    c_alt_u_l_cont\n2.93 (2.72, 3.14)\n2.86 (2.64, 3.10)\n        Unknown\n578\n584\n    c_albumin_g_l_cont\n39.01 (36.94, 41.01)\n39.98 (37.76, 42.07)\n        Unknown\n578\n584\n    c_bilirubin_mg_dl_cont\n-0.71 (-1.45, 0.07)\n-0.85 (-1.74, -0.03)\n        Unknown\n578\n584\n    c_chloride_mmol_l_cont\n102.08 (100.08, 104.20)\n102.05 (100.20, 104.12)\n        Unknown\n578\n584\n    c_monocytes_10_9_l_cont\n-0.53 (-0.78, -0.24)\n-0.51 (-0.68, -0.35)\n        Unknown\n578\n584\n    c_eosinophils_leukocytes_ratio_cont\n0.72 (0.50, 0.97)\n0.69 (0.28, 1.07)\n        Unknown\n578\n584\n    c_ldh_u_l_cont\n1.68 (1.65, 1.71)\n1.69 (1.65, 1.72)\n        Unknown\n578\n584\n    c_hr_cont\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n        Unknown\n578\n584\n    c_sbp_cont\n4.85 (4.77, 4.92)\n4.85 (4.79, 4.92)\n        Unknown\n578\n584\n    c_oxygen_cont\n97.000 (96.986, 97.014)\n97.001 (96.993, 97.007)\n        Unknown\n578\n584\n    c_neutrophil_lymphocyte_ratio_cont\n1.33 (1.11, 1.56)\n1.28 (1.02, 1.52)\n        Unknown\n578\n584\n    c_bmi_cont\n3.23 (3.14, 3.31)\n3.23 (3.14, 3.31)\n        Unknown\n578\n584\n    c_ast_alt_ratio_cont\n0.09 (-0.10, 0.30)\n0.12 (-0.07, 0.32)\n        Unknown\n578\n584\n    c_time_dx_to_index\n73 (43, 103)\n43 (32, 55)\n        Unknown\n578\n584\n    c_de_novo_mets_dx\n774 (68%)\n945 (78%)\n        Unknown\n578\n584\n    c_height_cont\n1.64 (1.59, 1.69)\n1.65 (1.59, 1.70)\n        Unknown\n578\n584\n    c_weight_cont\n68 (60, 76)\n69 (61, 76)\n        Unknown\n578\n584\n    c_dbp_cont\n75 (70, 79)\n76 (72, 80)\n        Unknown\n578\n584\n    c_year_index\n\n\n        &lt;2018\n87 (5.1%)\n1,703 (95%)\n        2018+\n1,625 (95%)\n85 (4.8%)\n    dem_age_index_cont\n70 (63, 76)\n69 (64, 74)\n    dem_sex_cont\n614 (36%)\n569 (32%)\n    dem_race\n664 (59%)\n753 (63%)\n        Unknown\n578\n584\n    dem_region\n\n\n        Midwest\n123 (11%)\n137 (11%)\n        Northeast\n382 (34%)\n390 (32%)\n        South\n409 (36%)\n456 (38%)\n        West\n220 (19%)\n221 (18%)\n        Unknown\n578\n584\n    dem_ses\n\n\n        1\n102 (9.0%)\n217 (18%)\n        2\n152 (13%)\n157 (13%)\n        3\n302 (27%)\n210 (17%)\n        4\n271 (24%)\n291 (24%)\n        5\n307 (27%)\n329 (27%)\n        Unknown\n578\n584\n  \n  \n  \n    \n      1 n (%); Median (Q1, Q3)"
  },
  {
    "objectID": "02_re_weight.html",
    "href": "02_re_weight.html",
    "title": "3  Re-weighting to a target population",
    "section": "",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\nShow the code\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  ) |&gt; \n  # we have to convert sex and ecog into a factor variable \n  # since anesrake doesn't accept 0/1 numeric encoding for \n  # binary variables\n  mutate(across(c(dem_sex_cont, c_ecog_cont), function(x) factor(as.character(x))))\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#multiple-imputation",
    "href": "02_re_weight.html#multiple-imputation",
    "title": "3  Re-weighting to a target population",
    "section": "3.2 Multiple imputation",
    "text": "3.2 Multiple imputation\nMultiple imputation using mice:\n\n\nShow the code\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = 7,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#defining-target-distributions",
    "href": "02_re_weight.html#defining-target-distributions",
    "title": "3  Re-weighting to a target population",
    "section": "3.3 Defining target distributions",
    "text": "3.3 Defining target distributions\nBefore applying the re-weighting, we need to define the target distributions of patient characteristics that we want to match from the clinical trial using the raking procedure. The following distributions are taken from Table 1 of the FLAURA trial.\n\n\n\nFLAURA trial Table 1; in OS analysis race was simplified to Asian vs. non-Asian\n\n\n\n\nShow the code\n# Define FLAURA distributions for key covariates --------------------------\n# order is as in Table 1\n\n## sex ---------------------------------------------------------------------\n\n# female (0) to male (1) proportion:\nsex_target &lt;- c(.63, .37) \nnames(sex_target) &lt;- c(\"0\", \"1\")\n\n## race --------------------------------------------------------------------\n# asian, non-asian\n# asian (TRUE) to non-asian (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nrace_target &lt;- c(.62, .38)\n\n## smoking -----------------------------------------------------------------\n\n# current/former smoker (TRUE) to never smoker (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nsmoker_target &lt;- c(.35, .65)\n\n## ecog --------------------------------------------------------------------\n\n# ecog 0 by exposure \navg_prop_ecog0 &lt;- .41\n\n# ecog 0 to ecog 1 proportion\necog_target &lt;- c(.41, .59)\nnames(ecog_target) &lt;- c(\"0\", \"1\")\n\n\n# summarize target distributions in a named list vector --------------\ntargets &lt;- list(sex_target, race_target, smoker_target, ecog_target)\nnames(targets) &lt;- c(\"dem_sex_cont\", \"dem_race\", \"c_smoking_history\", \"c_ecog_cont\")\n\n# print\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "href": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "title": "3  Re-weighting to a target population",
    "section": "3.4 Propensity score matching and re-weighting",
    "text": "3.4 Propensity score matching and re-weighting\nIn this step, propensity score matching and re-weighting of key patient characteristics to match those of the original RCT is performed across all imputed datasets.\nThe propensity score model is specified as follows:\n\n\nShow the code\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\n\ntreat ~ c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index + dem_age_index_cont + \n    dem_sex_cont + dem_race + dem_region + dem_ses\n\n\nThe matching and re-weighting is performed using the re_weight() function. This function is a wrapper for matchit() and weightit() in combination with the anesrake() function which performs the raking (= re-weighting) procedure.\nWe apply this function to each imputed dataset. Before doing so, the imputed datasets, which are currently stored as a mids object, needs to be converted to a list of dataframes:\n\n\nShow the code\n# create a mild object containing lists of data.frames\ndata_mild &lt;- mice::complete(data = data_imp, action = \"all\", include = FALSE)\n\nsummary(data_mild)\n\n\n   Length Class      Mode\n1  39     data.frame list\n2  39     data.frame list\n3  39     data.frame list\n4  39     data.frame list\n5  39     data.frame list\n6  39     data.frame list\n7  39     data.frame list\n8  39     data.frame list\n9  39     data.frame list\n10 39     data.frame list\n\n\nThe lapply function loops the function through each dataframe and returns a list of matchit objects which contain imputed &gt; matched &gt; re-weighted datasets. To take advantage of the features that come with the cobalt and matchthem packages, the function stores the raking weights as sampling weights (s.weights).\n\n\nShow the code\n# call match re-weight\nmatchit_out_list &lt;- lapply(\n  # list of dataframes\n  X = data_mild, \n  # call function\n  FUN = re_weight,\n  # target distributions\n  targets = targets,\n  # should matching or weighting be performed\n  matching_weighting = \"matching\",\n  # matching arguments passed on to matchit() function\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"linear.logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n[1] \"Raking converged in 15 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 14 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 16 iterations\"\n[1] \"Raking converged in 12 iterations\"\n\n\nWe can inspect the output of the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\nmatchit_out_list[[1]]\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression and linearized\n             - sampling weights not included in estimation\n - caliper: &lt;distance&gt; (0.179)\n - number of obs.: 3500 (original), 366 (matched)\n - sampling weights: present\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#unweighted-table-1",
    "href": "02_re_weight.html#unweighted-table-1",
    "title": "3  Re-weighting to a target population",
    "section": "3.5 (Un)weighted Table 1",
    "text": "3.5 (Un)weighted Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\n\n3.5.1 Unweighted Table 1\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 183  (50.0%)\n1\n1  N = 183  (50.0%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.06\n\n\n    0\n247 (67%)\n121 (66%)\n126 (69%)\n\n\n\n\n    1\n119 (33%)\n62 (34%)\n57 (31%)\n\n\n\n\ndem_race\n217 (59%)\n105 (57%)\n112 (61%)\n-0.08\n\n\nc_smoking_history\n179 (49%)\n91 (50%)\n88 (48%)\n0.03\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.15\n\n\n    0\n160 (44%)\n73 (40%)\n87 (48%)\n\n\n\n\n    1\n206 (56%)\n110 (60%)\n96 (52%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n3.5.2 Weighted Table 1\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 182.18  (49.8%)\n1\n1  N = 183.82  (50.2%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.04\n\n\n    0\n231 (63%)\n113 (62%)\n117 (64%)\n\n\n\n\n    1\n135 (37%)\n69 (38%)\n66 (36%)\n\n\n\n\ndem_race\n227 (62%)\n110 (61%)\n117 (63%)\n-0.06\n\n\nc_smoking_history\n128 (35%)\n66 (36%)\n62 (34%)\n0.05\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.07\n\n\n    0\n150 (41%)\n72 (39%)\n78 (43%)\n\n\n\n\n    1\n216 (59%)\n111 (61%)\n105 (57%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n3.5.4 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.5 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.6 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#table-1",
    "href": "02_re_weight.html#table-1",
    "title": "3  Re-weighting to a target population",
    "section": "3.5 Table 1",
    "text": "3.5 Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\nUnweighted Table 1Weighted Table 1\n\n\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 183  (50.0%)\n1\n1  N = 183  (50.0%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.06\n\n\n    0\n247 (67%)\n121 (66%)\n126 (69%)\n\n\n\n\n    1\n119 (33%)\n62 (34%)\n57 (31%)\n\n\n\n\ndem_race\n217 (59%)\n105 (57%)\n112 (61%)\n-0.08\n\n\nc_smoking_history\n179 (49%)\n91 (50%)\n88 (48%)\n0.03\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.15\n\n\n    0\n160 (44%)\n73 (40%)\n87 (48%)\n\n\n\n\n    1\n206 (56%)\n110 (60%)\n96 (52%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 182.18  (49.8%)\n1\n1  N = 183.82  (50.2%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.04\n\n\n    0\n231 (63%)\n113 (62%)\n117 (64%)\n\n\n\n\n    1\n135 (37%)\n69 (38%)\n66 (36%)\n\n\n\n\ndem_race\n227 (62%)\n110 (61%)\n117 (63%)\n-0.06\n\n\nc_smoking_history\n128 (35%)\n66 (36%)\n62 (34%)\n0.05\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.07\n\n\n    0\n150 (41%)\n72 (39%)\n78 (43%)\n\n\n\n\n    1\n216 (59%)\n111 (61%)\n105 (57%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.1 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n3.5.2 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.3 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.4 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#data-generation",
    "href": "chapters/syvcox_coxph.html#data-generation",
    "title": "3  Application in Cox PH models",
    "section": "3.1 Data generation",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness analytic cohort dataset with similar distributions to FLAURA, a randomized controlled trial that evaluated the efficacy and safety of osimertinib to standard-of-care (SoC) tyrosine kinase inhibitors (TKIs) in advanced NSCLC patients with a sensitizing EGFR mutation.\nThe following cohort resembles distributions observed in the EHR-derived EDB1dataset used in ENCORE. Note: the values of some continuous covariates (labs) are displayed after log/log-log transformation.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\n# store covariates\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"dem_\"), starts_with(\"c_\")) |&gt; \n  colnames()\n\n# crate Table 1\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    ) |&gt; \n  add_overall() |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {N}\",\n    stat_1 ~ \"**Comparator** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**Exposure** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt; \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\") |&gt; \n  modify_caption(\"**Table 1. Patient Characteristics**\")\n\n\n\n\n\n  Table 1. Patient Characteristics\n\n  \n    \n      Patient characteristic\n\n      Total  N = 3500\n1\n      \n        Treatment received\n\n      \n    \n    \n      Comparator  N = 1712  (48.9%)\n1\n      Exposure  N = 1788  (51.1%)\n1\n    \n  \n  \n    dem_age_index_cont\n69 (64, 75)\n70 (63, 76)\n69 (64, 74)\n    dem_sex_cont\n1,183 (34%)\n614 (36%)\n569 (32%)\n    dem_race\n1,417 (61%)\n664 (59%)\n753 (63%)\n        Unknown\n1,162\n578\n584\n    dem_region\n\n\n\n        Midwest\n260 (11%)\n123 (11%)\n137 (11%)\n        Northeast\n772 (33%)\n382 (34%)\n390 (32%)\n        South\n865 (37%)\n409 (36%)\n456 (38%)\n        West\n441 (19%)\n220 (19%)\n221 (18%)\n        Unknown\n1,162\n578\n584\n    dem_ses\n\n\n\n        1\n319 (14%)\n102 (9.0%)\n217 (18%)\n        2\n309 (13%)\n152 (13%)\n157 (13%)\n        3\n512 (22%)\n302 (27%)\n210 (17%)\n        4\n562 (24%)\n271 (24%)\n291 (24%)\n        5\n636 (27%)\n307 (27%)\n329 (27%)\n        Unknown\n1,162\n578\n584\n    c_smoking_history\n1,099 (47%)\n579 (51%)\n520 (43%)\n        Unknown\n1,162\n578\n584\n    c_number_met_sites\n\n\n\n        1\n1,736 (74%)\n837 (74%)\n899 (75%)\n        2\n504 (22%)\n249 (22%)\n255 (21%)\n        3\n83 (3.6%)\n41 (3.6%)\n42 (3.5%)\n        4\n15 (0.6%)\n7 (0.6%)\n8 (0.7%)\n        Unknown\n1,162\n578\n584\n    c_ecog_cont\n1,351 (58%)\n714 (63%)\n637 (53%)\n        Unknown\n1,162\n578\n584\n    c_stage_initial_dx_cont\n\n\n\n        1\n101 (4.3%)\n101 (8.9%)\n0 (0%)\n        2\n29 (1.2%)\n17 (1.5%)\n12 (1.0%)\n        3\n53 (2.3%)\n15 (1.3%)\n38 (3.2%)\n        4\n2,155 (92%)\n1,001 (88%)\n1,154 (96%)\n        Unknown\n1,162\n578\n584\n    c_hemoglobin_g_dl_cont\n12.92 (12.09, 13.74)\n12.97 (12.16, 13.72)\n12.89 (11.98, 13.75)\n        Unknown\n1,162\n578\n584\n    c_urea_nitrogen_mg_dl_cont\n2.77 (2.53, 3.02)\n2.76 (2.42, 3.08)\n2.77 (2.58, 2.97)\n        Unknown\n1,162\n578\n584\n    c_platelets_10_9_l_cont\n261 (224, 297)\n255 (218, 290)\n266 (230, 302)\n        Unknown\n1,162\n578\n584\n    c_calcium_mg_dl_cont\n2.23 (2.21, 2.26)\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n        Unknown\n1,162\n578\n584\n    c_glucose_mg_dl_cont\n4.65 (4.57, 4.73)\n4.64 (4.55, 4.72)\n4.65 (4.58, 4.73)\n        Unknown\n1,162\n578\n584\n    c_lymphocyte_leukocyte_ratio_cont\n2.93 (2.81, 3.06)\n2.94 (2.81, 3.08)\n2.93 (2.82, 3.04)\n        Unknown\n1,162\n578\n584\n    c_alp_u_l_cont\n4.49 (4.39, 4.60)\n4.47 (4.33, 4.61)\n4.51 (4.42, 4.59)\n        Unknown\n1,162\n578\n584\n    c_protein_g_l_cont\n68.4 (65.6, 71.4)\n67.8 (65.1, 70.6)\n69.0 (66.0, 72.1)\n        Unknown\n1,162\n578\n584\n    c_alt_u_l_cont\n2.90 (2.69, 3.12)\n2.93 (2.72, 3.14)\n2.86 (2.64, 3.10)\n        Unknown\n1,162\n578\n584\n    c_albumin_g_l_cont\n39.51 (37.33, 41.58)\n39.01 (36.94, 41.01)\n39.98 (37.76, 42.07)\n        Unknown\n1,162\n578\n584\n    c_bilirubin_mg_dl_cont\n-0.79 (-1.58, 0.01)\n-0.71 (-1.45, 0.07)\n-0.85 (-1.74, -0.03)\n        Unknown\n1,162\n578\n584\n    c_chloride_mmol_l_cont\n102.07 (100.11, 104.14)\n102.08 (100.08, 104.20)\n102.05 (100.20, 104.12)\n        Unknown\n1,162\n578\n584\n    c_monocytes_10_9_l_cont\n-0.51 (-0.73, -0.31)\n-0.53 (-0.78, -0.24)\n-0.51 (-0.68, -0.35)\n        Unknown\n1,162\n578\n584\n    c_eosinophils_leukocytes_ratio_cont\n0.71 (0.40, 1.02)\n0.72 (0.50, 0.97)\n0.69 (0.28, 1.07)\n        Unknown\n1,162\n578\n584\n    c_ldh_u_l_cont\n1.68 (1.65, 1.72)\n1.68 (1.65, 1.71)\n1.69 (1.65, 1.72)\n        Unknown\n1,162\n578\n584\n    c_hr_cont\n4.42 (4.40, 4.44)\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n        Unknown\n1,162\n578\n584\n    c_sbp_cont\n4.85 (4.78, 4.92)\n4.85 (4.77, 4.92)\n4.85 (4.79, 4.92)\n        Unknown\n1,162\n578\n584\n    c_oxygen_cont\n97.001 (96.991, 97.009)\n97.000 (96.986, 97.014)\n97.001 (96.993, 97.007)\n        Unknown\n1,162\n578\n584\n    c_neutrophil_lymphocyte_ratio_cont\n1.31 (1.07, 1.54)\n1.33 (1.11, 1.56)\n1.28 (1.02, 1.52)\n        Unknown\n1,162\n578\n584\n    c_bmi_cont\n3.23 (3.14, 3.31)\n3.23 (3.14, 3.31)\n3.23 (3.14, 3.31)\n        Unknown\n1,162\n578\n584\n    c_ast_alt_ratio_cont\n0.10 (-0.09, 0.31)\n0.09 (-0.10, 0.30)\n0.12 (-0.07, 0.32)\n        Unknown\n1,162\n578\n584\n    c_time_dx_to_index\n52 (35, 75)\n73 (43, 103)\n43 (32, 55)\n        Unknown\n1,162\n578\n584\n    c_de_novo_mets_dx\n1,719 (74%)\n774 (68%)\n945 (78%)\n        Unknown\n1,162\n578\n584\n    c_height_cont\n1.65 (1.59, 1.70)\n1.64 (1.59, 1.69)\n1.65 (1.59, 1.70)\n        Unknown\n1,162\n578\n584\n    c_weight_cont\n68 (60, 76)\n68 (60, 76)\n69 (61, 76)\n        Unknown\n1,162\n578\n584\n    c_dbp_cont\n75 (71, 80)\n75 (70, 79)\n76 (72, 80)\n        Unknown\n1,162\n578\n584\n    c_year_index\n\n\n\n        &lt;2018\n1,790 (51%)\n87 (5.1%)\n1,703 (95%)\n        2018+\n1,710 (49%)\n1,625 (95%)\n85 (4.8%)\n  \n  \n  \n    \n      1 Median (Q1, Q3); n (%)"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#multiple-imputation",
    "href": "chapters/syvcox_coxph.html#multiple-imputation",
    "title": "3  Application in Cox PH models",
    "section": "3.3 Multiple imputation",
    "text": "3.3 Multiple imputation\nMultiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#propensity-score-matching-and-weighting",
    "href": "chapters/syvcox_coxph.html#propensity-score-matching-and-weighting",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Propensity score matching and weighting",
    "text": "3.4 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset:\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#outcome-model-comparisons",
    "href": "chapters/syvcox_coxph.html#outcome-model-comparisons",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Outcome model comparisons",
    "text": "3.4 Outcome model comparisons\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n3.4.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.4.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n3.4.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n3.4.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.4.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n3.4.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#session-info",
    "href": "chapters/syvcox_coxph.html#session-info",
    "title": "3  Application in Cox PH models",
    "section": "3.6 Session info",
    "text": "3.6 Session info\nScript runtime: 0.39 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ndplyr\ndplyr\n1.1.4\n\n\nfurrr\nfurrr\n0.3.1\n\n\nfuture\nfuture\n1.34.0\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nparallelly\nparallelly\n1.38.0\n\n\nranger\nranger\n0.16.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: furrr(v.0.3.1), future(v.1.34.0), ranger(v.0.16.0), parallelly(v.1.38.0), gtsummary(v.2.0.1), here(v.1.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8) and dplyr(v.1.1.4)\nloaded via a namespace (and not attached): tidyselect(v.1.2.1), fastmap(v.1.2.0), digest(v.0.6.37), rpart(v.4.1.23), lifecycle(v.1.0.4), magrittr(v.2.0.3), compiler(v.4.4.0), rlang(v.1.1.4), sass(v.0.4.9), tools(v.4.4.0), utf8(v.1.2.4), yaml(v.2.3.10), gt(v.0.11.0), knitr(v.1.48), htmlwidgets(v.1.6.4), xml2(v.1.3.6), withr(v.3.0.1), purrr(v.1.0.2), nnet(v.7.3-19), fansi(v.1.0.6), jomo(v.2.7-6), colorspace(v.2.1-1), ggplot2(v.3.5.1), globals(v.0.16.3), scales(v.1.3.0), iterators(v.1.0.14), MASS(v.7.3-60.2), cli(v.3.6.3), rmarkdown(v.2.28), crayon(v.1.5.3), generics(v.0.1.3), rstudioapi(v.0.16.0), sessioninfo(v.1.2.2), commonmark(v.1.9.1), minqa(v.1.2.8), DBI(v.1.2.3), pander(v.0.6.5), stringr(v.1.5.1), splines(v.4.4.0), assertthat(v.0.2.1), parallel(v.4.4.0), base64enc(v.0.1-3), mitools(v.2.4), vctrs(v.0.6.5), WeightIt(v.1.3.0), boot(v.1.3-30), glmnet(v.4.1-8), jsonlite(v.1.8.8), mitml(v.0.4-5), listenv(v.0.9.1), foreach(v.1.5.2), tidyr(v.1.3.1), glue(v.1.7.0), nloptr(v.2.1.1), pan(v.1.9), chk(v.0.9.2), codetools(v.0.2-20), stringi(v.1.8.4), shape(v.1.4.6.1), gtable(v.0.3.5), lme4(v.1.1-35.5), munsell(v.0.5.1), tibble(v.3.2.1), pillar(v.1.9.0), htmltools(v.0.5.8.1), R6(v.2.5.1), rprojroot(v.2.0.4), evaluate(v.0.24.0), lattice(v.0.22-6), markdown(v.1.13), backports(v.1.5.0), cards(v.0.2.1), tictoc(v.1.2.1), MatchIt(v.4.5.5), broom(v.1.0.6), renv(v.1.0.7), simsurv(v.1.0.0), Rcpp(v.1.0.13), nlme(v.3.1-164), xfun(v.0.47) and pkgconfig(v.2.0.3)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#section",
    "href": "chapters/syvcox_coxph.html#section",
    "title": "3  Application in Cox PH models",
    "section": "3.7 ",
    "text": "3.7 \n\n\n\n\n\n\nBuuren, Stef van, and Karin Groothuis-Oudshoorn. 2011. “Mice: Multivariate Imputation by Chained Equations in r” 45: 1–67. https://doi.org/10.18637/jss.v045.i03.\n\n\nLumley, Thomas. 2024. “Survey: Analysis of Complex Survey Samples.”\n\n\nPishgar, Farhad, Noah Greifer, Clémence Leyrat, and Elizabeth Stuart. 2021. “MatchThem: Matching and Weighting after Multiple Imputation.” R Journal 13 (2): 292–305. https://doi.org/10.32614/RJ-2021-073.\n\n\nShah, Anoop D., Jonathan W. Bartlett, James Carpenter, Owen Nicholas, and Harry Hemingway. 2014. “Comparison of random forest and parametric imputation models for imputing missing data using MICE: a CALIBER study.” American Journal of Epidemiology 179 (6): 764–74. https://doi.org/10.1093/aje/kwt312.\n\n\nStekhoven, Daniel J., and Peter Bühlmann. 2012. “MissForestnon-Parametric Missing Value Imputation for Mixed-Type Data.” Bioinformatics 28 (1): 112–18. https://doi.org/10.1093/bioinformatics/btr597.\n\n\nTherneau, Terry M. 2024. “A Package for Survival Analysis in r.” https://CRAN.R-project.org/package=survival.\n\n\nWeberpals, Janick, Sudha Raman, Pamela Shaw, Hana Lee, Massimiliano Russo, Bradley Hammill, Sengwee Toh, et al. 2024. “A Principled Approach to Characterize and Analyze Partially Observed Confounder Data from Electronic Health Records.” Clinical Epidemiology Volume 16 (May): 329–43. https://doi.org/10.2147/clep.s436131."
  },
  {
    "objectID": "chapters/re_weight.html#data-generation",
    "href": "chapters/re_weight.html#data-generation",
    "title": "4  Re-weighting to a target population",
    "section": "4.1 Data generation",
    "text": "4.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n\nCode\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  ) |&gt; \n  # we have to convert sex and ecog into a factor variable \n  # since anesrake doesn't accept 0/1 numeric encoding for \n  # binary variables\n  mutate(across(c(dem_sex_cont, c_ecog_cont), function(x) factor(as.character(x))))\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"dem_\"), starts_with(\"c_\")) |&gt; \n  colnames()"
  },
  {
    "objectID": "chapters/re_weight.html#multiple-imputation",
    "href": "chapters/re_weight.html#multiple-imputation",
    "title": "4  Re-weighting to a target population",
    "section": "4.2 Multiple imputation",
    "text": "4.2 Multiple imputation\nMultiple imputation using mice:\n\n\nCode\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = 7,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )"
  },
  {
    "objectID": "chapters/re_weight.html#defining-target-distributions",
    "href": "chapters/re_weight.html#defining-target-distributions",
    "title": "4  Re-weighting to a target population",
    "section": "4.3 Defining target distributions",
    "text": "4.3 Defining target distributions\nBefore applying the re-weighting, we need to define the target distributions of patient characteristics that we want to match from the clinical trial using the raking procedure. The following distributions are taken from Table 1 of the FLAURA trial.\n\n\n\nFLAURA trial Table 1; in OS analysis race was simplified to Asian vs. non-Asian\n\n\n\n\nCode\n# Define FLAURA distributions for key covariates --------------------------\n# order is as in Table 1\n\n## sex ---------------------------------------------------------------------\n\n# female (0) to male (1) proportion:\nsex_target &lt;- c(.63, .37) \nnames(sex_target) &lt;- c(\"0\", \"1\")\n\n## race --------------------------------------------------------------------\n# asian, non-asian\n# asian (TRUE) to non-asian (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nrace_target &lt;- c(.62, .38)\n\n## smoking -----------------------------------------------------------------\n\n# current/former smoker (TRUE) to never smoker (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nsmoker_target &lt;- c(.35, .65)\n\n## ecog --------------------------------------------------------------------\n\n# ecog 0 by exposure \navg_prop_ecog0 &lt;- .41\n\n# ecog 0 to ecog 1 proportion\necog_target &lt;- c(.41, .59)\nnames(ecog_target) &lt;- c(\"0\", \"1\")\n\n\n# summarize target distributions in a named list vector --------------\ntargets &lt;- list(sex_target, race_target, smoker_target, ecog_target)\nnames(targets) &lt;- c(\"dem_sex_cont\", \"dem_race\", \"c_smoking_history\", \"c_ecog_cont\")\n\n# print\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59"
  },
  {
    "objectID": "chapters/re_weight.html#propensity-score-matching-and-re-weighting",
    "href": "chapters/re_weight.html#propensity-score-matching-and-re-weighting",
    "title": "4  Re-weighting to a target population",
    "section": "4.4 Propensity score matching and re-weighting",
    "text": "4.4 Propensity score matching and re-weighting\nIn this step, propensity score matching and re-weighting of key patient characteristics to match those of the original RCT is performed across all imputed datasets.\nThe propensity score model is specified as follows:\n\n\nCode\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\n\ntreat ~ dem_age_index_cont + dem_sex_cont + dem_race + dem_region + \n    dem_ses + c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index\n\n\nThe matching and re-weighting is performed using the re_weight() function. This function is a wrapper for matchit() and weightit() in combination with the anesrake() function which performs the raking (= re-weighting) procedure.\nWe apply this function to each imputed dataset. Before doing so, the imputed datasets, which are currently stored as a mids object, needs to be converted to a list of dataframes:\n\n\nCode\n# create a mild object containing lists of data.frames\ndata_mild &lt;- mice::complete(data = data_imp, action = \"all\", include = FALSE)\n\nsummary(data_mild)\n\n\n   Length Class      Mode\n1  39     data.frame list\n2  39     data.frame list\n3  39     data.frame list\n4  39     data.frame list\n5  39     data.frame list\n6  39     data.frame list\n7  39     data.frame list\n8  39     data.frame list\n9  39     data.frame list\n10 39     data.frame list\n\n\nThe lapply function loops the function through each dataframe and returns a list of matchit objects which contain imputed &gt; matched &gt; re-weighted datasets. To take advantage of the features that come with the cobalt and matchthem packages, the function stores the raking weights as sampling weights (s.weights).\n\n\nCode\n# call match re-weight\nmatchit_out_list &lt;- lapply(\n  # list of dataframes\n  X = data_mild, \n  # call function\n  FUN = re_weight,\n  # target distributions\n  targets = targets,\n  # should matching or weighting be performed\n  matching_weighting = \"matching\",\n  # matching arguments passed on to matchit() function\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"linear.logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n[1] \"Raking converged in 15 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 14 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 16 iterations\"\n[1] \"Raking converged in 12 iterations\"\n\n\nWe can inspect the output of the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nCode\nmatchit_out_list[[1]]\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression and linearized\n             - sampling weights not included in estimation\n - caliper: &lt;distance&gt; (0.179)\n - number of obs.: 3500 (original), 366 (matched)\n - sampling weights: present\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index"
  },
  {
    "objectID": "chapters/re_weight.html#table-1",
    "href": "chapters/re_weight.html#table-1",
    "title": "4  Re-weighting to a target population",
    "section": "4.5 Table 1",
    "text": "4.5 Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nCode\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nCode\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\nUnweighted Table 1Weighted Table 1\n\n\n\n\nCode\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\nTable 4.1:  Table 1 BEFORE re-weighting \n  \n    \n      Patient characteristic\n\n      Total  N = 366\n1\n      \n        Treatment received\n\n      \n      Difference\n2\n    \n    \n      0  N = 183  (50.0%)\n1\n      1  N = 183  (50.0%)\n1\n    \n  \n  \n    dem_sex_cont\n\n\n\n0.06\n        0\n247 (67%)\n121 (66%)\n126 (69%)\n\n        1\n119 (33%)\n62 (34%)\n57 (31%)\n\n    dem_race\n217 (59%)\n105 (57%)\n112 (61%)\n-0.08\n    c_smoking_history\n179 (49%)\n91 (50%)\n88 (48%)\n0.03\n    c_ecog_cont\n\n\n\n0.15\n        0\n160 (44%)\n73 (40%)\n87 (48%)\n\n        1\n206 (56%)\n110 (60%)\n96 (52%)\n\n  \n  \n  \n    \n      1 n (%)\n\n    \n    \n      2 Standardized Mean Difference\n\n    \n  \n\n\n\n\n\n\n\n\n\nCode\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\nTable 4.2:  Table 1 AFTER re-weighting \n  \n    \n      Patient characteristic\n\n      Total  N = 366\n1\n      \n        Treatment received\n\n      \n      Difference\n2\n    \n    \n      0  N = 182.18  (49.8%)\n1\n      1  N = 183.82  (50.2%)\n1\n    \n  \n  \n    dem_sex_cont\n\n\n\n0.04\n        0\n231 (63%)\n113 (62%)\n117 (64%)\n\n        1\n135 (37%)\n69 (38%)\n66 (36%)\n\n    dem_race\n227 (62%)\n110 (61%)\n117 (63%)\n-0.06\n    c_smoking_history\n128 (35%)\n66 (36%)\n62 (34%)\n0.05\n    c_ecog_cont\n\n\n\n0.07\n        0\n150 (41%)\n72 (39%)\n78 (43%)\n\n        1\n216 (59%)\n111 (61%)\n105 (57%)\n\n  \n  \n  \n    \n      1 n (%)\n\n    \n    \n      2 Standardized Mean Difference\n\n    \n  \n\n\n\n\n\n\n\n\n\n4.5.1 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n4.5.2 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nCode\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nCode\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n\n\n\n\n4.5.3 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nCode\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nCode\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n\n\n\n\n4.5.4 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nCode\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences"
  },
  {
    "objectID": "chapters/re_weight.html#session-info",
    "href": "chapters/re_weight.html#session-info",
    "title": "4  Re-weighting to a target population",
    "section": "4.6 Session info",
    "text": "4.6 Session info\nScript runtime: 0.41 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\n\nCode\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ncardx\ncardx\n0.2.0\n\n\ndplyr\ndplyr\n1.1.4\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchIt\nMatchIt\n4.5.5\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nsmd\nsmd\n0.7.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\n\nCode\npander::pander(sessionInfo())\n\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: smd(v.0.7.0), cardx(v.0.2.0), gtsummary(v.2.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchIt(v.4.5.5), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8), dplyr(v.1.1.4) and here(v.1.0.1)\nloaded via a namespace (and not attached): tidyselect(v.1.2.1), fastmap(v.1.2.0), digest(v.0.6.37), rpart(v.4.1.23), lifecycle(v.1.0.4), cluster(v.2.1.6), waldo(v.0.5.3), gdata(v.3.0.0), magrittr(v.2.0.3), compiler(v.4.4.0), sass(v.0.4.9), rlang(v.1.1.4), Hmisc(v.5.1-3), tools(v.4.4.0), gt(v.0.11.0), utf8(v.1.2.4), yaml(v.2.3.10), data.table(v.1.16.0), knitr(v.1.48), htmlwidgets(v.1.6.4), xml2(v.1.3.6), withr(v.3.0.1), foreign(v.0.8-86), purrr(v.1.0.2), nnet(v.7.3-19), fansi(v.1.0.6), jomo(v.2.7-6), colorspace(v.2.1-1), future(v.1.34.0), ggplot2(v.3.5.1), gtools(v.3.9.5), globals(v.0.16.3), scales(v.1.3.0), iterators(v.1.0.14), MASS(v.7.3-60.2), cli(v.3.6.3), rmarkdown(v.2.28), crayon(v.1.5.3), generics(v.0.1.3), rstudioapi(v.0.16.0), sessioninfo(v.1.2.2), commonmark(v.1.9.1), minqa(v.1.2.8), DBI(v.1.2.3), pander(v.0.6.5), stringr(v.1.5.1), splines(v.4.4.0), assertthat(v.0.2.1), parallel(v.4.4.0), base64enc(v.0.1-3), mitools(v.2.4), vctrs(v.0.6.5), WeightIt(v.1.3.0), boot(v.1.3-30), glmnet(v.4.1-8), jsonlite(v.1.8.8), mitml(v.0.4-5), Formula(v.1.2-5), htmlTable(v.2.4.3), listenv(v.0.9.1), weights(v.1.0.4), foreach(v.1.5.2), tidyr(v.1.3.1), glue(v.1.7.0), parallelly(v.1.38.0), nloptr(v.2.1.1), pan(v.1.9), chk(v.0.9.2), codetools(v.0.2-20), stringi(v.1.8.4), shape(v.1.4.6.1), gtable(v.0.3.5), lme4(v.1.1-35.5), munsell(v.0.5.1), tibble(v.3.2.1), anesrake(v.0.80), pillar(v.1.9.0), furrr(v.0.3.1), htmltools(v.0.5.8.1), R6(v.2.5.1), rprojroot(v.2.0.4), evaluate(v.0.24.0), lattice(v.0.22-6), markdown(v.1.13), cards(v.0.2.1), backports(v.1.5.0), tictoc(v.1.2.1), broom(v.1.0.6), renv(v.1.0.7), simsurv(v.1.0.0), Rcpp(v.1.0.13), gridExtra(v.2.3), nlme(v.3.1-164), checkmate(v.2.3.2), xfun(v.0.47) and pkgconfig(v.2.0.3)\n\n\n\n\n\n\nCode\npander::pander(options('repos'))\n\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest"
  },
  {
    "objectID": "chapters/re_weight.html#section",
    "href": "chapters/re_weight.html#section",
    "title": "4  Re-weighting to a target population",
    "section": "4.7 ",
    "text": "4.7"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#about",
    "href": "chapters/subgroup_analysis.html#about",
    "title": "5  Subgroup analysis",
    "section": "5.1 About",
    "text": "5.1 About\nThis script is adapted from Noah Greifer’s highly recommended blog post on “Subgroup Analysis After Propensity Score Matching Using R”.\nFor a more formal manuscript on subgroup analysis with propensity scores, see Green and Stuart.(Green and Stuart 2014)"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#data-generation",
    "href": "chapters/subgroup_analysis.html#data-generation",
    "title": "5  Subgroup analysis",
    "section": "5.2 Data generation",
    "text": "5.2 Data generation\nWe again use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  select(-dem_sex_cont) |&gt; \n  colnames()\n\nhead(data_miss)\n\n  treat dem_age_index_cont dem_sex_cont c_smoking_history c_number_met_sites\n1     0           45.72712            1              TRUE                  1\n2     0           68.80948            0              TRUE                  1\n3     1           69.08840            1              TRUE                  1\n4     0           68.53324            0                NA                 NA\n5     0           59.37128            1              TRUE                  2\n6     0           75.85751            0              TRUE                  1\n  c_ecog_cont c_stage_initial_dx_cont dem_race dem_region dem_ses\n1           1                       4     TRUE      South       3\n2           0                       4    FALSE  Northeast       3\n3           0                       4    FALSE       West       2\n4          NA                      NA       NA       &lt;NA&gt;      NA\n5           0                       4    FALSE       West       3\n6           0                       4     TRUE    Midwest       4\n  c_hemoglobin_g_dl_cont c_urea_nitrogen_mg_dl_cont c_platelets_10_9_l_cont\n1               12.66657                   2.522498                320.6275\n2               13.19548                   2.998084                231.0663\n3               13.94372                   2.878485                244.8208\n4                     NA                         NA                      NA\n5               13.20148                   2.068868                213.3328\n6               10.69378                   2.826482                316.9183\n  c_calcium_mg_dl_cont c_glucose_mg_dl_cont c_lymphocyte_leukocyte_ratio_cont\n1             2.196983             4.621117                          3.024268\n2             2.267144             4.654893                          2.702998\n3             2.278628             4.644069                          3.032139\n4                   NA                   NA                                NA\n5             2.239781             4.645509                          2.950502\n6             2.223204             4.673633                          2.627947\n  c_alp_u_l_cont c_protein_g_l_cont c_alt_u_l_cont c_albumin_g_l_cont\n1       4.316845           67.60541       2.484302           39.05167\n2       4.300352           68.67764       2.638243           39.17591\n3       4.340642           67.12073       2.813447           41.89578\n4             NA                 NA             NA                 NA\n5       4.050191           68.90887       3.271357           44.11435\n6       4.836835           64.02802       2.732577           35.75704\n  c_bilirubin_mg_dl_cont c_chloride_mmol_l_cont c_monocytes_10_9_l_cont\n1          -1.4809641766               99.02275             -0.44092220\n2           0.0007103677              105.58828             -0.40409105\n3          -0.7584989810              100.31545             -0.31518310\n4                     NA                     NA                      NA\n5           0.2537484544              102.47050             -0.27677341\n6          -2.2942350574              101.68754              0.06843379\n  c_eosinophils_leukocytes_ratio_cont c_ldh_u_l_cont c_hr_cont c_sbp_cont\n1                           1.1417198       1.722156  4.388467   4.773152\n2                           0.7942357       1.728584  4.406478   4.814099\n3                          -0.4574536       1.697640  4.479523   4.887520\n4                                  NA             NA        NA         NA\n5                           0.6337259       1.651701  4.393284   4.857790\n6                           0.2562202       1.720717  4.350660   4.794559\n  c_oxygen_cont c_neutrophil_lymphocyte_ratio_cont c_bmi_cont\n1      97.01706                          1.8116984   3.329260\n2      97.00790                          0.9970809   3.116247\n3      96.99572                          1.4552387   3.307000\n4            NA                                 NA         NA\n5      96.99230                          1.1772781   3.138414\n6      96.99236                          0.9956116   3.096611\n  c_ast_alt_ratio_cont c_time_dx_to_index c_de_novo_mets_dx c_height_cont\n1           0.25520166          22.333475              TRUE      1.645257\n2           0.43717963          -8.733742              TRUE      1.613621\n3          -0.27769998          32.036705              TRUE      1.534387\n4                   NA                 NA                NA            NA\n5           0.01972456          36.686128             FALSE      1.653337\n6           0.33510661          37.093396              TRUE      1.513132\n  c_weight_cont c_dbp_cont c_year_index fu_itt_months death_itt\n1      65.79150   71.65043        2018+     45.673471         1\n2      51.40890   85.69923        &lt;2018     19.120776         1\n3      57.89357   80.79833        &lt;2018      5.492147         1\n4            NA         NA        2018+     26.876450         1\n5      85.48502   74.99556        &lt;2018     23.348709         1\n6      83.69665   82.97996        2018+      1.395827         1"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#moderator-covariate",
    "href": "chapters/subgroup_analysis.html#moderator-covariate",
    "title": "5  Subgroup analysis",
    "section": "5.3 Moderator covariate",
    "text": "5.3 Moderator covariate\nIn this example, we assume heterogeneous treatment effect by sex and we aim to assess the average treatment effect among the treated for female and male patients separately. The effect size is time to all-cause mortality. In this dataset, sex is encoded with a binary covariate with 0 = female and 1 = male.\n\ntable(data_miss$dem_sex_cont)\n\n\n   0    1 \n2317 1183"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#multiple-imputation",
    "href": "chapters/subgroup_analysis.html#multiple-imputation",
    "title": "5  Subgroup analysis",
    "section": "5.4 Multiple imputation",
    "text": "5.4 Multiple imputation\nBoth the imputation and propensity score step Multiple imputation using mice:\n\n# impute data\nfemale_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss |&gt; filter(dem_sex_cont == 0),\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\n\nmale_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss |&gt; filter(dem_sex_cont == 1),\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1\nWarning: Number of logged events: 1"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#propensity-score-matching-and-weighting",
    "href": "chapters/subgroup_analysis.html#propensity-score-matching-and-weighting",
    "title": "5  Subgroup analysis",
    "section": "5.5 Propensity score matching and weighting",
    "text": "5.5 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset.\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\ntreat ~ c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index + dem_age_index_cont + \n    dem_race + dem_region + dem_ses\n\n\n\n5.5.1 Matching\n\nmatch_within_strata &lt;- function(i, imputed_data = NULL, ps_formula = NULL){\n  \n  matched &lt;- MatchIt::matchit(\n    formula = ps_formula, \n    data = mice::complete(imputed_data, i),\n    method = \"nearest\",\n    caliper = 0.01,\n    ratio = 1,\n    replace = F\n    ) |&gt; \n    MatchIt::match.data()\n  \n  return(matched)\n  \n}\n\nfemale_matched &lt;- lapply(\n  X = 1:female_imp$m, \n  FUN = match_within_strata, \n  imputed_data = female_imp,\n  ps_formula = ps_form\n  )\n\nmale_matched &lt;- lapply(\n  X = 1:male_imp$m, \n  FUN = match_within_strata, \n  imputed_data = male_imp,\n  ps_formula = ps_form\n  )\n\n# combine the mth imputed and matched datasets\ncombine_list &lt;- function(i, data_0 = NULL, data_1 = NULL){\n  \n  data_combined &lt;- rbind(data_0[[i]], data_1[[i]])\n  \n  return(data_combined)\n  \n}\n\nmatched_all &lt;- lapply(\n  X = 1:female_imp$m, \n  FUN = combine_list, \n  data_0 = female_matched,\n  data_1 = male_matched\n  )\n\n\n\n5.5.2 Weighting\n\nweight_within_strata &lt;- function(i, imputed_data = NULL, ps_formula = NULL){\n  \n  weighted &lt;- WeightIt::weightit(\n    formula = ps_formula, \n    data = mice::complete(imputed_data, i),\n    method = \"glm\",\n    estimand = \"ATT\"\n    )\n  \n  # trim extreme weights\n  weighted &lt;- trim(\n    x = weighted, \n    at = .95, \n    lower = TRUE\n    )\n  \n  weighted_data &lt;- mice::complete(imputed_data, i) |&gt; \n    mutate(weights = weighted$weights)\n  \n  return(weighted_data)\n  \n}\n\nfemale_weighted &lt;- lapply(\n  X = 1:female_imp$m, \n  FUN = weight_within_strata, \n  imputed_data = female_imp,\n  ps_formula = ps_form\n  )\n\nmale_weighted &lt;- lapply(\n  X = 1:male_imp$m, \n  FUN = weight_within_strata, \n  imputed_data = male_imp,\n  ps_formula = ps_form\n  )\n\nweighted_all &lt;- lapply(\n  X = 1:female_imp$m, \n  FUN = combine_list, \n  data_0 = female_weighted,\n  data_1 = male_weighted\n  )"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#outcome-model-comparisons",
    "href": "chapters/subgroup_analysis.html#outcome-model-comparisons",
    "title": "5  Subgroup analysis",
    "section": "5.6 Outcome model comparisons",
    "text": "5.6 Outcome model comparisons\n\n5.6.1 Matching\n\ncox_fit_matching &lt;- function(i){\n  \n  survival_fit &lt;- survival::coxph(\n    data = i,\n    formula = Surv(fu_itt_months, death_itt) ~ treat*dem_sex_cont, \n    weights = weights, \n    cluster = subclass,\n    robust = TRUE\n    )\n  \n}\n\n\nmatched_all |&gt; \n  lapply(FUN = cox_fit_matching) |&gt; \n  mice::pool() |&gt; \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  dplyr::select(term, estimate, std.error, conf.low, conf.high)\n\n                term  estimate std.error  conf.low conf.high\n1              treat 0.6802007 0.1588437 0.4964419  0.931978\n2       dem_sex_cont 0.8241669 0.2029580 0.5506235  1.233604\n3 treat:dem_sex_cont 0.9520131 0.3065403 0.5139928  1.763310\n\n\n\n\n5.6.2 Weighting\n\ncox_fit_weighting &lt;- function(i){\n  \n  survival_fit &lt;- survival::coxph(\n    data = i,\n    formula = Surv(fu_itt_months, death_itt) ~ treat*dem_sex_cont, \n    weights = weights, \n    robust = TRUE\n    )\n  \n}\n\n\nweighted_all |&gt; \n  lapply(FUN = cox_fit_weighting) |&gt; \n  mice::pool() |&gt; \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  dplyr::select(term, estimate, std.error, conf.low, conf.high)\n\n                term  estimate std.error  conf.low conf.high\n1              treat 0.8034467 0.0742781 0.6942947 0.9297589\n2       dem_sex_cont 0.9077231 0.1466264 0.6803678 1.2110527\n3 treat:dem_sex_cont 0.9427430 0.1552176 0.6948934 1.2789939"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#session-info",
    "href": "chapters/subgroup_analysis.html#session-info",
    "title": "5  Subgroup analysis",
    "section": "5.8 Session info",
    "text": "5.8 Session info\nScript runtime: 0.43 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ndplyr\ndplyr\n1.1.4\n\n\nfurrr\nfurrr\n0.3.1\n\n\nfuture\nfuture\n1.34.0\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nparallelly\nparallelly\n1.38.0\n\n\nranger\nranger\n0.16.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: furrr(v.0.3.1), future(v.1.34.0), ranger(v.0.16.0), parallelly(v.1.38.0), gtsummary(v.2.0.1), here(v.1.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8) and dplyr(v.1.1.4)\nloaded via a namespace (and not attached): gtable(v.0.3.5), shape(v.1.4.6.1), xfun(v.0.47), ggplot2(v.3.5.1), htmlwidgets(v.1.6.4), MatchIt(v.4.5.5), lattice(v.0.22-6), simsurv(v.1.0.0), vctrs(v.0.6.5), tools(v.4.4.0), generics(v.0.1.3), parallel(v.4.4.0), tibble(v.3.2.1), fansi(v.1.0.6), pan(v.1.9), pkgconfig(v.2.0.3), jomo(v.2.7-6), assertthat(v.0.2.1), lifecycle(v.1.0.4), stringr(v.1.5.1), compiler(v.4.4.0), tictoc(v.1.2.1), munsell(v.0.5.1), mitools(v.2.4), codetools(v.0.2-20), htmltools(v.0.5.8.1), yaml(v.2.3.10), glmnet(v.4.1-8), pillar(v.1.9.0), nloptr(v.2.1.1), crayon(v.1.5.3), tidyr(v.1.3.1), MASS(v.7.3-60.2), sessioninfo(v.1.2.2), iterators(v.1.0.14), rpart(v.4.1.23), boot(v.1.3-30), foreach(v.1.5.2), mitml(v.0.4-5), nlme(v.3.1-164), WeightIt(v.1.3.0), tidyselect(v.1.2.1), digest(v.0.6.37), stringi(v.1.8.4), pander(v.0.6.5), listenv(v.0.9.1), purrr(v.1.0.2), splines(v.4.4.0), rprojroot(v.2.0.4), fastmap(v.1.2.0), colorspace(v.2.1-1), cli(v.3.6.3), magrittr(v.2.0.3), utf8(v.1.2.4), broom(v.1.0.6), withr(v.3.0.1), scales(v.1.3.0), backports(v.1.5.0), rmarkdown(v.2.28), globals(v.0.16.3), nnet(v.7.3-19), lme4(v.1.1-35.5), chk(v.0.9.2), evaluate(v.0.24.0), knitr(v.1.48), rlang(v.1.1.4), Rcpp(v.1.0.13), glue(v.1.7.0), DBI(v.1.2.3), renv(v.1.0.7), rstudioapi(v.0.16.0), minqa(v.1.2.8), jsonlite(v.1.8.8) and R6(v.2.5.1)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#references",
    "href": "chapters/subgroup_analysis.html#references",
    "title": "5  Subgroup analysis",
    "section": "5.7 References",
    "text": "5.7 References\n\n\nGreen, Kerry M., and Elizabeth A. Stuart. 2014. “Examining Moderation Analyses in Propensity Score Methods: Application to Depression and Substance Use.” Journal of Consulting and Clinical Psychology 82 (5): 773–83. https://doi.org/10.1037/a0036515."
  },
  {
    "objectID": "chapters/whole_game.html#background",
    "href": "chapters/whole_game.html#background",
    "title": "2  The whole game",
    "section": "2.1 Background",
    "text": "2.1 Background\n\nIn 2022, nearly every third drug approval was granted in the field of oncology (tendency ↑)(Mullard 2022)\nDecision-makers increasingly rely on real-world evidence (RWE) generated from routine-care health data such as electronic health records (EHR) to evaluate the comparative safety and effectiveness of novel cancer therapies\n\nENCORE\n\nThe ENCORE project is an RCT DUPLICATE expansion to oncology which is going to emulate 12 randomized clinical trials using multiple EHR data sources. The process includes an emphasis on transparency with documented assessment of data fitness of the RWD source for each trial and conducting extensive sensitivity analyses to assess robustness of findings and trial eligibility criteria.\nPartially observed covariates/confounders are a common and pervasive challenge\nTo date, most oncology studies utilizing RWD have relied on complete case analysis although assumptions for a complete case analysis (missing completely at random [MCAR]) are even stronger than those (missing at random [MAR]) for multiple imputation (MI). Besides this, MI has additional advantages:\n\nAll patients are retained\nFlexible modeling (parametric, non-parametric)\nCan incorporate additional information (auxiliary covariates) to make the MAR assumption more likely\nRealistic variance estimation (Rubin’s rule)\n\nHowever:\n\nNot much is known about how to use multiple imputation in combination with propensity score-based approaches\nComputational implementation can be complex"
  },
  {
    "objectID": "chapters/whole_game.html#objective",
    "href": "chapters/whole_game.html#objective",
    "title": "2  The whole game",
    "section": "2.2 Objective",
    "text": "2.2 Objective\n\n\n\n\n\n\nObjective\n\n\n\nTo establish a computationally reproducible workflow that streamlines multiple imputation &gt; propensity score matching/weighting &gt; survival analysis workflows in a transparent fashion\n\n\n\n\n\nFigure 2.1: Streamlined workflow to approach partially observed covariate data in oncology trial emulations."
  },
  {
    "objectID": "chapters/whole_game.html#leyrat-et-al.-simulation-study",
    "href": "chapters/whole_game.html#leyrat-et-al.-simulation-study",
    "title": "2  The whole game",
    "section": "2.3 Leyrat et al. simulation study",
    "text": "2.3 Leyrat et al. simulation study\nOne of the most comprehensive and influental simulation studies that addressed the question on how to combine multiple imputation with propensity scores (IPTW weighting) was published in 2019 by Leyrat et al. (Leyrat et al. 2019). In this study, the authors looked at three different potential ways:\n\nMIte: MI &gt; PS estimation &gt; Outcome model for each PS model &gt; Pooling of results\nMIps: MI &gt; PS estimation &gt; PS pooling across datasets &gt; single outcome model\nMIpar: MI &gt; Pooling of covariate parameters &gt; single PS model &gt; single outcome model\n\nAdditional questions that were also addressed:\n\nShould outcome be included in imputation model?\nHow to estimate variance of IPTW estimator in context of MIte or MIps or MIpar?\n\n\n\n\nFigure 2.2: Illustration of potential approaches that could be considered after multiple imputation (MI) of the partially observed covariates are missing values on the original dataset.\n\n\n\n2.3.1 Simulation study results\n\nMIte performed best in terms of bias, standardized differences/balancing, coverage rate and variance estimation\n\nMI &gt; PS estimation &gt; Outcome model for each PS model &gt; Pooling of results\n\nStandard IPTW variance estimation is valid for MIte\nOutcome must be included in imputation model\n\n\n\n\nFigure 2.3: Leyrat et al. simulation study results.\n\n\n\n\n2.3.2 Implementation in MatchThem R package\nTo streamline the implementation of multiple imputation &gt; propensity score workflows, Farhad Pishgar, Noah Greifer, Clémence Leyrat and Elizabeth Stuart developed the MatchThem package (Pishgar et al. 2021) which relies on the functionality provided by the mice, MatchIt, and WeightIt packages. An exemplary illustration on how to use the package in a survival analysis context is given in Chapter 3 (cheatsheet)."
  },
  {
    "objectID": "chapters/whole_game.html#session-info",
    "href": "chapters/whole_game.html#session-info",
    "title": "2  The whole game",
    "section": "2.5 Session info",
    "text": "2.5 Session info\nScript runtime: 0.00 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\npackage\nloadedversion\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: stats, graphics, grDevices, datasets, utils, methods and base\nloaded via a namespace (and not attached): digest(v.0.6.37), fastmap(v.1.2.0), xfun(v.0.47), tictoc(v.1.2.1), knitr(v.1.48), htmltools(v.0.5.8.1), rmarkdown(v.2.28), cli(v.3.6.3), pander(v.0.6.5), sessioninfo(v.1.2.2), renv(v.1.0.7), compiler(v.4.4.0), rstudioapi(v.0.16.0), tools(v.4.4.0), evaluate(v.0.24.0), Rcpp(v.1.0.13), yaml(v.2.3.10), rlang(v.1.1.4), jsonlite(v.1.8.8) and htmlwidgets(v.1.6.4)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest"
  },
  {
    "objectID": "chapters/whole_game.html#references",
    "href": "chapters/whole_game.html#references",
    "title": "2  The whole game",
    "section": "2.4 References",
    "text": "2.4 References\n\n\nBuuren, Stef van, and Karin Groothuis-Oudshoorn. 2011.\n“Mice: Multivariate Imputation by\nChained Equations in r” 45: 1–67. https://doi.org/10.18637/jss.v045.i03.\n\n\nGreen, Kerry M., and Elizabeth A. Stuart. 2014. “Examining\nModeration Analyses in Propensity Score Methods: Application to\nDepression and Substance Use.” Journal of Consulting and\nClinical Psychology 82 (5): 773–83. https://doi.org/10.1037/a0036515.\n\n\nLeyrat, Clémence, Shaun R Seaman, Ian R White, Ian Douglas, Liam Smeeth,\nJoseph Kim, Matthieu Resche-Rigon, James R Carpenter, and Elizabeth J\nWilliamson. 2019. “Propensity Score Analysis with Partially\nObserved Covariates: How Should Multiple Imputation Be Used?”\nStatistical Methods in Medical Research 28 (1): 3–19. https://doi.org/10.1177/0962280217713032.\n\n\nLumley, Thomas. 2024. “Survey: Analysis of Complex Survey\nSamples.”\n\n\nMullard, Asher. 2022. “2021 FDA Approvals.” Nature\nReviews Drug Discovery 21 (2): 83–88. https://doi.org/10.1038/d41573-022-00001-9.\n\n\nPishgar, Farhad, Noah Greifer, Clémence Leyrat, and Elizabeth Stuart.\n2021. “MatchThem: Matching and Weighting after Multiple\nImputation.” R Journal 13 (2): 292–305. https://doi.org/10.32614/RJ-2021-073.\n\n\nShah, Anoop D., Jonathan W. Bartlett, James Carpenter, Owen Nicholas,\nand Harry Hemingway. 2014. “Comparison of random forest and\nparametric imputation models for imputing missing data using MICE: a\nCALIBER study.” American Journal of Epidemiology 179\n(6): 764–74. https://doi.org/10.1093/aje/kwt312.\n\n\nStekhoven, Daniel J., and Peter Bühlmann. 2012.\n“MissForestnon-Parametric Missing Value Imputation\nfor Mixed-Type Data.” Bioinformatics 28 (1): 112–18. https://doi.org/10.1093/bioinformatics/btr597.\n\n\nTherneau, Terry M. 2024. “A Package for Survival Analysis in\nr.” https://CRAN.R-project.org/package=survival.\n\n\nWeberpals, Janick, Sudha Raman, Pamela Shaw, Hana Lee, Massimiliano\nRusso, Bradley Hammill, Sengwee Toh, et al. 2024. “A Principled\nApproach to Characterize and Analyze Partially Observed Confounder Data\nfrom Electronic Health Records.” Clinical Epidemiology\nVolume 16 (May): 329–43. https://doi.org/10.2147/clep.s436131."
  },
  {
    "objectID": "chapters/syvcox_coxph.html#comparison-of-coxph-versus-svycoxph-after-multiple-imputation-and-propensity-score-matching",
    "href": "chapters/syvcox_coxph.html#comparison-of-coxph-versus-svycoxph-after-multiple-imputation-and-propensity-score-matching",
    "title": "3  Application in Cox PH models",
    "section": "3.1 Comparison of coxph versus svycoxph after multiple imputation and propensity score matching",
    "text": "3.1 Comparison of coxph versus svycoxph after multiple imputation and propensity score matching\nIn Chapter 3 we illustrate a reproducible example on how to use coxph (survival package (Therneau 2024)) and svycoxph (survey package (Lumley 2024)) in combination with multiple imputation by chained equations (mice package (Buuren and Groothuis-Oudshoorn 2011)) and propensity score matching using the MatchThem package (Pishgar et al. 2021).\nFirst, we load the required R libraries/packages and some custom functions that are part of the encore.io R package that is being developed to streamline the analysis of all ENCORE trial emulations (non-public package).\n\nlibrary(dplyr)\nlibrary(survival)\nlibrary(mice)\nlibrary(MatchThem)\nlibrary(survey)\nlibrary(here)\nlibrary(gtsummary)\nlibrary(parallelly)\nlibrary(ranger)\nlibrary(furrr)\n\nsource(here(\"functions\", \"source_encore.io_functions.R\"))\n\n# track time\nruntime &lt;- tictoc::tic()"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-1-multiple-imputation",
    "href": "chapters/syvcox_coxph.html#step-1-multiple-imputation",
    "title": "3  Application in Cox PH models",
    "section": "3.2 Step 1: Multiple imputation",
    "text": "3.2 Step 1: Multiple imputation\nThe first step after deriving the analytic cohort includes the creation of multiple imputed datasets using mice R package(Buuren and Groothuis-Oudshoorn 2011).\n\nThe mice algorithm is one particular instance of a fully conditionally specified model. The algorithm starts with a random draw from the observed data, and imputes the incomplete data in a variable-by-variable fashion. One iteration consists of one cycle through all \\(Y_j\\).\n\n\n\n\nMICE algorithm for imputation of multivariate missing data.\n\n\nThe number of iterations \\(M\\) (= number of imputed datasets) in this example is 10, but in ENCORE we follow Stef van Buuren’s advice:\n\n[…] if calculation is not prohibitive, we may set \\(M\\) to the average percentage of missing data.\n(Flexible imputation of Missing Data, Sub-chapter 2.8)\n\nFollowing the results of various simulation studies (Shah et al. 2014; Weberpals et al. 2024), we use a non-parametric (random forest-based) imputation approach as the actual imputation algorithm.\n\n\n\n\n\n\nAdvantages of non-parametric imputation approaches\n\n\n\n\nParametric imputation models have to be correctly specified, i.e. also have to explicitly model nonlinear and non-additive covariate relationships\nMany imputation algorithms are not prepared for mixed type of data\nPopular: random forest-based algorithms\n\nfor each variable random forest is fit on the observed part and then predicts the missing part\nmissForest(Stekhoven and Bühlmann 2012) provides OOB error but only provides single imputations\nAlternatives: rf, cart in mice package (Buuren and Groothuis-Oudshoorn 2011)\n\n\n\n\nNote: In this example we utilize the futuremice() instead of the legacy mice() function to run the mice imputation across 7 cores in parallel.\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\nThe imputation step creates an object of class…\n\nclass(data_imp)\n\n[1] \"mids\"\n\n\n…which stands for multiple imputed datasets. It contains important information on the imputation procedure and the actual imputed datasets."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Background",
    "text": "Background\nMultiple imputation is a powerful tool in presence of missing data. However, especially in combination with propensity score analyses, multiple imputation can lead to challenges since analytic workflows can be become much more complex."
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-2-propensity-score-matching-and-weighting",
    "href": "chapters/syvcox_coxph.html#step-2-propensity-score-matching-and-weighting",
    "title": "3  Application in Cox PH models",
    "section": "3.3 Step 2: Propensity score matching and weighting",
    "text": "3.3 Step 2: Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset. As pointed in Section 2.3.1, the MIte approach performed best in terms of bias, standardized differences/balancing, coverage rate and variance estimation. In MatchThem this approach is referred to a within approach (performing matching within each dataset), while the inferior MIps approach (estimating propensity scores within each dataset, averaging them across datasets, and performing matching using the averaged propensity scores in each dataset) is referred to as across approach. Since MIte/within has been shown to have superior performance in most cases, we only illustrate this approach here.\nLet’s assume we fit the following propensity score model within each imputed dataset.\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\ntreat ~ dem_age_index_cont + dem_sex_cont + dem_race + dem_region + \n    dem_ses + c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index\n\n\n\nMatchingWeighting\n\n\nThe matching step happens using the matchthem() function, which is a wrapper around the matchit() function. This function not only provides the functionality to match on the propensity score, but also to perform (coarsened) exact matching, cardinality matching, genetic matching and more. In this example, we use a simple 1:1 nearest neighbor matching on the propensity score (estimated through logistic regression) without replacement with a caliper of 1% of the standard deviation of the propensity score.\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# print summary for matched dataset #1\ndata_mimids\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.005)\n - number of obs.: 3500 (original), 336 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n\n\nThe resulting “mimids” object contains the original imputed data and the output of the calls to matchit() applied to each imputed dataset.\n\n\nThe weighting step is performed very similarly using the weightthem() function. In this example weapply SMR weighting to arrive at the same ATT estimand as matching which is indicated through the estimand = \"ATT\" argument. In case we wanted to weight patients based on overlap weights, estimand = \"AT0\" would need to be specified (which is one of the sensitivity analyses in the FLAURA protocol).\nTo mitigate the risks of extreme weights, the subsequent trim() function truncates large weights by setting all weights higher than that at a given quantile (in this example the 95% quantile) to the weight at the quantile. Since we specify lower = TRUE, this is done symmetrically also with the 5% quantile.\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )\n\ndata_wimids\n\nA weightit object\n - method: \"glm\" (propensity score weighting with GLM)\n - number of obs.: 3500\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: 1)\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n - weights trimmed at 5% and 95%\n\n\nThe resulting “wimids” object contains the original imputed data and the output of the calls to weightit() applied to each imputed dataset."
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-4-outcome-model-comparisons",
    "href": "chapters/syvcox_coxph.html#step-4-outcome-model-comparisons",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Step 4: Outcome model comparisons",
    "text": "3.4 Step 4: Outcome model comparisons"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-4-estimation-of-marginal-treatment-effects",
    "href": "chapters/syvcox_coxph.html#step-4-estimation-of-marginal-treatment-effects",
    "title": "3  Application in Cox PH models",
    "section": "3.5 Step 4: Estimation of marginal treatment effects",
    "text": "3.5 Step 4: Estimation of marginal treatment effects\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n3.5.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n3.5.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n3.5.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n3.5.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  }
]