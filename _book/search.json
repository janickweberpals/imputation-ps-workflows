[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multiple imputation-propensity score workflows",
    "section": "",
    "text": "Background\nMultiple imputation is a powerful tool in presence of missing data. However, especially in combination with propensity score analyses, multiple imputation can lead to challenges since analytic workflows can be become much more complex.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>README</span>"
    ]
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Objective",
    "text": "Objective\nThis repository showcases and evaluation different multiple imputation &gt; propensity score &gt; outcome analyses and associated implementation challenges."
  },
  {
    "objectID": "index.html#sec-dependencies",
    "href": "index.html#sec-dependencies",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Dependencies",
    "text": "Dependencies\nThis is a quarto book project and R package dependencies are managed through the renv package. All packages and their versions can be viewed in the lockfile renv.lock. All required packages and the appropriate versions can be installed by running the following command:\n\nrenv::restore(repos = \"https://packagemanager.posit.co/cran/latest\")\n\n\n\n\n\n\n\nImportant\n\n\n\nThe dependencies are managed through Posit’s repository package manager (RSPM). If you use a different operating system than macOS, please head over to the RSPM setup website and follow these steps to adjust the URL above.\n\nGo to the RSPM setup website\nChoose the operating system (if Linux, also choose the Linux distribution)\nGo to Repository URL: and copy-paste the URL to the options statement in the .Rprofile file\noptions(repos = c(REPO_NAME = “URL”))"
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Reproducibility",
    "text": "Reproducibility\nFollow these steps in RStudio to reproduce this study:\n\n\n\n\n\n\nNote\n\n\n\n\nClone this repository via git clone &lt;url&gt; or in RStudio via File &gt; New Project &gt; Version Control &gt; Git &gt; then paste the link to repository URL\nInstall all necessary dependencies (see above)\nAdd/adapt the paths to the datasets in .Renviron\nIn RStudio, run all scripts via quarto render or Build &gt; Render Book (make sure quarto is installed)\n\n\n\n\nSteps to clone this repository in RStudio\n\n\n\n\nThe data used in this project is strictly simulated and no real patient-level data is used."
  },
  {
    "objectID": "index.html#repository-structure-and-files",
    "href": "index.html#repository-structure-and-files",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Repository structure and files",
    "text": "Repository structure and files\n\nDirectory overview\n\n\n.\n├── README.md\n├── RStudio_init.png\n├── _book\n│   ├── 01_syvcox_coxph.html\n│   ├── 02_re_weight.html\n│   ├── RStudio_init.png\n│   ├── chapters\n│   ├── index.html\n│   ├── nejm_tbl1.png\n│   ├── search.json\n│   └── site_libs\n├── _quarto.yml\n├── chapters\n│   ├── images\n│   ├── re_weight.md\n│   ├── re_weight.qmd\n│   ├── references.bib\n│   ├── subgroup_analysis.md\n│   ├── subgroup_analysis.qmd\n│   ├── syvcox_coxph.md\n│   ├── syvcox_coxph.qmd\n│   ├── whole_game.md\n│   ├── whole_game.qmd\n│   └── whole_game_files\n├── functions\n│   ├── install_on_demand.R\n│   ├── re_weight.R\n│   ├── simulate_flaura.R\n│   ├── source_encore.io_functions.R\n│   └── subgroup.R\n├── images\n│   ├── leyrat_results.png\n│   ├── mi_ps.png\n│   ├── mice.png\n│   ├── nejm_tbl1.png\n│   └── workflow.png\n├── imputation-ps-workflows.Rproj\n├── index.qmd\n├── index.rmarkdown\n├── index_files\n│   └── execute-results\n├── literature\n│   ├── MatchThem_vignette.pdf\n│   └── leyrat-et-al-2017-propensity-score-analysis-with-partially-observed-covariates-how-should-multiple-imputation-be-used.pdf\n├── references.bib\n├── renv\n│   ├── activate.R\n│   ├── library\n│   ├── settings.json\n│   └── staging\n├── renv.lock\n└── site_libs\n    ├── bootstrap\n    ├── clipboard\n    ├── quarto-html\n    ├── quarto-nav\n    └── quarto-search"
  },
  {
    "objectID": "01_syvcox_coxph.html",
    "href": "01_syvcox_coxph.html",
    "title": "2  coxph versus svycoxph",
    "section": "",
    "text": "2.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()\n\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 1,761\n1\n1\nN = 1,739\n1\n\n\n\n\nc_smoking_history\n607 (53%)\n504 (43%)\n\n\n    Unknown\n617\n563\n\n\nc_number_met_sites\n\n\n\n\n\n\n    1\n868 (76%)\n888 (76%)\n\n\n    2\n244 (21%)\n235 (20%)\n\n\n    3\n27 (2.4%)\n45 (3.8%)\n\n\n    4\n4 (0.3%)\n7 (0.6%)\n\n\n    5\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n\n\n    Unknown\n617\n563\n\n\nc_ecog_cont\n697 (61%)\n642 (55%)\n\n\n    Unknown\n617\n563\n\n\nc_stage_initial_dx_cont\n\n\n\n\n\n\n    1\n122 (11%)\n0 (0%)\n\n\n    2\n12 (1.0%)\n16 (1.4%)\n\n\n    3\n20 (1.7%)\n48 (4.1%)\n\n\n    4\n990 (87%)\n1,112 (95%)\n\n\n    Unknown\n617\n563\n\n\nc_hemoglobin_g_dl_cont\n12.95 (12.28, 13.77)\n12.86 (11.91, 13.72)\n\n\n    Unknown\n617\n563\n\n\nc_urea_nitrogen_mg_dl_cont\n2.78 (2.44, 3.11)\n2.76 (2.56, 2.95)\n\n\n    Unknown\n617\n563\n\n\nc_platelets_10_9_l_cont\n257 (216, 293)\n261 (226, 303)\n\n\n    Unknown\n617\n563\n\n\nc_calcium_mg_dl_cont\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n\n\n    Unknown\n617\n563\n\n\nc_glucose_mg_dl_cont\n4.63 (4.56, 4.71)\n4.65 (4.58, 4.73)\n\n\n    Unknown\n617\n563\n\n\nc_lymphocyte_leukocyte_ratio_cont\n2.94 (2.81, 3.07)\n2.93 (2.82, 3.04)\n\n\n    Unknown\n617\n563\n\n\nc_alp_u_l_cont\n4.47 (4.32, 4.61)\n4.51 (4.42, 4.60)\n\n\n    Unknown\n617\n563\n\n\nc_protein_g_l_cont\n68.1 (65.4, 70.8)\n69.0 (66.2, 71.6)\n\n\n    Unknown\n617\n563\n\n\nc_alt_u_l_cont\n2.91 (2.71, 3.10)\n2.89 (2.66, 3.12)\n\n\n    Unknown\n617\n563\n\n\nc_albumin_g_l_cont\n38.94 (36.87, 41.00)\n39.92 (37.90, 41.96)\n\n\n    Unknown\n617\n563\n\n\nc_bilirubin_mg_dl_cont\n-0.65 (-1.46, 0.16)\n-0.93 (-1.75, -0.09)\n\n\n    Unknown\n617\n563\n\n\nc_chloride_mmol_l_cont\n101.93 (100.01, 103.92)\n101.83 (99.82, 104.21)\n\n\n    Unknown\n617\n563\n\n\nc_monocytes_10_9_l_cont\n-0.49 (-0.76, -0.24)\n-0.49 (-0.67, -0.34)\n\n\n    Unknown\n617\n563\n\n\nc_eosinophils_leukocytes_ratio_cont\n0.72 (0.50, 0.96)\n0.67 (0.28, 1.07)\n\n\n    Unknown\n617\n563\n\n\nc_ldh_u_l_cont\n1.68 (1.65, 1.70)\n1.69 (1.65, 1.72)\n\n\n    Unknown\n617\n563\n\n\nc_hr_cont\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n\n\n    Unknown\n617\n563\n\n\nc_sbp_cont\n4.86 (4.78, 4.93)\n4.85 (4.79, 4.91)\n\n\n    Unknown\n617\n563\n\n\nc_oxygen_cont\n97.000 (96.985, 97.014)\n96.999 (96.992, 97.006)\n\n\n    Unknown\n617\n563\n\n\nc_neutrophil_lymphocyte_ratio_cont\n1.30 (1.05, 1.54)\n1.29 (1.06, 1.52)\n\n\n    Unknown\n617\n563\n\n\nc_bmi_cont\n3.23 (3.14, 3.32)\n3.24 (3.15, 3.32)\n\n\n    Unknown\n617\n563\n\n\nc_ast_alt_ratio_cont\n0.10 (-0.11, 0.31)\n0.12 (-0.08, 0.32)\n\n\n    Unknown\n617\n563\n\n\nc_time_dx_to_index\n73 (43, 102)\n44 (33, 55)\n\n\n    Unknown\n617\n563\n\n\nc_de_novo_mets_dx\n772 (67%)\n922 (78%)\n\n\n    Unknown\n617\n563\n\n\nc_height_cont\n1.64 (1.60, 1.69)\n1.65 (1.59, 1.70)\n\n\n    Unknown\n617\n563\n\n\nc_weight_cont\n68 (60, 76)\n69 (61, 76)\n\n\n    Unknown\n617\n563\n\n\nc_dbp_cont\n75 (70, 80)\n76 (72, 80)\n\n\n    Unknown\n617\n563\n\n\nc_year_index\n\n\n\n\n\n\n    &lt;2018\n91 (5.2%)\n1,639 (94%)\n\n\n    2018+\n1,670 (95%)\n100 (5.8%)\n\n\ndem_age_index_cont\n70 (64, 76)\n69 (64, 75)\n\n\ndem_sex_cont\n605 (34%)\n598 (34%)\n\n\ndem_race\n\n\n\n\n\n\n    Asian\n137 (12%)\n154 (13%)\n\n\n    Other\n320 (28%)\n355 (30%)\n\n\n    White\n687 (60%)\n667 (57%)\n\n\n    Unknown\n617\n563\n\n\ndem_region\n\n\n\n\n\n\n    Midwest\n117 (10%)\n160 (14%)\n\n\n    Northeast\n391 (34%)\n340 (29%)\n\n\n    South\n424 (37%)\n477 (41%)\n\n\n    West\n212 (19%)\n199 (17%)\n\n\n    Unknown\n617\n563\n\n\ndem_ses\n\n\n\n\n\n\n    1\n138 (12%)\n198 (17%)\n\n\n    2\n156 (14%)\n173 (15%)\n\n\n    3\n299 (26%)\n223 (19%)\n\n\n    4\n245 (21%)\n256 (22%)\n\n\n    5\n306 (27%)\n326 (28%)\n\n\n    Unknown\n617\n563\n\n\n\n1\nn (%); Median (Q1, Q3)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`coxph` versus `svycoxph`</span>"
    ]
  },
  {
    "objectID": "01_syvcox_coxph.html#multiple-imputation",
    "href": "01_syvcox_coxph.html#multiple-imputation",
    "title": "2  coxph versus svycoxph",
    "section": "2.2 Multiple imputation",
    "text": "2.2 Multiple imputation\nMultiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )"
  },
  {
    "objectID": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "href": "01_syvcox_coxph.html#propensity-score-matching-and-weighting",
    "title": "2  coxph versus svycoxph",
    "section": "2.3 Propensity score matching and weighting",
    "text": "2.3 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset:\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )"
  },
  {
    "objectID": "01_syvcox_coxph.html#outcome-model-comparisons",
    "href": "01_syvcox_coxph.html#outcome-model-comparisons",
    "title": "2  coxph versus svycoxph",
    "section": "2.4 Outcome model comparisons",
    "text": "2.4 Outcome model comparisons\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n2.4.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n2.4.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n2.4.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n2.4.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n2.4.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  },
  {
    "objectID": "01_syvcox_coxph.html#data-generation",
    "href": "01_syvcox_coxph.html#data-generation",
    "title": "2  coxph versus svycoxph",
    "section": "2.1 Data generation",
    "text": "2.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()\n\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates\n    )\n\n\n\n\n\n  \n    \n      Characteristic\n\n      0\nN = 1,712\n1\n      1\nN = 1,788\n1\n    \n  \n  \n    c_smoking_history\n579 (51%)\n520 (43%)\n        Unknown\n578\n584\n    c_number_met_sites\n\n\n        1\n837 (74%)\n899 (75%)\n        2\n249 (22%)\n255 (21%)\n        3\n41 (3.6%)\n42 (3.5%)\n        4\n7 (0.6%)\n8 (0.7%)\n        Unknown\n578\n584\n    c_ecog_cont\n714 (63%)\n637 (53%)\n        Unknown\n578\n584\n    c_stage_initial_dx_cont\n\n\n        1\n101 (8.9%)\n0 (0%)\n        2\n17 (1.5%)\n12 (1.0%)\n        3\n15 (1.3%)\n38 (3.2%)\n        4\n1,001 (88%)\n1,154 (96%)\n        Unknown\n578\n584\n    c_hemoglobin_g_dl_cont\n12.97 (12.16, 13.72)\n12.89 (11.98, 13.75)\n        Unknown\n578\n584\n    c_urea_nitrogen_mg_dl_cont\n2.76 (2.42, 3.08)\n2.77 (2.58, 2.97)\n        Unknown\n578\n584\n    c_platelets_10_9_l_cont\n255 (218, 290)\n266 (230, 302)\n        Unknown\n578\n584\n    c_calcium_mg_dl_cont\n2.23 (2.21, 2.25)\n2.24 (2.21, 2.27)\n        Unknown\n578\n584\n    c_glucose_mg_dl_cont\n4.64 (4.55, 4.72)\n4.65 (4.58, 4.73)\n        Unknown\n578\n584\n    c_lymphocyte_leukocyte_ratio_cont\n2.94 (2.81, 3.08)\n2.93 (2.82, 3.04)\n        Unknown\n578\n584\n    c_alp_u_l_cont\n4.47 (4.33, 4.61)\n4.51 (4.42, 4.59)\n        Unknown\n578\n584\n    c_protein_g_l_cont\n67.8 (65.1, 70.6)\n69.0 (66.0, 72.1)\n        Unknown\n578\n584\n    c_alt_u_l_cont\n2.93 (2.72, 3.14)\n2.86 (2.64, 3.10)\n        Unknown\n578\n584\n    c_albumin_g_l_cont\n39.01 (36.94, 41.01)\n39.98 (37.76, 42.07)\n        Unknown\n578\n584\n    c_bilirubin_mg_dl_cont\n-0.71 (-1.45, 0.07)\n-0.85 (-1.74, -0.03)\n        Unknown\n578\n584\n    c_chloride_mmol_l_cont\n102.08 (100.08, 104.20)\n102.05 (100.20, 104.12)\n        Unknown\n578\n584\n    c_monocytes_10_9_l_cont\n-0.53 (-0.78, -0.24)\n-0.51 (-0.68, -0.35)\n        Unknown\n578\n584\n    c_eosinophils_leukocytes_ratio_cont\n0.72 (0.50, 0.97)\n0.69 (0.28, 1.07)\n        Unknown\n578\n584\n    c_ldh_u_l_cont\n1.68 (1.65, 1.71)\n1.69 (1.65, 1.72)\n        Unknown\n578\n584\n    c_hr_cont\n4.41 (4.39, 4.43)\n4.43 (4.40, 4.46)\n        Unknown\n578\n584\n    c_sbp_cont\n4.85 (4.77, 4.92)\n4.85 (4.79, 4.92)\n        Unknown\n578\n584\n    c_oxygen_cont\n97.000 (96.986, 97.014)\n97.001 (96.993, 97.007)\n        Unknown\n578\n584\n    c_neutrophil_lymphocyte_ratio_cont\n1.33 (1.11, 1.56)\n1.28 (1.02, 1.52)\n        Unknown\n578\n584\n    c_bmi_cont\n3.23 (3.14, 3.31)\n3.23 (3.14, 3.31)\n        Unknown\n578\n584\n    c_ast_alt_ratio_cont\n0.09 (-0.10, 0.30)\n0.12 (-0.07, 0.32)\n        Unknown\n578\n584\n    c_time_dx_to_index\n73 (43, 103)\n43 (32, 55)\n        Unknown\n578\n584\n    c_de_novo_mets_dx\n774 (68%)\n945 (78%)\n        Unknown\n578\n584\n    c_height_cont\n1.64 (1.59, 1.69)\n1.65 (1.59, 1.70)\n        Unknown\n578\n584\n    c_weight_cont\n68 (60, 76)\n69 (61, 76)\n        Unknown\n578\n584\n    c_dbp_cont\n75 (70, 79)\n76 (72, 80)\n        Unknown\n578\n584\n    c_year_index\n\n\n        &lt;2018\n87 (5.1%)\n1,703 (95%)\n        2018+\n1,625 (95%)\n85 (4.8%)\n    dem_age_index_cont\n70 (63, 76)\n69 (64, 74)\n    dem_sex_cont\n614 (36%)\n569 (32%)\n    dem_race\n664 (59%)\n753 (63%)\n        Unknown\n578\n584\n    dem_region\n\n\n        Midwest\n123 (11%)\n137 (11%)\n        Northeast\n382 (34%)\n390 (32%)\n        South\n409 (36%)\n456 (38%)\n        West\n220 (19%)\n221 (18%)\n        Unknown\n578\n584\n    dem_ses\n\n\n        1\n102 (9.0%)\n217 (18%)\n        2\n152 (13%)\n157 (13%)\n        3\n302 (27%)\n210 (17%)\n        4\n271 (24%)\n291 (24%)\n        5\n307 (27%)\n329 (27%)\n        Unknown\n578\n584\n  \n  \n  \n    \n      1 n (%); Median (Q1, Q3)"
  },
  {
    "objectID": "02_re_weight.html",
    "href": "02_re_weight.html",
    "title": "3  Re-weighting to a target population",
    "section": "",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\nShow the code\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  treat_prevalence = .51, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  ) |&gt; \n  # we have to convert sex and ecog into a factor variable \n  # since anesrake doesn't accept 0/1 numeric encoding for \n  # binary variables\n  mutate(across(c(dem_sex_cont, c_ecog_cont), function(x) factor(as.character(x))))\n\ncovariates &lt;- data_miss |&gt; \n  select(starts_with(\"c_\"), starts_with(\"dem_\")) |&gt; \n  colnames()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#multiple-imputation",
    "href": "02_re_weight.html#multiple-imputation",
    "title": "3  Re-weighting to a target population",
    "section": "3.2 Multiple imputation",
    "text": "3.2 Multiple imputation\nMultiple imputation using mice:\n\n\nShow the code\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = 7,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#defining-target-distributions",
    "href": "02_re_weight.html#defining-target-distributions",
    "title": "3  Re-weighting to a target population",
    "section": "3.3 Defining target distributions",
    "text": "3.3 Defining target distributions\nBefore applying the re-weighting, we need to define the target distributions of patient characteristics that we want to match from the clinical trial using the raking procedure. The following distributions are taken from Table 1 of the FLAURA trial.\n\n\n\nFLAURA trial Table 1; in OS analysis race was simplified to Asian vs. non-Asian\n\n\n\n\nShow the code\n# Define FLAURA distributions for key covariates --------------------------\n# order is as in Table 1\n\n## sex ---------------------------------------------------------------------\n\n# female (0) to male (1) proportion:\nsex_target &lt;- c(.63, .37) \nnames(sex_target) &lt;- c(\"0\", \"1\")\n\n## race --------------------------------------------------------------------\n# asian, non-asian\n# asian (TRUE) to non-asian (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nrace_target &lt;- c(.62, .38)\n\n## smoking -----------------------------------------------------------------\n\n# current/former smoker (TRUE) to never smoker (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nsmoker_target &lt;- c(.35, .65)\n\n## ecog --------------------------------------------------------------------\n\n# ecog 0 by exposure \navg_prop_ecog0 &lt;- .41\n\n# ecog 0 to ecog 1 proportion\necog_target &lt;- c(.41, .59)\nnames(ecog_target) &lt;- c(\"0\", \"1\")\n\n\n# summarize target distributions in a named list vector --------------\ntargets &lt;- list(sex_target, race_target, smoker_target, ecog_target)\nnames(targets) &lt;- c(\"dem_sex_cont\", \"dem_race\", \"c_smoking_history\", \"c_ecog_cont\")\n\n# print\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "href": "02_re_weight.html#propensity-score-matching-and-re-weighting",
    "title": "3  Re-weighting to a target population",
    "section": "3.4 Propensity score matching and re-weighting",
    "text": "3.4 Propensity score matching and re-weighting\nIn this step, propensity score matching and re-weighting of key patient characteristics to match those of the original RCT is performed across all imputed datasets.\nThe propensity score model is specified as follows:\n\n\nShow the code\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\n\ntreat ~ c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index + dem_age_index_cont + \n    dem_sex_cont + dem_race + dem_region + dem_ses\n\n\nThe matching and re-weighting is performed using the re_weight() function. This function is a wrapper for matchit() and weightit() in combination with the anesrake() function which performs the raking (= re-weighting) procedure.\nWe apply this function to each imputed dataset. Before doing so, the imputed datasets, which are currently stored as a mids object, needs to be converted to a list of dataframes:\n\n\nShow the code\n# create a mild object containing lists of data.frames\ndata_mild &lt;- mice::complete(data = data_imp, action = \"all\", include = FALSE)\n\nsummary(data_mild)\n\n\n   Length Class      Mode\n1  39     data.frame list\n2  39     data.frame list\n3  39     data.frame list\n4  39     data.frame list\n5  39     data.frame list\n6  39     data.frame list\n7  39     data.frame list\n8  39     data.frame list\n9  39     data.frame list\n10 39     data.frame list\n\n\nThe lapply function loops the function through each dataframe and returns a list of matchit objects which contain imputed &gt; matched &gt; re-weighted datasets. To take advantage of the features that come with the cobalt and matchthem packages, the function stores the raking weights as sampling weights (s.weights).\n\n\nShow the code\n# call match re-weight\nmatchit_out_list &lt;- lapply(\n  # list of dataframes\n  X = data_mild, \n  # call function\n  FUN = re_weight,\n  # target distributions\n  targets = targets,\n  # should matching or weighting be performed\n  matching_weighting = \"matching\",\n  # matching arguments passed on to matchit() function\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"linear.logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n[1] \"Raking converged in 15 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 14 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 10 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 16 iterations\"\n[1] \"Raking converged in 12 iterations\"\n\n\nWe can inspect the output of the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\nmatchit_out_list[[1]]\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression and linearized\n             - sampling weights not included in estimation\n - caliper: &lt;distance&gt; (0.179)\n - number of obs.: 3500 (original), 366 (matched)\n - sampling weights: present\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#unweighted-table-1",
    "href": "02_re_weight.html#unweighted-table-1",
    "title": "3  Re-weighting to a target population",
    "section": "3.5 (Un)weighted Table 1",
    "text": "3.5 (Un)weighted Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\n\n3.5.1 Unweighted Table 1\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 183  (50.0%)\n1\n1  N = 183  (50.0%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.06\n\n\n    0\n247 (67%)\n121 (66%)\n126 (69%)\n\n\n\n\n    1\n119 (33%)\n62 (34%)\n57 (31%)\n\n\n\n\ndem_race\n217 (59%)\n105 (57%)\n112 (61%)\n-0.08\n\n\nc_smoking_history\n179 (49%)\n91 (50%)\n88 (48%)\n0.03\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.15\n\n\n    0\n160 (44%)\n73 (40%)\n87 (48%)\n\n\n\n\n    1\n206 (56%)\n110 (60%)\n96 (52%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n3.5.2 Weighted Table 1\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 182.18  (49.8%)\n1\n1  N = 183.82  (50.2%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.04\n\n\n    0\n231 (63%)\n113 (62%)\n117 (64%)\n\n\n\n\n    1\n135 (37%)\n69 (38%)\n66 (36%)\n\n\n\n\ndem_race\n227 (62%)\n110 (61%)\n117 (63%)\n-0.06\n\n\nc_smoking_history\n128 (35%)\n66 (36%)\n62 (34%)\n0.05\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.07\n\n\n    0\n150 (41%)\n72 (39%)\n78 (43%)\n\n\n\n\n    1\n216 (59%)\n111 (61%)\n105 (57%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n3.5.4 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.5 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.6 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "02_re_weight.html#table-1",
    "href": "02_re_weight.html#table-1",
    "title": "3  Re-weighting to a target population",
    "section": "3.5 Table 1",
    "text": "3.5 Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_sex_cont\n   0    1 \n0.63 0.37 \n\n$dem_race\n[1] 0.62 0.38\n\n$c_smoking_history\n[1] 0.35 0.65\n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\nUnweighted Table 1Weighted Table 1\n\n\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 183  (50.0%)\n1\n1  N = 183  (50.0%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.06\n\n\n    0\n247 (67%)\n121 (66%)\n126 (69%)\n\n\n\n\n    1\n119 (33%)\n62 (34%)\n57 (31%)\n\n\n\n\ndem_race\n217 (59%)\n105 (57%)\n112 (61%)\n-0.08\n\n\nc_smoking_history\n179 (49%)\n91 (50%)\n88 (48%)\n0.03\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.15\n\n\n    0\n160 (44%)\n73 (40%)\n87 (48%)\n\n\n\n\n    1\n206 (56%)\n110 (60%)\n96 (52%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = names(targets)\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 366\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 182.18  (49.8%)\n1\n1  N = 183.82  (50.2%)\n1\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.04\n\n\n    0\n231 (63%)\n113 (62%)\n117 (64%)\n\n\n\n\n    1\n135 (37%)\n69 (38%)\n66 (36%)\n\n\n\n\ndem_race\n227 (62%)\n110 (61%)\n117 (63%)\n-0.06\n\n\nc_smoking_history\n128 (35%)\n66 (36%)\n62 (34%)\n0.05\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.07\n\n\n    0\n150 (41%)\n72 (39%)\n78 (43%)\n\n\n\n\n    1\n216 (59%)\n111 (61%)\n105 (57%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.1 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n3.5.2 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\nNo target distributions specified, no re-weighting will be performed.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.3 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.023)\n - number of obs.: 3500 (original), 364 (matched)\n - target estimand: ATT\n - covariates: c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index, dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses\n\n\n\n\n3.5.4 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#data-generation",
    "href": "chapters/syvcox_coxph.html#data-generation",
    "title": "3  Application in Cox PH models",
    "section": "3.1 Data generation",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness analytic cohort dataset with similar distributions to FLAURA, a randomized controlled trial that evaluated the efficacy and safety of osimertinib to standard-of-care (SoC) tyrosine kinase inhibitors (TKIs) in advanced NSCLC patients with a sensitizing EGFR mutation.\nThe following cohort resembles distributions observed in the EHR-derived EDB1dataset used in ENCORE. Note: the values of some continuous covariates (labs) are displayed after log/log-log transformation.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE\n  )\n\n# crate Table 1\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates_for_imputation\n    ) |&gt; \n  add_overall() |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {N}\",\n    stat_1 ~ \"**Comparator** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**Exposure** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt; \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\") |&gt; \n  modify_caption(\"**Table 1. Patient Characteristics**\")\n\n\n\n\n\n  Table 1. Patient Characteristics\n\n  \n    \n      Patient characteristic\n\n      Total  N = 3500\n1\n      \n        Treatment received\n\n      \n    \n    \n      Comparator  N = 2069  (59.1%)\n1\n      Exposure  N = 1431  (40.9%)\n1\n    \n  \n  \n    dem_age_index_cont\n69 (64, 74)\n69 (63, 74)\n69 (64, 74)\n    dem_sex_cont\n1,146 (33%)\n676 (33%)\n470 (33%)\n    c_smoking_history\n1,037 (44%)\n653 (47%)\n384 (41%)\n        Unknown\n1,162\n677\n485\n    c_number_met_sites\n\n\n\n        1\n1,742 (75%)\n1,043 (75%)\n699 (74%)\n        2\n501 (21%)\n293 (21%)\n208 (22%)\n        3\n77 (3.3%)\n44 (3.2%)\n33 (3.5%)\n        4\n16 (0.7%)\n10 (0.7%)\n6 (0.6%)\n        5\n2 (&lt;0.1%)\n2 (0.1%)\n0 (0%)\n        Unknown\n1,162\n677\n485\n    c_hemoglobin_g_dl_cont\n12.89 (11.99, 13.83)\n12.87 (11.96, 13.83)\n12.94 (12.03, 13.84)\n        Unknown\n1,162\n677\n485\n    c_urea_nitrogen_mg_dl_cont\n2.72 (2.51, 2.93)\n2.72 (2.51, 2.93)\n2.72 (2.51, 2.92)\n        Unknown\n1,162\n677\n485\n    c_platelets_10_9_l_cont\n262 (225, 297)\n261 (225, 298)\n263 (224, 297)\n        Unknown\n1,162\n677\n485\n    c_calcium_mg_dl_cont\n2.23 (2.20, 2.26)\n2.23 (2.20, 2.26)\n2.23 (2.20, 2.26)\n        Unknown\n1,162\n677\n485\n    c_glucose_mg_dl_cont\n4.64 (4.56, 4.71)\n4.64 (4.57, 4.71)\n4.64 (4.56, 4.71)\n        Unknown\n1,162\n677\n485\n    c_lymphocyte_leukocyte_ratio_cont\n2.87 (2.75, 2.99)\n2.87 (2.75, 2.99)\n2.88 (2.75, 2.99)\n        Unknown\n1,162\n677\n485\n    c_alp_u_l_cont\n4.48 (4.39, 4.56)\n4.47 (4.39, 4.56)\n4.48 (4.40, 4.56)\n        Unknown\n1,162\n677\n485\n    c_protein_g_l_cont\n68.1 (65.4, 70.6)\n68.1 (65.4, 70.6)\n68.0 (65.3, 70.7)\n        Unknown\n1,162\n677\n485\n    c_alt_u_l_cont\n2.89 (2.66, 3.09)\n2.88 (2.66, 3.09)\n2.89 (2.66, 3.10)\n        Unknown\n1,162\n677\n485\n    c_albumin_g_l_cont\n40.0 (37.9, 42.0)\n39.9 (37.8, 41.9)\n40.0 (38.1, 42.2)\n        Unknown\n1,162\n677\n485\n    c_bilirubin_mg_dl_cont\n-0.92 (-1.79, -0.09)\n-0.83 (-1.71, 0.00)\n-1.08 (-1.89, -0.24)\n        Unknown\n1,162\n677\n485\n    c_chloride_mmol_l_cont\n102.09 (100.05, 104.09)\n102.09 (99.97, 104.08)\n102.10 (100.12, 104.17)\n        Unknown\n1,162\n677\n485\n    c_monocytes_10_9_l_cont\n-0.51 (-0.67, -0.34)\n-0.51 (-0.68, -0.35)\n-0.51 (-0.67, -0.33)\n        Unknown\n1,162\n677\n485\n    c_eosinophils_leukocytes_ratio_cont\n0.69 (0.31, 1.09)\n0.70 (0.33, 1.12)\n0.67 (0.28, 1.06)\n        Unknown\n1,162\n677\n485\n    c_ldh_u_l_cont\n1.69 (1.65, 1.72)\n1.69 (1.65, 1.72)\n1.69 (1.66, 1.72)\n        Unknown\n1,162\n677\n485\n    c_hr_cont\n4.43 (4.40, 4.46)\n4.43 (4.40, 4.45)\n4.43 (4.40, 4.46)\n        Unknown\n1,162\n677\n485\n    c_sbp_cont\n4.85 (4.79, 4.91)\n4.85 (4.79, 4.91)\n4.85 (4.79, 4.92)\n        Unknown\n1,162\n677\n485\n    c_oxygen_cont\n97.000 (96.994, 97.007)\n97.000 (96.993, 97.007)\n97.000 (96.994, 97.007)\n        Unknown\n1,162\n677\n485\n    c_ecog_cont\n1,341 (57%)\n842 (60%)\n499 (53%)\n        Unknown\n1,162\n677\n485\n    c_neutrophil_lymphocyte_ratio_cont\n1.30 (1.03, 1.55)\n1.30 (1.04, 1.55)\n1.30 (1.03, 1.55)\n        Unknown\n1,162\n677\n485\n    c_bmi_cont\n3.23 (3.14, 3.32)\n3.23 (3.14, 3.32)\n3.23 (3.14, 3.32)\n        Unknown\n1,162\n677\n485\n    c_ast_alt_ratio_cont\n0.12 (-0.08, 0.31)\n0.11 (-0.08, 0.31)\n0.12 (-0.08, 0.31)\n        Unknown\n1,162\n677\n485\n    c_stage_initial_dx_cont\n\n\n\n        1\n32 (1.4%)\n23 (1.7%)\n9 (1.0%)\n        2\n63 (2.7%)\n41 (2.9%)\n22 (2.3%)\n        3\n455 (19%)\n276 (20%)\n179 (19%)\n        4\n1,788 (76%)\n1,052 (76%)\n736 (78%)\n        Unknown\n1,162\n677\n485\n    c_de_novo_mets_dx\n1,856 (79%)\n1,104 (79%)\n752 (79%)\n        Unknown\n1,162\n677\n485\n    c_height_cont\n1.65 (1.60, 1.70)\n1.65 (1.59, 1.70)\n1.65 (1.60, 1.70)\n        Unknown\n1,162\n677\n485\n    c_weight_cont\n69 (61, 76)\n69 (61, 76)\n69 (61, 76)\n        Unknown\n1,162\n677\n485\n    c_year_index\n\n\n\n        &lt;2018\n3,324 (95%)\n1,978 (96%)\n1,346 (94%)\n        2018+\n176 (5.0%)\n91 (4.4%)\n85 (5.9%)\n    c_dbp_cont\n76.2 (72.0, 80.2)\n76.0 (71.7, 80.2)\n76.4 (72.3, 80.2)\n        Unknown\n1,162\n677\n485\n    death_itt\n3,481 (99%)\n2,061 (100%)\n1,420 (99%)\n    fu_itt_months\n16 (8, 32)\n15 (7, 29)\n19 (9, 36)\n  \n  \n  \n    \n      1 Median (Q1, Q3); n (%)"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#multiple-imputation",
    "href": "chapters/syvcox_coxph.html#multiple-imputation",
    "title": "3  Application in Cox PH models",
    "section": "3.3 Multiple imputation",
    "text": "3.3 Multiple imputation\nMultiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#propensity-score-matching-and-weighting",
    "href": "chapters/syvcox_coxph.html#propensity-score-matching-and-weighting",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Propensity score matching and weighting",
    "text": "3.4 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset:\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#outcome-model-comparisons",
    "href": "chapters/syvcox_coxph.html#outcome-model-comparisons",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Outcome model comparisons",
    "text": "3.4 Outcome model comparisons\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n3.4.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.4.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n3.4.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n3.4.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.4.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n3.4.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#session-info",
    "href": "chapters/syvcox_coxph.html#session-info",
    "title": "3  Application in Cox PH models",
    "section": "3.6 Session info",
    "text": "3.6 Session info\nScript runtime: 0.38 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ncobalt\ncobalt\n4.5.5\n\n\ndplyr\ndplyr\n1.1.4\n\n\nfurrr\nfurrr\n0.3.1\n\n\nfuture\nfuture\n1.34.0\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nparallelly\nparallelly\n1.38.0\n\n\nranger\nranger\n0.16.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: cobalt(v.4.5.5), furrr(v.0.3.1), future(v.1.34.0), ranger(v.0.16.0), parallelly(v.1.38.0), gtsummary(v.2.0.1), here(v.1.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8) and dplyr(v.1.1.4)\nloaded via a namespace (and not attached): tidyselect(v.1.2.1), farver(v.2.1.2), fastmap(v.1.2.0), digest(v.0.6.37), rpart(v.4.1.23), lifecycle(v.1.0.4), magrittr(v.2.0.3), compiler(v.4.4.0), rlang(v.1.1.4), sass(v.0.4.9), tools(v.4.4.0), utf8(v.1.2.4), yaml(v.2.3.10), gt(v.0.11.0), knitr(v.1.48), labeling(v.0.4.3), htmlwidgets(v.1.6.4), xml2(v.1.3.6), withr(v.3.0.1), purrr(v.1.0.2), nnet(v.7.3-19), fansi(v.1.0.6), jomo(v.2.7-6), colorspace(v.2.1-1), ggplot2(v.3.5.1), globals(v.0.16.3), scales(v.1.3.0), iterators(v.1.0.14), MASS(v.7.3-60.2), cli(v.3.6.3), rmarkdown(v.2.28), crayon(v.1.5.3), generics(v.0.1.3), rstudioapi(v.0.16.0), sessioninfo(v.1.2.2), commonmark(v.1.9.1), minqa(v.1.2.8), DBI(v.1.2.3), pander(v.0.6.5), stringr(v.1.5.1), splines(v.4.4.0), assertthat(v.0.2.1), parallel(v.4.4.0), base64enc(v.0.1-3), mitools(v.2.4), vctrs(v.0.6.5), WeightIt(v.1.3.0), boot(v.1.3-30), glmnet(v.4.1-8), jsonlite(v.1.8.8), mitml(v.0.4-5), listenv(v.0.9.1), locfit(v.1.5-9.10), foreach(v.1.5.2), tidyr(v.1.3.1), glue(v.1.7.0), nloptr(v.2.1.1), pan(v.1.9), chk(v.0.9.2), codetools(v.0.2-20), stringi(v.1.8.4), shape(v.1.4.6.1), gtable(v.0.3.5), lme4(v.1.1-35.5), munsell(v.0.5.1), tibble(v.3.2.1), pillar(v.1.9.0), htmltools(v.0.5.8.1), R6(v.2.5.1), rprojroot(v.2.0.4), evaluate(v.0.24.0), lattice(v.0.22-6), markdown(v.1.13), backports(v.1.5.0), cards(v.0.2.1), tictoc(v.1.2.1), MatchIt(v.4.5.5), broom(v.1.0.6), renv(v.1.0.7), simsurv(v.1.0.0), Rcpp(v.1.0.13), nlme(v.3.1-164), xfun(v.0.47) and pkgconfig(v.2.0.3)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#section",
    "href": "chapters/syvcox_coxph.html#section",
    "title": "3  Application in Cox PH models",
    "section": "3.7 ",
    "text": "3.7 \n\n\n\n\n\n\nBuuren, Stef van, and Karin Groothuis-Oudshoorn. 2011. “Mice: Multivariate Imputation by Chained Equations in r” 45: 1–67. https://doi.org/10.18637/jss.v045.i03.\n\n\nLumley, Thomas. 2024. “Survey: Analysis of Complex Survey Samples.”\n\n\nPishgar, Farhad, Noah Greifer, Clémence Leyrat, and Elizabeth Stuart. 2021. “MatchThem: Matching and Weighting after Multiple Imputation.” R Journal 13 (2): 292–305. https://doi.org/10.32614/RJ-2021-073.\n\n\nShah, Anoop D., Jonathan W. Bartlett, James Carpenter, Owen Nicholas, and Harry Hemingway. 2014. “Comparison of random forest and parametric imputation models for imputing missing data using MICE: a CALIBER study.” American Journal of Epidemiology 179 (6): 764–74. https://doi.org/10.1093/aje/kwt312.\n\n\nStekhoven, Daniel J., and Peter Bühlmann. 2012. “MissForestnon-Parametric Missing Value Imputation for Mixed-Type Data.” Bioinformatics 28 (1): 112–18. https://doi.org/10.1093/bioinformatics/btr597.\n\n\nTherneau, Terry M. 2024. “A Package for Survival Analysis in r.” https://CRAN.R-project.org/package=survival.\n\n\nWeberpals, Janick, Sudha Raman, Pamela Shaw, Hana Lee, Massimiliano Russo, Bradley Hammill, Sengwee Toh, et al. 2024. “A Principled Approach to Characterize and Analyze Partially Observed Confounder Data from Electronic Health Records.” Clinical Epidemiology Volume 16 (May): 329–43. https://doi.org/10.2147/clep.s436131.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#data-generation",
    "href": "chapters/re_weight.html#data-generation",
    "title": "4  Re-weighting to a target population",
    "section": "4.1 Data generation",
    "text": "4.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n\nCode\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE\n  ) |&gt; \n  # anesrake works best with factor variables\n  # create age category with age less than 65\n  mutate(dem_age_lt65 = factor(ifelse(dem_age_index_cont &lt; 65, \"&lt;65\", \"65+\"))) |&gt; \n  # convert dem_race into a binary Asian vs. non-Asian \n  mutate(dem_race = factor(ifelse(dem_race == \"Asian\", \"Asian\", \"Non-Asian\"))) |&gt;\n  # convert dem_sex_cont into a factor \n  mutate(dem_sex_cont = factor(ifelse(dem_sex_cont == \"1\", \"Male\", \"Female\"))) |&gt; \n  # convert dem_sex_cont into a factor \n  mutate(c_smoking_history = factor(ifelse(c_smoking_history == TRUE, \"Current/former\", \"Never\"))) |&gt; \n  # convert c_ecog_cont into a factor \n  mutate(across(c(c_ecog_cont), function(x) factor(as.character(x))))"
  },
  {
    "objectID": "chapters/re_weight.html#multiple-imputation",
    "href": "chapters/re_weight.html#multiple-imputation",
    "title": "4  Re-weighting to a target population",
    "section": "4.2 Multiple imputation",
    "text": "4.2 Multiple imputation\nMultiple imputation using mice:\n\n\nShow the code\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = 7,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#defining-target-distributions",
    "href": "chapters/re_weight.html#defining-target-distributions",
    "title": "4  Re-weighting to a target population",
    "section": "4.3 Defining target distributions",
    "text": "4.3 Defining target distributions\nBefore applying the re-weighting, we need to define the target distributions of patient characteristics that we want to match from the clinical trial using the raking procedure. The following distributions are taken from Table 1 of the FLAURA trial.\n\n\n\nTable 4.1: FLAURA trial Table 1; in OS analysis race was simplified to Asian vs. non-Asian\n\n\n\n\n\n\n\n\nShow the code\n# Define FLAURA distributions for key covariates --------------------------\n# order is as in Table 1\n\n## age (taken from https://www.tagrissohcp.com/metastatic/flaura/efficacy.html)\n# less than 65 years (54%, TRUE) to 65+ (46%, FALSE)\nage_target &lt;- c(.54, .46)\nnames(age_target) &lt;- c(\"&lt;65\", \"65+\")\n\n## sex ---------------------------------------------------------------------\n\n# female (0) to male (1) proportion:\nsex_target &lt;- c(.63, .37) \nnames(sex_target) &lt;- c(\"Female\", \"Male\")\n\n## race --------------------------------------------------------------------\n# asian, non-asian\n# asian (TRUE) to non-asian (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nrace_target &lt;- c(.62, .38)\nnames(race_target) &lt;- c(\"Asian\", \"Non-Asian\")\n\n## smoking -----------------------------------------------------------------\n\n# current/former smoker (TRUE) to never smoker (FALSE) proportion\n# note: logical variables in dataframe can be matched to a numeric vector of length 2 and ordered with the TRUE target as the first element and the FALSE target as the second element.\nsmoker_target &lt;- c(.35, .65)\nnames(smoker_target) &lt;- c(\"Current/former\", \"Never\")\n\n## ecog --------------------------------------------------------------------\n\n# ecog 0 to ecog 1 proportion\necog_target &lt;- c(.41, .59)\nnames(ecog_target) &lt;- c(\"0\", \"1\")\n\n# summarize target distributions in a named list vector --------------\ntargets &lt;- list(age_target, sex_target, race_target, smoker_target, ecog_target)\nnames(targets) &lt;- c(\"dem_age_lt65\", \"dem_sex_cont\", \"dem_race\", \"c_smoking_history\", \"c_ecog_cont\")\n\n# print\ntargets\n\n\n$dem_age_lt65\n &lt;65  65+ \n0.54 0.46 \n\n$dem_sex_cont\nFemale   Male \n  0.63   0.37 \n\n$dem_race\n    Asian Non-Asian \n     0.62      0.38 \n\n$c_smoking_history\nCurrent/former          Never \n          0.35           0.65 \n\n$c_ecog_cont\n   0    1 \n0.41 0.59",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#propensity-score-matching-and-re-weighting",
    "href": "chapters/re_weight.html#propensity-score-matching-and-re-weighting",
    "title": "4  Re-weighting to a target population",
    "section": "4.4 Propensity score matching and re-weighting",
    "text": "4.4 Propensity score matching and re-weighting\nIn this step, propensity score matching and re-weighting of key patient characteristics to match those of the original RCT is performed across all imputed datasets.\nThe propensity score model is specified as follows:\n\n\nShow the code\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates_for_ps, collapse = \" + \")))\nps_form\n\n\ntreat ~ dem_age_index_cont + dem_sex_cont + c_smoking_history + \n    c_number_met_sites + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_ecog_cont + c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + \n    c_ast_alt_ratio_cont + c_stage_initial_dx_cont + dem_race + \n    dem_region + dem_ses + c_time_dx_to_index\n\n\nThe matching and re-weighting is performed using the re_weight() function. This function is a wrapper for matchit() and weightit() in combination with the anesrake() function which performs the raking (= re-weighting) procedure.\nWe apply this function to each imputed dataset. Before doing so, the imputed datasets, which are currently stored as a mids object, needs to be converted to a list of dataframes:\n\n\nShow the code\n# create a mild object containing lists of data.frames\ndata_mild &lt;- mice::complete(data = data_imp, action = \"all\", include = FALSE)\n\nsummary(data_mild)\n\n\n   Length Class      Mode\n1  40     data.frame list\n2  40     data.frame list\n3  40     data.frame list\n4  40     data.frame list\n5  40     data.frame list\n6  40     data.frame list\n7  40     data.frame list\n8  40     data.frame list\n9  40     data.frame list\n10 40     data.frame list\n\n\nThe lapply function loops the function through each dataframe and returns a list of matchit objects which contain imputed &gt; matched &gt; re-weighted datasets. To take advantage of the features that come with the cobalt and matchthem packages, the function stores the raking weights as sampling weights (s.weights).\n\n\nShow the code\n# call match re-weight\nmatchit_out_list &lt;- lapply(\n  # list of dataframes\n  X = data_mild, \n  # call function\n  FUN = re_weight,\n  # target distributions\n  targets = targets,\n  # should matching or weighting be performed\n  matching_weighting = \"matching\",\n  # matching arguments passed on to matchit() function\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 12 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 11 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 14 iterations\"\n[1] \"Raking converged in 8 iterations\"\n[1] \"Raking converged in 9 iterations\"\n[1] \"Raking converged in 11 iterations\"\n\n\nWe can inspect the output of the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\nmatchit_out_list[[1]]\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n             - sampling weights not included in estimation\n - caliper: &lt;distance&gt; (0.003)\n - number of obs.: 3500 (original), 2924 (matched)\n - sampling weights: present\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, c_smoking_history, c_number_met_sites, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_ecog_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_stage_initial_dx_cont, dem_race, dem_region, dem_ses, c_time_dx_to_index",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#table-1",
    "href": "chapters/re_weight.html#table-1",
    "title": "4  Re-weighting to a target population",
    "section": "4.5 Table 1",
    "text": "4.5 Table 1\nTo check if the re-weighting process worked, we can extract the matched patients and compare a Table 1 that does not include the weights vs. a Table that considers the weights. For this example, we look at the first imputed &gt; matched &gt; re-weighted dataset.\n\n\nShow the code\n# extract the matched of\nfirst_dataset &lt;- get_matches(\n  object = matchit_out_list[[1]]\n  )\n\n\n\nReminder : The target distributions look like this\n\n\n\nShow the code\ntargets\n\n\n$dem_age_lt65\n &lt;65  65+ \n0.54 0.46 \n\n$dem_sex_cont\nFemale   Male \n  0.63   0.37 \n\n$dem_race\n    Asian Non-Asian \n     0.62      0.38 \n\n$c_smoking_history\nCurrent/former          Never \n          0.35           0.65 \n\n$c_ecog_cont\n   0    1 \n0.41 0.59 \n\n\n\nUnweighted Table 1Weighted Table 1\n\n\n\n\nShow the code\nlibrary(cardx)\nlibrary(smd)\n\n# print\nfirst_dataset |&gt;\n  tbl_summary(\n    by = treat,\n    include = c(dem_age_index_cont, names(targets))\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\nTable 4.2: Table 1 BEFORE re-weighting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 2924\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 1462  (50.0%)\n1\n1  N = 1462  (50.0%)\n1\n\n\n\n\ndem_age_index_cont\n69 (63, 74)\n69 (63, 74)\n69 (63, 74)\n-0.02\n\n\ndem_age_lt65\n\n\n\n\n\n\n0.01\n\n\n    &lt;65\n930 (32%)\n460 (31%)\n470 (32%)\n\n\n\n\n    65+\n1,994 (68%)\n1,002 (69%)\n992 (68%)\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.01\n\n\n    Female\n1,927 (66%)\n961 (66%)\n966 (66%)\n\n\n\n\n    Male\n997 (34%)\n501 (34%)\n496 (34%)\n\n\n\n\ndem_race\n\n\n\n\n\n\n0.01\n\n\n    Asian\n1,780 (61%)\n885 (61%)\n895 (61%)\n\n\n\n\n    Non-Asian\n1,144 (39%)\n577 (39%)\n567 (39%)\n\n\n\n\nc_smoking_history\n\n\n\n\n\n\n0.02\n\n\n    Current/former\n1,313 (45%)\n664 (45%)\n649 (44%)\n\n\n\n\n    Never\n1,611 (55%)\n798 (55%)\n813 (56%)\n\n\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.00\n\n\n    0\n1,271 (43%)\n635 (43%)\n636 (44%)\n\n\n\n\n    1\n1,653 (57%)\n827 (57%)\n826 (56%)\n\n\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# create survey object \ndata_svy &lt;- svydesign(ids = ~ 1, weights = ~ weights, data = first_dataset)\n\n# print\ndata_svy |&gt;\n  tbl_svysummary(\n    by = treat,\n    include = c(dem_age_index_cont, names(targets))\n    ) |&gt; \n  add_difference(test = dplyr::everything() ~ \"smd\") |&gt;\n  add_overall() |&gt;\n  modify_column_hide(columns = \"conf.low\") |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {round(N, 2)}\",\n    stat_1 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**{level}** &lt;br&gt; N = {round(n, 2)} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt;\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\")\n\n\n\n\nTable 4.3: Table 1 AFTER re-weighting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 2924\n1\n\nTreatment received\n\nDifference\n2\n\n\n0  N = 1449.08  (49.6%)\n1\n1  N = 1474.92  (50.4%)\n1\n\n\n\n\ndem_age_index_cont\n64 (61, 72)\n65 (61, 71)\n64 (60, 72)\n0.01\n\n\ndem_age_lt65\n\n\n\n\n\n\n0.03\n\n\n    &lt;65\n1,579 (54%)\n771 (53%)\n808 (55%)\n\n\n\n\n    65+\n1,345 (46%)\n678 (47%)\n667 (45%)\n\n\n\n\ndem_sex_cont\n\n\n\n\n\n\n0.00\n\n\n    Female\n1,842 (63%)\n911 (63%)\n931 (63%)\n\n\n\n\n    Male\n1,082 (37%)\n538 (37%)\n544 (37%)\n\n\n\n\ndem_race\n\n\n\n\n\n\n0.03\n\n\n    Asian\n1,797 (61%)\n879 (61%)\n918 (62%)\n\n\n\n\n    Non-Asian\n1,127 (39%)\n570 (39%)\n557 (38%)\n\n\n\n\nc_smoking_history\n\n\n\n\n\n\n0.06\n\n\n    Current/former\n1,023 (35%)\n528 (36%)\n496 (34%)\n\n\n\n\n    Never\n1,901 (65%)\n921 (64%)\n979 (66%)\n\n\n\n\nc_ecog_cont\n\n\n\n\n\n\n0.02\n\n\n    0\n1,259 (43%)\n618 (43%)\n641 (43%)\n\n\n\n\n    1\n1,665 (57%)\n831 (57%)\n834 (57%)\n\n\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n2\nStandardized Mean Difference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.1 Comparison of custom function vs. matchthem()\nLastly, we want to make sure that our custom function results in the same matched datasets as the matchthem() function which we use in the main analysis - not considering the re-weighting.\nFor this demonstration, we use the same matching parameters, but without re-weighting after matching in our custom function.\n\n\n\n4.5.2 Custom function\nWe run again our custom function but with targets = NULL to not re-weight any of the included covariates. To convert the returned output of a list of matchit objects into an object of type mimids we use the MatchThem::as.mimids() function.\n\n\nShow the code\n# call match re-weight\nset.seed(42)\nmatchit_out_list &lt;- lapply(\n  X = data_mild, \n  FUN = re_weight,\n  targets = NULL,\n  matching_weighting = \"matching\",\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nNo target distributions specified, no re-weighting will be performed.\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\nShow the code\n# convert the output into a mimids object\ndata_mimids_from_function &lt;- MatchThem::as.mimids(\n  x = matchit_out_list, \n  datasets = data_imp\n  )\n\ndata_mimids_from_function\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.003)\n - number of obs.: 3500 (original), 2924 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, c_smoking_history, c_number_met_sites, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_ecog_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_stage_initial_dx_cont, dem_race, dem_region, dem_ses, c_time_dx_to_index\n\n\n\n\n4.5.3 matchthem() function\nThe following code resembles the code we would use in the main analysis by implementing the generic matchthem() function.\n\n\nShow the code\n# matching\nset.seed(42)\ndata_mimids &lt;- matchthem(\n  datasets = data_imp,\n  formula = ps_form,\n  ratio = 1,\n  method = \"nearest\",\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.05,\n  replace = F\n  )\n\n\n\nMatching Observations  | dataset: #1\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#2\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#3\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#4\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#5\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#6\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#7\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#8\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#9\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n#10\n\n\nWarning: Fewer control units than treated units; not all treated units will get\na match.\n\n\n\n\n\nShow the code\ndata_mimids\n\n\nPrinting               | dataset: #1\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.003)\n - number of obs.: 3500 (original), 2924 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, c_smoking_history, c_number_met_sites, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_ecog_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_stage_initial_dx_cont, dem_race, dem_region, dem_ses, c_time_dx_to_index\n\n\n\n\n4.5.4 Comparison of stacked datasets\nWe can now stack the datasets (= vertically append them) and compare the resulting 10 x 10 datasets for any differences:\n\n\nShow the code\nwaldo::compare(\n  MatchThem::complete(data_mimids_from_function), \n  MatchThem::complete(data_mimids)\n  )\n\n\n✔ No differences",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#session-info",
    "href": "chapters/re_weight.html#session-info",
    "title": "4  Re-weighting to a target population",
    "section": "4.6 Session info",
    "text": "4.6 Session info\nScript runtime: 0.46 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\n\nShow the code\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ncardx\ncardx\n0.2.0\n\n\ndplyr\ndplyr\n1.1.4\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchIt\nMatchIt\n4.5.5\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nsmd\nsmd\n0.7.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\n\nShow the code\npander::pander(sessionInfo())\n\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: smd(v.0.7.0), cardx(v.0.2.0), gtsummary(v.2.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchIt(v.4.5.5), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8), dplyr(v.1.1.4) and here(v.1.0.1)\nloaded via a namespace (and not attached): tidyselect(v.1.2.1), fastmap(v.1.2.0), digest(v.0.6.37), rpart(v.4.1.23), lifecycle(v.1.0.4), cluster(v.2.1.6), waldo(v.0.5.3), gdata(v.3.0.0), magrittr(v.2.0.3), compiler(v.4.4.0), sass(v.0.4.9), rlang(v.1.1.4), Hmisc(v.5.1-3), tools(v.4.4.0), gt(v.0.11.0), utf8(v.1.2.4), yaml(v.2.3.10), data.table(v.1.16.0), knitr(v.1.48), htmlwidgets(v.1.6.4), xml2(v.1.3.6), withr(v.3.0.1), foreign(v.0.8-86), purrr(v.1.0.2), nnet(v.7.3-19), fansi(v.1.0.6), jomo(v.2.7-6), colorspace(v.2.1-1), future(v.1.34.0), ggplot2(v.3.5.1), gtools(v.3.9.5), globals(v.0.16.3), scales(v.1.3.0), iterators(v.1.0.14), MASS(v.7.3-60.2), cli(v.3.6.3), rmarkdown(v.2.28), crayon(v.1.5.3), generics(v.0.1.3), rstudioapi(v.0.16.0), sessioninfo(v.1.2.2), commonmark(v.1.9.1), minqa(v.1.2.8), DBI(v.1.2.3), pander(v.0.6.5), stringr(v.1.5.1), splines(v.4.4.0), assertthat(v.0.2.1), parallel(v.4.4.0), base64enc(v.0.1-3), mitools(v.2.4), vctrs(v.0.6.5), WeightIt(v.1.3.0), boot(v.1.3-30), glmnet(v.4.1-8), jsonlite(v.1.8.8), mitml(v.0.4-5), Formula(v.1.2-5), htmlTable(v.2.4.3), listenv(v.0.9.1), weights(v.1.0.4), locfit(v.1.5-9.10), foreach(v.1.5.2), tidyr(v.1.3.1), glue(v.1.7.0), parallelly(v.1.38.0), nloptr(v.2.1.1), pan(v.1.9), chk(v.0.9.2), codetools(v.0.2-20), stringi(v.1.8.4), shape(v.1.4.6.1), gtable(v.0.3.5), lme4(v.1.1-35.5), munsell(v.0.5.1), tibble(v.3.2.1), anesrake(v.0.80), pillar(v.1.9.0), furrr(v.0.3.1), htmltools(v.0.5.8.1), R6(v.2.5.1), rprojroot(v.2.0.4), evaluate(v.0.24.0), lattice(v.0.22-6), markdown(v.1.13), cards(v.0.2.1), backports(v.1.5.0), tictoc(v.1.2.1), broom(v.1.0.6), renv(v.1.0.7), simsurv(v.1.0.0), Rcpp(v.1.0.13), checkmate(v.2.3.2), gridExtra(v.2.3), nlme(v.3.1-164), xfun(v.0.47) and pkgconfig(v.2.0.3)\n\n\n\n\n\n\nShow the code\npander::pander(options('repos'))\n\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html#section",
    "href": "chapters/re_weight.html#section",
    "title": "4  Re-weighting to a target population",
    "section": "4.7 ",
    "text": "4.7",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#about",
    "href": "chapters/subgroup_analysis.html#about",
    "title": "5  Subgroup analysis",
    "section": "5.1 About",
    "text": "5.1 About\nThis script is adapted from Noah Greifer’s highly recommended blog post on “Subgroup Analysis After Propensity Score Matching Using R”.\nFor a more formal manuscript on subgroup analysis with propensity scores, see Green and Stuart.(Green and Stuart 2014)"
  },
  {
    "objectID": "chapters/subgroup_analysis.html#data-generation",
    "href": "chapters/subgroup_analysis.html#data-generation",
    "title": "5  Subgroup analysis",
    "section": "5.2 Data generation",
    "text": "5.2 Data generation\nWe again use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\n\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE,\n  propNA = .13\n  ) |&gt; \n  # we simplify and assume a binary Asian/non-Asian race covariate where Asian is the reference group\n  mutate(dem_race = ifelse(dem_race == \"Asian\", 0, 1))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#moderator-covariate",
    "href": "chapters/subgroup_analysis.html#moderator-covariate",
    "title": "5  Subgroup analysis",
    "section": "5.3 Moderator covariate",
    "text": "5.3 Moderator covariate\nIn this example, we assume heterogeneous treatment effect by race and we aim to assess the average treatment effect among the treated for Asian (reference) and non-Asian patients. The effect size is time to all-cause mortality. In this dataset, race is encoded with a binary covariate with 0 = Asian and 1 = non-Asian.\n\ntable(data_miss$dem_race, useNA = \"ifany\")\n\n\n   0    1 &lt;NA&gt; \n1854 1166  480 \n\n\n\n\n\nInvestigated subgroup effect in the FLAURA trial.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#multiple-imputation",
    "href": "chapters/subgroup_analysis.html#multiple-imputation",
    "title": "5  Subgroup analysis",
    "section": "5.4 Multiple imputation",
    "text": "5.4 Multiple imputation\nBoth the imputation and propensity score step Multiple imputation using mice:\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#propensity-score-matching-and-weighting",
    "href": "chapters/subgroup_analysis.html#propensity-score-matching-and-weighting",
    "title": "5  Subgroup analysis",
    "section": "5.5 Propensity score matching and weighting",
    "text": "5.5 Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset.\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates_for_ps, collapse = \" + \")))\nps_form\n\ntreat ~ dem_age_index_cont + dem_sex_cont + c_smoking_history + \n    c_number_met_sites + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_ecog_cont + c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + \n    c_ast_alt_ratio_cont + c_stage_initial_dx_cont + dem_race + \n    dem_region + dem_ses + c_time_dx_to_index\n\n\n\nMatchingWeighting\n\n\n\nmatch_within_strata &lt;- function(i, \n                                imputed_data = NULL, \n                                ps_formula = NULL, \n                                filter_expr = NULL\n                                ){\n  \n  stratum &lt;- mice::complete(imputed_data, i) |&gt; \n    dplyr::filter(eval(filter_expr))\n    \n  matched &lt;- MatchIt::matchit(\n    formula = ps_formula, \n    data = stratum,\n    method = \"nearest\",\n    caliper = 0.01,\n    ratio = 1,\n    replace = F\n    ) |&gt; \n    MatchIt::match.data()\n  \n  return(matched)\n  \n}\n\nasian_matched &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = match_within_strata, \n  imputed_data = data_imp,\n  ps_formula = ps_form,\n  filter_expr = expr(dem_race == 0)\n  )\n\nnon_asian_matched &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = match_within_strata, \n  imputed_data = data_imp,\n  ps_formula = ps_form,\n  filter_expr = expr(dem_race == 1)\n  )\n\n# combine the mth imputed and matched datasets\ncombine_list &lt;- function(i, data_0 = NULL, data_1 = NULL){\n  \n  data_combined &lt;- rbind(data_0[[i]], data_1[[i]])\n  \n  return(data_combined)\n  \n}\n\nmatched_all &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = combine_list, \n  data_0 = non_asian_matched,\n  data_1 = asian_matched\n  )\n\n\n\n\nweight_within_strata &lt;- function(i, \n                                 imputed_data = NULL, \n                                 ps_formula = NULL,\n                                 filter_expr = NULL\n                                 ){\n  \n  stratum &lt;- mice::complete(imputed_data, i) |&gt; \n    dplyr::filter(eval(filter_expr))\n  \n  weighted &lt;- WeightIt::weightit(\n    formula = ps_formula, \n    data = stratum,\n    method = \"glm\",\n    estimand = \"ATT\"\n    )\n  \n  # trim extreme weights\n  weighted &lt;- trim(\n    x = weighted, \n    at = .95, \n    lower = TRUE\n    )\n  \n  weighted_data &lt;- mice::complete(imputed_data, i) |&gt; \n    dplyr::filter(eval(filter_expr)) |&gt; \n    mutate(weights = weighted$weights)\n  \n  return(weighted_data)\n  \n}\n\nasian_weighted &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = weight_within_strata, \n  imputed_data = data_imp,\n  ps_formula = ps_form,\n  filter_expr = expr(dem_race == 0)\n  )\n\nnon_asian_weighted &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = weight_within_strata, \n  imputed_data = data_imp,\n  ps_formula = ps_form,\n  filter_expr = expr(dem_race == 1)\n  )\n\nweighted_all &lt;- lapply(\n  X = 1:data_imp$m, \n  FUN = combine_list, \n  data_0 = asian_weighted,\n  data_1 = non_asian_weighted\n  )",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#outcome-model-comparisons",
    "href": "chapters/subgroup_analysis.html#outcome-model-comparisons",
    "title": "5  Subgroup analysis",
    "section": "5.6 Outcome model comparisons",
    "text": "5.6 Outcome model comparisons\n\nMatchingWeighting\n\n\n\ncox_fit_matching &lt;- function(i){\n  \n  survival_fit &lt;- survival::coxph(\n    data = i,\n    formula = Surv(fu_itt_months, death_itt) ~ treat*dem_race, \n    weights = weights, \n    cluster = subclass,\n    robust = TRUE\n    )\n  \n}\n\n\nmatched_all |&gt; \n  lapply(FUN = cox_fit_matching) |&gt; \n  mice::pool() |&gt; \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  dplyr::select(term, estimate, std.error, conf.low, conf.high)\n\n            term  estimate  std.error  conf.low conf.high\n1          treat 1.0164611 0.06285385 0.8964279 1.1525669\n2       dem_race 1.0168610 0.06594461 0.8929551 1.1579600\n3 treat:dem_race 0.5838534 0.10944305 0.4687215 0.7272652\n\n\n\n\n\ncox_fit_weighting &lt;- function(i){\n  \n  survival_fit &lt;- survival::coxph(\n    data = i,\n    formula = Surv(fu_itt_months, death_itt) ~ treat*dem_race, \n    weights = weights, \n    robust = TRUE\n    )\n  \n}\n\n\nweighted_all |&gt; \n  lapply(FUN = cox_fit_weighting) |&gt; \n  mice::pool() |&gt; \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  dplyr::select(term, estimate, std.error, conf.low, conf.high)\n\n            term  estimate  std.error  conf.low conf.high\n1          treat 1.0129437 0.04540748 0.9265436  1.107401\n2       dem_race 1.0140269 0.05675557 0.9070347  1.133640\n3 treat:dem_race 0.5930234 0.07725232 0.5094262  0.690339",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#session-info",
    "href": "chapters/subgroup_analysis.html#session-info",
    "title": "5  Subgroup analysis",
    "section": "5.8 Session info",
    "text": "5.8 Session info\nScript runtime: 0.66 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\n\n \npackage\nloadedversion\n\n\n\n\ndplyr\ndplyr\n1.1.4\n\n\nfurrr\nfurrr\n0.3.1\n\n\nfuture\nfuture\n1.34.0\n\n\ngtsummary\ngtsummary\n2.0.1\n\n\nhere\nhere\n1.0.1\n\n\nMatchThem\nMatchThem\n1.2.1\n\n\nMatrix\nMatrix\n1.7-0\n\n\nmice\nmice\n3.16.0\n\n\nparallelly\nparallelly\n1.38.0\n\n\nranger\nranger\n0.16.0\n\n\nsurvey\nsurvey\n4.4-2\n\n\nsurvival\nsurvival\n3.5-8\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: grid, stats, graphics, grDevices, datasets, utils, methods and base\nother attached packages: furrr(v.0.3.1), future(v.1.34.0), ranger(v.0.16.0), parallelly(v.1.38.0), gtsummary(v.2.0.1), here(v.1.0.1), survey(v.4.4-2), Matrix(v.1.7-0), MatchThem(v.1.2.1), mice(v.3.16.0), survival(v.3.5-8) and dplyr(v.1.1.4)\nloaded via a namespace (and not attached): gtable(v.0.3.5), shape(v.1.4.6.1), xfun(v.0.47), ggplot2(v.3.5.1), htmlwidgets(v.1.6.4), MatchIt(v.4.5.5), lattice(v.0.22-6), simsurv(v.1.0.0), vctrs(v.0.6.5), tools(v.4.4.0), generics(v.0.1.3), parallel(v.4.4.0), tibble(v.3.2.1), fansi(v.1.0.6), pan(v.1.9), pkgconfig(v.2.0.3), jomo(v.2.7-6), assertthat(v.0.2.1), lifecycle(v.1.0.4), stringr(v.1.5.1), compiler(v.4.4.0), tictoc(v.1.2.1), munsell(v.0.5.1), mitools(v.2.4), codetools(v.0.2-20), htmltools(v.0.5.8.1), yaml(v.2.3.10), glmnet(v.4.1-8), pillar(v.1.9.0), nloptr(v.2.1.1), crayon(v.1.5.3), tidyr(v.1.3.1), MASS(v.7.3-60.2), sessioninfo(v.1.2.2), iterators(v.1.0.14), rpart(v.4.1.23), boot(v.1.3-30), foreach(v.1.5.2), mitml(v.0.4-5), nlme(v.3.1-164), locfit(v.1.5-9.10), WeightIt(v.1.3.0), tidyselect(v.1.2.1), digest(v.0.6.37), stringi(v.1.8.4), pander(v.0.6.5), listenv(v.0.9.1), purrr(v.1.0.2), splines(v.4.4.0), rprojroot(v.2.0.4), fastmap(v.1.2.0), colorspace(v.2.1-1), cli(v.3.6.3), magrittr(v.2.0.3), utf8(v.1.2.4), broom(v.1.0.6), withr(v.3.0.1), scales(v.1.3.0), backports(v.1.5.0), rmarkdown(v.2.28), globals(v.0.16.3), nnet(v.7.3-19), lme4(v.1.1-35.5), chk(v.0.9.2), evaluate(v.0.24.0), knitr(v.1.48), rlang(v.1.1.4), Rcpp(v.1.0.13), glue(v.1.7.0), DBI(v.1.2.3), renv(v.1.0.7), rstudioapi(v.0.16.0), minqa(v.1.2.8), jsonlite(v.1.8.8) and R6(v.2.5.1)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html#references",
    "href": "chapters/subgroup_analysis.html#references",
    "title": "5  Subgroup analysis",
    "section": "5.7 References",
    "text": "5.7 References\n\n\nGreen, Kerry M., and Elizabeth A. Stuart. 2014. “Examining Moderation Analyses in Propensity Score Methods: Application to Depression and Substance Use.” Journal of Consulting and Clinical Psychology 82 (5): 773–83. https://doi.org/10.1037/a0036515.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/whole_game.html#background",
    "href": "chapters/whole_game.html#background",
    "title": "2  The whole game",
    "section": "",
    "text": "In 2022, nearly every third drug approval was granted in the field of oncology (tendency ↑)(Mullard 2022)\nDecision-makers increasingly rely on real-world evidence (RWE) generated from routine-care health data such as electronic health records (EHR) to evaluate the comparative safety and effectiveness of novel cancer therapies\n\n\n\nThe ENCORE project is an RCT DUPLICATE expansion to oncology which is going to emulate 12 randomized clinical trials using multiple EHR data sources. The process includes an emphasis on transparency with documented assessment of data fitness of the RWD source for each trial and conducting extensive sensitivity analyses to assess robustness of findings and trial eligibility criteria.\nPartially observed covariates/confounders are a common and pervasive challenge\nTo date, most oncology studies utilizing RWD have relied on complete case analysis although assumptions for a complete case analysis (missing completely at random [MCAR]) are even stronger than those (missing at random [MAR]) for multiple imputation (MI). Besides this, MI has additional advantages:\n\nAll patients are retained\nFlexible modeling (parametric, non-parametric)\nCan incorporate additional information (auxiliary covariates) to make the MAR assumption more likely\nRealistic variance estimation (Rubin’s rule)\n\nHowever:\n\nNot much is known about how to use multiple imputation in combination with propensity score-based approaches\nComputational implementation can be complex",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The whole game</span>"
    ]
  },
  {
    "objectID": "chapters/whole_game.html#objective",
    "href": "chapters/whole_game.html#objective",
    "title": "2  The whole game",
    "section": "2.2 Objective",
    "text": "2.2 Objective\n\n\n\n\n\n\nObjective\n\n\n\nTo establish a computationally reproducible workflow that streamlines multiple imputation &gt; propensity score matching/weighting &gt; survival analysis workflows in a transparent fashion\n\n\n\n\n\n\n\n\nFigure 2.1: Streamlined workflow to approach partially observed covariate data in oncology trial emulations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The whole game</span>"
    ]
  },
  {
    "objectID": "chapters/whole_game.html#leyrat-et-al.-simulation-study",
    "href": "chapters/whole_game.html#leyrat-et-al.-simulation-study",
    "title": "2  The whole game",
    "section": "2.3 Leyrat et al. simulation study",
    "text": "2.3 Leyrat et al. simulation study\nOne of the most comprehensive and influental simulation studies that addressed the question on how to combine multiple imputation with propensity scores (IPTW weighting) was published in 2019 by Leyrat et al. (Leyrat et al. 2019). In this study, the authors looked at three different potential ways:\n\nMIte: MI &gt; PS estimation &gt; Outcome model for each PS model &gt; Pooling of results\nMIps: MI &gt; PS estimation &gt; PS pooling across datasets &gt; single outcome model\nMIpar: MI &gt; Pooling of covariate parameters &gt; single PS model &gt; single outcome model\n\nAdditional questions that were also addressed:\n\nShould outcome be included in imputation model?\nHow to estimate variance of IPTW estimator in context of MIte or MIps or MIpar?\n\n\n\n\n\n\n\nFigure 2.2: Illustration of potential approaches that could be considered after multiple imputation (MI) of the partially observed covariates are missing values on the original dataset.\n\n\n\n\n2.3.1 Simulation study results\n\nMIte performed best in terms of bias, standardized differences/balancing, coverage rate and variance estimation\n\nMI &gt; PS estimation &gt; Outcome model for each PS model &gt; Pooling of results\n\nStandard IPTW variance estimation is valid for MIte\nOutcome must be included in imputation model\n\n\n\n\n\n\n\nFigure 2.3: Leyrat et al. simulation study results.\n\n\n\n\n\n2.3.2 Implementation in MatchThem R package\nTo streamline the implementation of multiple imputation &gt; propensity score workflows, Farhad Pishgar, Noah Greifer, Clémence Leyrat and Elizabeth Stuart developed the MatchThem package (Pishgar et al. 2021) which relies on the functionality provided by the mice, MatchIt, and WeightIt packages. An exemplary illustration on how to use the package in a survival analysis context is given in Chapter 3 (cheatsheet).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The whole game</span>"
    ]
  },
  {
    "objectID": "chapters/whole_game.html#session-info",
    "href": "chapters/whole_game.html#session-info",
    "title": "2  The whole game",
    "section": "2.5 Session info",
    "text": "2.5 Session info\nScript runtime: 0.00 minutes.\n\nLoaded packagesSession infoRepositories\n\n\n\npander::pander(subset(data.frame(sessioninfo::package_info()), attached==TRUE, c(package, loadedversion)))\n\n\n\n\n\n\n\n\npackage\nloadedversion\n\n\n\n\n\n\n\n\npander::pander(sessionInfo())\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nlocale: en_US.UTF-8||en_US.UTF-8||en_US.UTF-8||C||en_US.UTF-8||en_US.UTF-8\nattached base packages: stats, graphics, grDevices, datasets, utils, methods and base\nloaded via a namespace (and not attached): digest(v.0.6.37), fastmap(v.1.2.0), xfun(v.0.47), tictoc(v.1.2.1), knitr(v.1.48), htmltools(v.0.5.8.1), rmarkdown(v.2.28), cli(v.3.6.3), pander(v.0.6.5), sessioninfo(v.1.2.2), renv(v.1.0.7), compiler(v.4.4.0), rstudioapi(v.0.16.0), tools(v.4.4.0), evaluate(v.0.24.0), Rcpp(v.1.0.13), yaml(v.2.3.10), rlang(v.1.1.4), jsonlite(v.1.8.8) and htmlwidgets(v.1.6.4)\n\n\n\n\n\npander::pander(options('repos'))\n\n\nrepos:\n\n\n\n\n\n\nREPO_NAME\n\n\n\n\nhttps://packagemanager.posit.co/cran/latest"
  },
  {
    "objectID": "chapters/whole_game.html#references",
    "href": "chapters/whole_game.html#references",
    "title": "2  The whole game",
    "section": "2.4 References",
    "text": "2.4 References\n\n\nBuuren, Stef van, and Karin Groothuis-Oudshoorn. 2011.\n“Mice: Multivariate Imputation by\nChained Equations in r” 45: 1–67. https://doi.org/10.18637/jss.v045.i03.\n\n\nGreen, Kerry M., and Elizabeth A. Stuart. 2014. “Examining\nModeration Analyses in Propensity Score Methods: Application to\nDepression and Substance Use.” Journal of Consulting and\nClinical Psychology 82 (5): 773–83. https://doi.org/10.1037/a0036515.\n\n\nLeyrat, Clémence, Shaun R Seaman, Ian R White, Ian Douglas, Liam Smeeth,\nJoseph Kim, Matthieu Resche-Rigon, James R Carpenter, and Elizabeth J\nWilliamson. 2019. “Propensity Score Analysis with Partially\nObserved Covariates: How Should Multiple Imputation Be Used?”\nStatistical Methods in Medical Research 28 (1): 3–19. https://doi.org/10.1177/0962280217713032.\n\n\nLumley, Thomas. 2024. “Survey: Analysis of Complex Survey\nSamples.”\n\n\nMullard, Asher. 2022. “2021 FDA Approvals.” Nature\nReviews Drug Discovery 21 (2): 83–88. https://doi.org/10.1038/d41573-022-00001-9.\n\n\nPishgar, Farhad, Noah Greifer, Clémence Leyrat, and Elizabeth Stuart.\n2021. “MatchThem: Matching and Weighting after Multiple\nImputation.” R Journal 13 (2): 292–305. https://doi.org/10.32614/RJ-2021-073.\n\n\nShah, Anoop D., Jonathan W. Bartlett, James Carpenter, Owen Nicholas,\nand Harry Hemingway. 2014. “Comparison of random forest and\nparametric imputation models for imputing missing data using MICE: a\nCALIBER study.” American Journal of Epidemiology 179\n(6): 764–74. https://doi.org/10.1093/aje/kwt312.\n\n\nStekhoven, Daniel J., and Peter Bühlmann. 2012.\n“MissForestnon-Parametric Missing Value Imputation\nfor Mixed-Type Data.” Bioinformatics 28 (1): 112–18. https://doi.org/10.1093/bioinformatics/btr597.\n\n\nTherneau, Terry M. 2024. “A Package for Survival Analysis in\nr.” https://CRAN.R-project.org/package=survival.\n\n\nWeberpals, Janick, Sudha Raman, Pamela Shaw, Hana Lee, Massimiliano\nRusso, Bradley Hammill, Sengwee Toh, et al. 2024. “A Principled\nApproach to Characterize and Analyze Partially Observed Confounder Data\nfrom Electronic Health Records.” Clinical Epidemiology\nVolume 16 (May): 329–43. https://doi.org/10.2147/clep.s436131.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The whole game</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#comparison-of-coxph-versus-svycoxph-after-multiple-imputation-and-propensity-score-matching",
    "href": "chapters/syvcox_coxph.html#comparison-of-coxph-versus-svycoxph-after-multiple-imputation-and-propensity-score-matching",
    "title": "3  Application in Cox PH models",
    "section": "3.1 Comparison of coxph versus svycoxph after multiple imputation and propensity score matching",
    "text": "3.1 Comparison of coxph versus svycoxph after multiple imputation and propensity score matching\nIn Chapter 3 we illustrate a reproducible example on how to use coxph (survival package (Therneau 2024)) and svycoxph (survey package (Lumley 2024)) in combination with multiple imputation by chained equations (mice package (Buuren and Groothuis-Oudshoorn 2011)) and propensity score matching using the MatchThem package (Pishgar et al. 2021).\nFirst, we load the required R libraries/packages and some custom functions that are part of the encore.io R package that is being developed to streamline the analysis of all ENCORE trial emulations (non-public package).\n\nlibrary(dplyr)\nlibrary(survival)\nlibrary(mice)\nlibrary(MatchThem)\nlibrary(survey)\nlibrary(here)\nlibrary(gtsummary)\nlibrary(parallelly)\nlibrary(ranger)\nlibrary(furrr)\n\nsource(here(\"functions\", \"source_encore.io_functions.R\"))\n\n# track time\nruntime &lt;- tictoc::tic()"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-1-multiple-imputation",
    "href": "chapters/syvcox_coxph.html#step-1-multiple-imputation",
    "title": "3  Application in Cox PH models",
    "section": "3.2 Step 1: Multiple imputation",
    "text": "3.2 Step 1: Multiple imputation\nThe first step after deriving the analytic cohort includes the creation of multiple imputed datasets using mice R package(Buuren and Groothuis-Oudshoorn 2011).\n\nThe mice algorithm is one particular instance of a fully conditionally specified model. The algorithm starts with a random draw from the observed data, and imputes the incomplete data in a variable-by-variable fashion. One iteration consists of one cycle through all \\(Y_j\\).\n\n\n\n\nMICE algorithm for imputation of multivariate missing data.\n\n\nThe number of iterations \\(M\\) (= number of imputed datasets) in this example is 10, but in ENCORE we follow Stef van Buuren’s advice:\n\n[…] if calculation is not prohibitive, we may set \\(M\\) to the average percentage of missing data.\n(Flexible imputation of Missing Data, Sub-chapter 2.8)\n\nFollowing the results of various simulation studies (Shah et al. 2014; Weberpals et al. 2024), we use a non-parametric (random forest-based) imputation approach as the actual imputation algorithm.\n\n\n\n\n\n\nAdvantages of non-parametric imputation approaches\n\n\n\n\nParametric imputation models have to be correctly specified, i.e. also have to explicitly model nonlinear and non-additive covariate relationships\nMany imputation algorithms are not prepared for mixed type of data\nPopular: random forest-based algorithms\n\nfor each variable random forest is fit on the observed part and then predicts the missing part\nmissForest(Stekhoven and Bühlmann 2012) provides OOB error but only provides single imputations\nAlternatives: rf, cart in mice package (Buuren and Groothuis-Oudshoorn 2011)\n\n\n\n\nNote: In this example we utilize the futuremice() instead of the legacy mice() function to run the mice imputation across 7 cores in parallel.\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\nThe imputation step creates an object of class…\n\nclass(data_imp)\n\n[1] \"mids\"\n\n\n…which stands for multiple imputed datasets. It contains important information on the imputation procedure and the actual imputed datasets."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Multiple imputation-propensity score workflows",
    "section": "Background",
    "text": "Background\nMultiple imputation is a powerful tool in presence of missing data. However, especially in combination with propensity score analyses, multiple imputation can lead to challenges since analytic workflows can be become much more complex."
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-2-propensity-score-matching-and-weighting",
    "href": "chapters/syvcox_coxph.html#step-2-propensity-score-matching-and-weighting",
    "title": "3  Application in Cox PH models",
    "section": "3.3 Step 2: Propensity score matching and weighting",
    "text": "3.3 Step 2: Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset. As pointed in Section 2.3.1, the MIte approach performed best in terms of bias, standardized differences/balancing, coverage rate and variance estimation. In MatchThem this approach is referred to a within approach (performing matching within each dataset), while the inferior MIps approach (estimating propensity scores within each dataset, averaging them across datasets, and performing matching using the averaged propensity scores in each dataset) is referred to as across approach. Since MIte/within has been shown to have superior performance in most cases, we only illustrate this approach here.\nLet’s assume we fit the following propensity score model within each imputed dataset.\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))\nps_form\n\ntreat ~ dem_age_index_cont + dem_sex_cont + dem_race + dem_region + \n    dem_ses + c_smoking_history + c_number_met_sites + c_ecog_cont + \n    c_stage_initial_dx_cont + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + c_ast_alt_ratio_cont + \n    c_time_dx_to_index + c_de_novo_mets_dx + c_height_cont + \n    c_weight_cont + c_dbp_cont + c_year_index\n\n\n\nMatchingWeighting\n\n\nThe matching step happens using the matchthem() function, which is a wrapper around the matchit() function. This function not only provides the functionality to match on the propensity score, but also to perform (coarsened) exact matching, cardinality matching, genetic matching and more. In this example, we use a simple 1:1 nearest neighbor matching on the propensity score (estimated through logistic regression) without replacement with a caliper of 1% of the standard deviation of the propensity score.\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# print summary for matched dataset #1\ndata_mimids\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.005)\n - number of obs.: 3500 (original), 336 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n\n\nThe resulting “mimids” object contains the original imputed data and the output of the calls to matchit() applied to each imputed dataset.\n\n\nThe weighting step is performed very similarly using the weightthem() function. In this example weapply SMR weighting to arrive at the same ATT estimand as matching which is indicated through the estimand = \"ATT\" argument. In case we wanted to weight patients based on overlap weights, estimand = \"AT0\" would need to be specified (which is one of the sensitivity analyses in the FLAURA protocol).\nTo mitigate the risks of extreme weights, the subsequent trim() function truncates large weights by setting all weights higher than that at a given quantile (in this example the 95% quantile) to the weight at the quantile. Since we specify lower = TRUE, this is done symmetrically also with the 5% quantile.\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )\n\ndata_wimids\n\nA weightit object\n - method: \"glm\" (propensity score weighting with GLM)\n - number of obs.: 3500\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: 1)\n - covariates: dem_age_index_cont, dem_sex_cont, dem_race, dem_region, dem_ses, c_smoking_history, c_number_met_sites, c_ecog_cont, c_stage_initial_dx_cont, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_time_dx_to_index, c_de_novo_mets_dx, c_height_cont, c_weight_cont, c_dbp_cont, c_year_index\n - weights trimmed at 5% and 95%\n\n\nThe resulting “wimids” object contains the original imputed data and the output of the calls to weightit() applied to each imputed dataset."
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-4-outcome-model-comparisons",
    "href": "chapters/syvcox_coxph.html#step-4-outcome-model-comparisons",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Step 4: Outcome model comparisons",
    "text": "3.4 Step 4: Outcome model comparisons"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-4-estimation-of-marginal-treatment-effects",
    "href": "chapters/syvcox_coxph.html#step-4-estimation-of-marginal-treatment-effects",
    "title": "3  Application in Cox PH models",
    "section": "3.5 Step 4: Estimation of marginal treatment effects",
    "text": "3.5 Step 4: Estimation of marginal treatment effects\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n3.5.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n3.5.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate std.error  conf.low conf.high\n1 survival treat 0.6807406 0.1584256 0.4922441 0.9414186\n2   survey treat 0.6807406 0.1586700 0.4934002 0.9392128\n\n\n\n\n\n\n3.5.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n3.5.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7761114 0.07023749 0.6758481 0.8912490\n2   survey treat 0.7761114 0.07024572 0.6758771 0.8912107"
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-1---multiple-imputation",
    "href": "chapters/syvcox_coxph.html#step-1---multiple-imputation",
    "title": "3  Application in Cox PH models",
    "section": "3.2 Step 1 - Multiple imputation",
    "text": "3.2 Step 1 - Multiple imputation\nThe first step after deriving the analytic cohort includes the creation of multiple imputed datasets using mice R package(Buuren and Groothuis-Oudshoorn 2011).\n\nThe mice algorithm is one particular instance of a fully conditionally specified model. The algorithm starts with a random draw from the observed data, and imputes the incomplete data in a variable-by-variable fashion. One iteration consists of one cycle through all \\(Y_j\\).\n\n\n\n\nMICE algorithm for imputation of multivariate missing data.\n\n\nThe number of iterations \\(M\\) (= number of imputed datasets) in this example is 10, but in ENCORE we follow Stef van Buuren’s advice:\n\n[…] if calculation is not prohibitive, we may set \\(M\\) to the average percentage of missing data.\n(Flexible imputation of Missing Data, Sub-chapter 2.8)\n\nFollowing the results of various simulation studies (Shah et al. 2014; Weberpals et al. 2024), we use a non-parametric (random forest-based) imputation approach as the actual imputation algorithm.\n\n\n\n\n\n\nAdvantages of non-parametric imputation approaches\n\n\n\n\nParametric imputation models have to be correctly specified, i.e. also have to explicitly model nonlinear and non-additive covariate relationships\nMany imputation algorithms are not prepared for mixed type of data\nPopular: random forest-based algorithms\n\nfor each variable random forest is fit on the observed part and then predicts the missing part\nmissForest(Stekhoven and Bühlmann 2012) provides OOB error but only provides single imputations\nAlternatives: rf, cart in mice package (Buuren and Groothuis-Oudshoorn 2011)\n\n\n\n\nNote: In this example we utilize the futuremice() instead of the legacy mice() function to run the mice imputation across 9 cores in parallel.\n\n# impute data\ndata_imp &lt;- futuremice(\n  parallelseed = 42,\n  n.core = parallel::detectCores()-1,\n  data = data_miss,\n  method = \"rf\",\n  m = 10,\n  print = FALSE\n  )\n\nThe imputation step creates an object of class…\n\nclass(data_imp)\n\n[1] \"mids\"\n\n\n…which stands for multiple imputed datasets. It contains important information on the imputation procedure and the actual imputed datasets.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-2---propensity-score-matching-and-weighting",
    "href": "chapters/syvcox_coxph.html#step-2---propensity-score-matching-and-weighting",
    "title": "3  Application in Cox PH models",
    "section": "3.3 Step 2 - Propensity score matching and weighting",
    "text": "3.3 Step 2 - Propensity score matching and weighting\nApply propensity score matching and weighting with replacement within in each imputed dataset. As pointed in Section 2.3.1, the MIte approach performed best in terms of bias, standardized differences/balancing, coverage rate and variance estimation. In MatchThem this approach is referred to a within approach (performing matching within each dataset), while the inferior MIps approach (estimating propensity scores within each dataset, averaging them across datasets, and performing matching using the averaged propensity scores in each dataset) is referred to as across approach. Since MIte/within has been shown to have superior performance in most cases, we only illustrate this approach here.\nLet’s assume we fit the following propensity score model within each imputed dataset.\n\n# apply propensity score matching on mids object\nps_form &lt;- as.formula(paste(\"treat ~\", paste(covariates_for_ps, collapse = \" + \")))\nps_form\n\ntreat ~ dem_age_index_cont + dem_sex_cont + c_smoking_history + \n    c_number_met_sites + c_hemoglobin_g_dl_cont + c_urea_nitrogen_mg_dl_cont + \n    c_platelets_10_9_l_cont + c_calcium_mg_dl_cont + c_glucose_mg_dl_cont + \n    c_lymphocyte_leukocyte_ratio_cont + c_alp_u_l_cont + c_protein_g_l_cont + \n    c_alt_u_l_cont + c_albumin_g_l_cont + c_bilirubin_mg_dl_cont + \n    c_chloride_mmol_l_cont + c_monocytes_10_9_l_cont + c_eosinophils_leukocytes_ratio_cont + \n    c_ldh_u_l_cont + c_hr_cont + c_sbp_cont + c_oxygen_cont + \n    c_ecog_cont + c_neutrophil_lymphocyte_ratio_cont + c_bmi_cont + \n    c_ast_alt_ratio_cont + c_stage_initial_dx_cont + dem_race + \n    dem_region + dem_ses + c_time_dx_to_index\n\n\n\nMatchingWeighting\n\n\nThe matching step happens using the matchthem() function, which is a wrapper around the matchit() function. This function not only provides the functionality to match on the propensity score, but also to perform (coarsened) exact matching, cardinality matching, genetic matching and more. In this example, we use a simple 1:1 nearest neighbor matching on the propensity score (estimated through logistic regression) without replacement with a caliper of 1% of the standard deviation of the propensity score.\n\n# matching\ndata_mimids &lt;- matchthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = 'nearest',\n  distance = \"glm\",\n  link = \"logit\",\n  caliper = 0.01,\n  ratio = 1,\n  replace = F\n  )\n\n# print summary for matched dataset #1\ndata_mimids\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [caliper]\n             - estimated with logistic regression\n - caliper: &lt;distance&gt; (0.001)\n - number of obs.: 3500 (original), 2682 (matched)\n - target estimand: ATT\n - covariates: dem_age_index_cont, dem_sex_cont, c_smoking_history, c_number_met_sites, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_ecog_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_stage_initial_dx_cont, dem_race, dem_region, dem_ses, c_time_dx_to_index\n\n\nThe resulting “mimids” object contains the original imputed data and the output of the calls to matchit() applied to each imputed dataset.\n\n\nThe weighting step is performed very similarly using the weightthem() function. In this example weapply SMR weighting to arrive at the same ATT estimand as matching which is indicated through the estimand = \"ATT\" argument. In case we wanted to weight patients based on overlap weights, estimand = \"AT0\" would need to be specified (which is one of the sensitivity analyses in the FLAURA protocol).\nTo mitigate the risks of extreme weights, the subsequent trim() function truncates large weights by setting all weights higher than that at a given quantile (in this example the 95% quantile) to the weight at the quantile. Since we specify lower = TRUE, this is done symmetrically also with the 5% quantile.\n\n# SMR weighting\ndata_wimids &lt;- weightthem(\n  formula = ps_form,\n  datasets = data_imp,\n  approach = 'within',\n  method = \"glm\",\n  estimand = \"ATT\"\n  )\n\n# trim extreme weights\ndata_wimids &lt;- trim(\n  x = data_wimids, \n  at = .95, \n  lower = TRUE\n  )\n\ndata_wimids\n\nA weightit object\n - method: \"glm\" (propensity score weighting with GLM)\n - number of obs.: 3500\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATT (focal: 1)\n - covariates: dem_age_index_cont, dem_sex_cont, c_smoking_history, c_number_met_sites, c_hemoglobin_g_dl_cont, c_urea_nitrogen_mg_dl_cont, c_platelets_10_9_l_cont, c_calcium_mg_dl_cont, c_glucose_mg_dl_cont, c_lymphocyte_leukocyte_ratio_cont, c_alp_u_l_cont, c_protein_g_l_cont, c_alt_u_l_cont, c_albumin_g_l_cont, c_bilirubin_mg_dl_cont, c_chloride_mmol_l_cont, c_monocytes_10_9_l_cont, c_eosinophils_leukocytes_ratio_cont, c_ldh_u_l_cont, c_hr_cont, c_sbp_cont, c_oxygen_cont, c_ecog_cont, c_neutrophil_lymphocyte_ratio_cont, c_bmi_cont, c_ast_alt_ratio_cont, c_stage_initial_dx_cont, dem_race, dem_region, dem_ses, c_time_dx_to_index\n - weights trimmed at 5% and 95%\n\n\nThe resulting “wimids” object contains the original imputed data and the output of the calls to weightit() applied to each imputed dataset.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-3---balance-assessment",
    "href": "chapters/syvcox_coxph.html#step-3---balance-assessment",
    "title": "3  Application in Cox PH models",
    "section": "3.4 Step 3 - Balance assessment",
    "text": "3.4 Step 3 - Balance assessment\nThe inspection of balance assessment in multiple imputed and matched/weighted data can be done in a similar way as with a single complete dataset. For illustration we just look at the matched datasets, but the exact same principles also apply to the weighted datasets.\n\nBalance tableCovariate balance (conditional exchangeability)Distributional balance (positivity)\n\n\n\n\n\nTable 3.1: Covariate balance table.\n\n\n# create balance table\nbalance_table &lt;- bal.tab(\n  x = data_mimids, \n  stats = \"m\",\n  abs = TRUE\n  )\n\nbalance_table\n\nBalance summary across all imputations\n                                        Type Mean.Diff.Adj Max.Diff.Adj\ndistance                            Distance        0.0054       0.0059\ndem_age_index_cont                   Contin.        0.0147       0.0371\ndem_sex_cont                          Binary        0.0090       0.0204\nc_smoking_history                     Binary        0.0051       0.0104\nc_number_met_sites                   Contin.        0.0162       0.0343\nc_hemoglobin_g_dl_cont               Contin.        0.0139       0.0336\nc_urea_nitrogen_mg_dl_cont           Contin.        0.0198       0.0484\nc_platelets_10_9_l_cont              Contin.        0.0123       0.0288\nc_calcium_mg_dl_cont                 Contin.        0.0116       0.0243\nc_glucose_mg_dl_cont                 Contin.        0.0142       0.0271\nc_lymphocyte_leukocyte_ratio_cont    Contin.        0.0125       0.0329\nc_alp_u_l_cont                       Contin.        0.0194       0.0435\nc_protein_g_l_cont                   Contin.        0.0093       0.0291\nc_alt_u_l_cont                       Contin.        0.0144       0.0306\nc_albumin_g_l_cont                   Contin.        0.0194       0.0544\nc_bilirubin_mg_dl_cont               Contin.        0.0153       0.0324\nc_chloride_mmol_l_cont               Contin.        0.0147       0.0310\nc_monocytes_10_9_l_cont              Contin.        0.0166       0.0425\nc_eosinophils_leukocytes_ratio_cont  Contin.        0.0150       0.0279\nc_ldh_u_l_cont                       Contin.        0.0094       0.0230\nc_hr_cont                            Contin.        0.0161       0.0383\nc_sbp_cont                           Contin.        0.0164       0.0465\nc_oxygen_cont                        Contin.        0.0198       0.0389\nc_ecog_cont                           Binary        0.0086       0.0189\nc_neutrophil_lymphocyte_ratio_cont   Contin.        0.0154       0.0358\nc_bmi_cont                           Contin.        0.0080       0.0144\nc_ast_alt_ratio_cont                 Contin.        0.0146       0.0420\nc_stage_initial_dx_cont              Contin.        0.0152       0.0321\ndem_race_Asian                        Binary        0.0067       0.0226\ndem_race_Other                        Binary        0.0021       0.0053\ndem_race_White                        Binary        0.0060       0.0173\ndem_region_Midwest                    Binary        0.0085       0.0148\ndem_region_Northeast                  Binary        0.0060       0.0128\ndem_region_South                      Binary        0.0091       0.0158\ndem_region_West                       Binary        0.0073       0.0159\ndem_ses                              Contin.        0.0177       0.0320\nc_time_dx_to_index                   Contin.        0.0156       0.0314\n\nAverage sample sizes across imputations\n               0      1\nAll       1487.  2013. \nMatched   1337.9 1337.9\nUnmatched  149.1  675.1\n\n\n\n\n\n\n\nlove.plot(\n  x = data_mimids,\n  abs = TRUE,\n  thresholds = 0.1, \n  drop.distance = TRUE,\n  var.order = \"unadjusted\",\n  colors = c(\"orange\", \"blue\"), \n  stars = \"std\",\n  shapes = 17, \n  size = 4, \n  grid = TRUE,\n  position = \"top\"\n  )\n\n\n\n\n\n\n\nFigure 3.1: Covariate balance plot (love plot).\n\n\n\n\n\n\n\n\nbal.plot(\n  x = data_mimids,\n  var.name = \"distance\",\n  which = \"both\",\n  which.imp = .none,\n  colors = c(\"orange\", \"blue\")\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html#step-4---estimation-of-marginal-treatment-effects",
    "href": "chapters/syvcox_coxph.html#step-4---estimation-of-marginal-treatment-effects",
    "title": "3  Application in Cox PH models",
    "section": "3.5 Step 4 - Estimation of marginal treatment effects",
    "text": "3.5 Step 4 - Estimation of marginal treatment effects\nNext, we compare the marginal treatment effect estimates coming from a Cox proportional hazards model after propensity score matching and weighting as implemented in the coxph() and in the svycoxph() functions.\nFrom the MatchThem documentation:\n\n\n\n\n\n\nImportant\n\n\n\n\nwith() applies the supplied model in expr to the (matched or weighted) multiply imputed datasets, automatically incorporating the (matching) weights when possible. The argument to expr should be of the form glm(y ~ z, family = quasibinomial), for example, excluding the data or weights argument, which are automatically supplied.\nFunctions from the survey package, such as svyglm(), are treated a bit differently. No svydesign object needs to be supplied because with() automatically constructs and supplies it with the imputed dataset and estimated weights. When cluster = TRUE (or with() detects that pairs should be clustered; see the cluster argument above), pair membership is supplied to the ids argument of svydesign().\nAfter weighting using weightthem(), glm_weightit() should be used as the modeling function to fit generalized linear models. It correctly produces robust standard errors that account for estimation of the weights, if possible. See WeightIt::glm_weightit() for details. Otherwise, svyglm() should be used rather than glm() in order to correctly compute standard errors.\nFor Cox models, coxph() will produce approximately correct standard errors when used with weighting, but svycoxph() will produce more accurate standard errors when matching is used.\n\n\n\n\nMatchingWeighting\n\n\nWe now want to compare treatment effect estimates for treat when computed (a) using coxph (survival package) and (b) svycoxph (survey package). More information on estimating treatment effects after matching is provided in https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html#survival-outcomes\n\n3.5.0.1 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_mimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat, \n               weights = weights, \n               cluster = subclass,\n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.2 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_mimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high)\n\nsvycoxph_results\n\n\n\n3.5.0.3 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7254684 0.04621408 0.6619961 0.7950264\n2   survey treat 0.7254684 0.04622663 0.6620192 0.7949987\n\n\n\n\n\n\n3.5.0.4 coxph\n\n# coxph result\ncoxph_results &lt;- with(\n  data = data_wimids,\n  expr = coxph(formula = Surv(fu_itt_months, death_itt) ~ treat,\n               weights = weights, \n               robust = TRUE\n               )\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survival\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\ncoxph_results\n\n\n\n3.5.0.5 svycoxph\n\n# svycoxph result\nsvycoxph_results &lt;- with(\n  data = data_wimids,\n  expr = svycoxph(formula = Surv(fu_itt_months, death_itt) ~ treat),\n  cluster = TRUE\n  ) |&gt; \n  pool() |&gt; \n  tidy(exponentiate = TRUE, conf.int = TRUE) |&gt; \n  mutate(package = \"survey\") |&gt; \n  select(package, term, estimate, std.error, conf.low, conf.high) \n\nsvycoxph_results\n\n\n\n3.5.0.6 Summary\n\nrbind(coxph_results, svycoxph_results)\n\n   package  term  estimate  std.error  conf.low conf.high\n1 survival treat 0.7310165 0.03463701 0.6830182 0.7823879\n2   survey treat 0.7310165 0.03464187 0.6830282 0.7823765",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/subgroup_analysis.html",
    "href": "chapters/subgroup_analysis.html",
    "title": "5  Subgroup analysis",
    "section": "",
    "text": "5.1 About\nThis script is adapted from Noah Greifer’s highly recommended blog post on “Subgroup Analysis After Propensity Score Matching Using R”.\nFor a more formal manuscript on subgroup analysis with propensity scores, see Green and Stuart.(Green and Stuart 2014)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Subgroup analysis</span>"
    ]
  },
  {
    "objectID": "chapters/whole_game.html",
    "href": "chapters/whole_game.html",
    "title": "2  The whole game",
    "section": "",
    "text": "2.1 Background\nENCORE",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The whole game</span>"
    ]
  },
  {
    "objectID": "chapters/syvcox_coxph.html",
    "href": "chapters/syvcox_coxph.html",
    "title": "3  Application in Cox PH models",
    "section": "",
    "text": "3.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness analytic cohort dataset with similar distributions to FLAURA, a randomized controlled trial that evaluated the efficacy and safety of osimertinib to standard-of-care (SoC) tyrosine kinase inhibitors (TKIs) in advanced NSCLC patients with a sensitizing EGFR mutation.\nThe following cohort resembles distributions observed in the EHR-derived EDB1dataset used in ENCORE. Note: the values of some continuous covariates (labs) are displayed after log/log-log transformation.\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  seed = 42, \n  include_id = FALSE, \n  imposeNA = TRUE,\n  propNA = .33\n  )\n\n# crate Table 1\ndata_miss |&gt; \n  tbl_summary(\n    by = \"treat\", \n    include = covariates_for_imputation\n    ) |&gt; \n  add_overall() |&gt; \n  modify_header(\n    label ~ \"**Patient characteristic**\",\n    stat_0 ~ \"**Total** &lt;br&gt; N = {N}\",\n    stat_1 ~ \"**Comparator** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\",\n    stat_2 ~ \"**Exposure** &lt;br&gt; N = {n} &lt;br&gt; ({style_percent(p, digits=1)}%)\"\n    ) |&gt; \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Treatment received**\") |&gt; \n  modify_caption(\"**Table 1. Patient Characteristics**\")\n\n\n\n\n\nTable 1. Patient Characteristics\n\n\n\n\n\n\n\n\nPatient characteristic\nTotal  N = 3500\n1\n\nTreatment received\n\n\n\nComparator  N = 1487  (42.5%)\n1\nExposure  N = 2013  (57.5%)\n1\n\n\n\n\ndem_age_index_cont\n69 (64, 74)\n69 (64, 74)\n69 (64, 74)\n\n\ndem_sex_cont\n1,146 (33%)\n494 (33%)\n652 (32%)\n\n\nc_smoking_history\n1,065 (46%)\n505 (50%)\n560 (42%)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_number_met_sites\n\n\n\n\n\n\n\n\n    1\n1,754 (75%)\n765 (76%)\n989 (74%)\n\n\n    2\n498 (21%)\n204 (20%)\n294 (22%)\n\n\n    3\n69 (3.0%)\n29 (2.9%)\n40 (3.0%)\n\n\n    4\n15 (0.6%)\n3 (0.3%)\n12 (0.9%)\n\n\n    5\n2 (&lt;0.1%)\n1 (&lt;0.1%)\n1 (&lt;0.1%)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_hemoglobin_g_dl_cont\n12.90 (11.95, 13.80)\n12.81 (11.91, 13.78)\n12.97 (11.98, 13.81)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_urea_nitrogen_mg_dl_cont\n2.71 (2.51, 2.93)\n2.72 (2.52, 2.95)\n2.70 (2.50, 2.91)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_platelets_10_9_l_cont\n261 (222, 296)\n262 (222, 298)\n259 (222, 294)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_calcium_mg_dl_cont\n2.23 (2.20, 2.26)\n2.23 (2.20, 2.26)\n2.23 (2.20, 2.26)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_glucose_mg_dl_cont\n4.64 (4.56, 4.71)\n4.64 (4.56, 4.71)\n4.64 (4.57, 4.71)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_lymphocyte_leukocyte_ratio_cont\n2.88 (2.75, 2.99)\n2.87 (2.75, 2.99)\n2.88 (2.75, 3.00)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_alp_u_l_cont\n4.48 (4.39, 4.57)\n4.47 (4.38, 4.56)\n4.48 (4.40, 4.57)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_protein_g_l_cont\n67.9 (65.3, 70.7)\n67.9 (65.3, 70.6)\n68.0 (65.4, 70.7)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_alt_u_l_cont\n2.89 (2.66, 3.10)\n2.89 (2.67, 3.10)\n2.89 (2.66, 3.10)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_albumin_g_l_cont\n39.94 (37.91, 41.93)\n39.92 (37.96, 41.82)\n39.97 (37.86, 42.03)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_bilirubin_mg_dl_cont\n-0.91 (-1.75, -0.09)\n-0.88 (-1.75, -0.07)\n-0.92 (-1.76, -0.13)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_chloride_mmol_l_cont\n102.07 (99.95, 104.09)\n101.98 (99.89, 104.04)\n102.11 (100.03, 104.20)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_monocytes_10_9_l_cont\n-0.51 (-0.68, -0.33)\n-0.53 (-0.69, -0.34)\n-0.49 (-0.66, -0.33)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_eosinophils_leukocytes_ratio_cont\n0.68 (0.30, 1.08)\n0.69 (0.33, 1.07)\n0.68 (0.29, 1.08)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_ldh_u_l_cont\n1.69 (1.66, 1.72)\n1.69 (1.65, 1.72)\n1.69 (1.66, 1.72)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_hr_cont\n4.43 (4.40, 4.46)\n4.43 (4.40, 4.46)\n4.43 (4.40, 4.45)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_sbp_cont\n4.85 (4.79, 4.91)\n4.85 (4.79, 4.92)\n4.85 (4.79, 4.91)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_oxygen_cont\n97.000 (96.994, 97.006)\n97.000 (96.993, 97.006)\n97.000 (96.994, 97.006)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_ecog_cont\n1,360 (58%)\n620 (62%)\n740 (55%)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_neutrophil_lymphocyte_ratio_cont\n1.30 (1.03, 1.55)\n1.29 (1.02, 1.55)\n1.31 (1.04, 1.55)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_bmi_cont\n3.23 (3.14, 3.32)\n3.24 (3.15, 3.32)\n3.23 (3.13, 3.32)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_ast_alt_ratio_cont\n0.12 (-0.08, 0.32)\n0.12 (-0.08, 0.31)\n0.12 (-0.08, 0.32)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_stage_initial_dx_cont\n\n\n\n\n\n\n\n\n    1\n34 (1.5%)\n19 (1.9%)\n15 (1.1%)\n\n\n    2\n71 (3.0%)\n34 (3.4%)\n37 (2.8%)\n\n\n    3\n476 (20%)\n226 (23%)\n250 (19%)\n\n\n    4\n1,757 (75%)\n723 (72%)\n1,034 (77%)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_de_novo_mets_dx\n1,870 (80%)\n796 (79%)\n1,074 (80%)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_height_cont\n1.65 (1.60, 1.71)\n1.65 (1.60, 1.70)\n1.65 (1.60, 1.71)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_weight_cont\n69 (61, 76)\n69 (61, 76)\n69 (61, 77)\n\n\n    Unknown\n1,162\n485\n677\n\n\nc_year_index\n\n\n\n\n\n\n\n\n    &lt;2018\n3,324 (95%)\n1,400 (94%)\n1,924 (96%)\n\n\n    2018+\n176 (5.0%)\n87 (5.9%)\n89 (4.4%)\n\n\nc_dbp_cont\n76.2 (71.9, 80.1)\n76.4 (72.1, 80.0)\n75.9 (71.8, 80.2)\n\n\n    Unknown\n1,162\n485\n677\n\n\ndeath_itt\n3,465 (99%)\n1,482 (100%)\n1,983 (99%)\n\n\nfu_itt_months\n18 (8, 36)\n16 (8, 30)\n20 (9, 39)\n\n\n\n1\nMedian (Q1, Q3); n (%)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Application in Cox PH models</span>"
    ]
  },
  {
    "objectID": "chapters/re_weight.html",
    "href": "chapters/re_weight.html",
    "title": "4  Re-weighting to a target population",
    "section": "",
    "text": "4.1 Data generation\nWe use the simulate_flaura() function to simulate a realistic oncology comparative effectiveness cohort analytic dataset.\nShow the code\n# load example dataset with missing observations\ndata_miss &lt;- simulate_flaura(\n  n_total = 3500, \n  seed = 41, \n  include_id = FALSE, \n  imposeNA = TRUE,\n  propNA = .33\n  ) |&gt; \n  # anesrake works best with factor variables\n  # create age category with age less than 65\n  mutate(dem_age_lt65 = factor(ifelse(dem_age_index_cont &lt; 65, \"&lt;65\", \"65+\"))) |&gt; \n  # convert dem_race into a binary Asian vs. non-Asian \n  mutate(dem_race = factor(ifelse(dem_race == \"Asian\", \"Asian\", \"Non-Asian\"))) |&gt;\n  # convert dem_sex_cont into a factor \n  mutate(dem_sex_cont = factor(ifelse(dem_sex_cont == \"1\", \"Male\", \"Female\"))) |&gt; \n  # convert dem_sex_cont into a factor \n  mutate(c_smoking_history = factor(ifelse(c_smoking_history == TRUE, \"Current/former\", \"Never\"))) |&gt; \n  # convert c_ecog_cont into a factor \n  mutate(across(c(c_ecog_cont), function(x) factor(as.character(x))))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Re-weighting to a target population</span>"
    ]
  }
]